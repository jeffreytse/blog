[
    {
      "title"    : "A* Search and its Variants",
      "url"      : "/blog/2022/Multi-heuristic-Astar.html",
      "tags"     : "Machine Learning, Notes",
      "date"     : "2022-04-20 00:00:00 +0000",
      "content"  : "Let $g(s)$ denote the cost of a least-cost path from $s_{start}$ to $s$, we then have$$g(s) = min_{s’in pred(s)}{(g(s’) + c(s’, s))}$$That is, minimum $s$ equals min get predecessor (a.k.a. $s’$ in formula above) add actual $s$.A* Search :package: A* is guaranteed Return an optimal Perform minimal number state expansions required guarantee optimality.The predicted $s_{goal}$ through can be estimated through$$f(s_{start}, s, s_{goal}) g(s_{start}, s) h(s, s_{goal})$$$g$ represents getting starting state. $h$ heuristic estimation $s$.Requirement Heuristic FunctionHeuristic function must beAdmissible - The underestimate / accurately predict cost.$$h(s) leq min{c(s, s_{goal})}$$Consistent should satisfy triangle inequality.$$h(s_{goal}, 0,quad h(S) c(s, s’) h(s’)$$A consistent admissible.Multi-goal (With Imaginary Goal State)When there are multiple goals, construct imaginary goal graph that connects all goals.If goals have different weights (we preference certain over others), adjust edge between each state.Weighted weighted allow us sub-optimal result with less expansion, which consumes memory and computation time.The scale explored nodes search much smaller than dijkastra algorithm. This because $f(s) h(s) g(s)$ provides two constraints on explore.However, for high dimensional graph, algorithm will soon out memory. We need some stronger constraint expansion nodes. Weighted A*, one apply losing optimality search.Instead using g(s)$, puts weight $epsilon$ function$$f(s) g(s) epsilon h(s)$$This make has more bias towards states closer goal.Definition ($varepsilon$-suboptimal) $cost(solution) varepsiloncdot cost(optimal;solution)$Common Functions Function Equation Euclidean Distance $h(x, y) sqrt{(x x_{goal})^2 (y y_{goal})^2}$ Manhattan abs(x x_{goal}) abs(y y_{goal})$ Diagonal max(abs(x x_{goal}), y_{goal}))$ These functions both admissible.:zap: Useful Properties If $h_1(s)$, $h_2(s)$ consistent, $h(s) max(h_1(s), h_2(s))$ also consistent. uses $varepsilon$-consistent heuristics $$ forall sneq s_{goal}quad h(s_{goal}) 0 wedge varepsilon succ(s)) h(succ(s)) $varepsilon$-suboptimal Cost(solution) cdot Cost(optimal;solution) h(s)$ $varepsilon$ -consistent heuristics. $h_1(s) h_2(s)$ $varepsilon$-consistent. :question: what here? There no such variable $h_1$ $h_2$… Why Need Multiple Heuristic? Can use bunch inadmissible simultaneously while preserving guarantees completeness bounded sub-optimality?To solve real-world problem DoF robots, series arbitrary, functions! How reach this …? :drum::drum::drum: Multi-heuristic A*!Why not taking max directly? Information lost when Creates local minima inside space Requires admissible :arrow_left: real problemMulti-Heuristic SearchVersion 1 Parallel A*Run $N$ independent, searches. them find solution, whole finds solution.Version 2 Shared SearchShare information searches Share Open Closed algorithms. When adds node into Open, other algorithm’s as well.Such shared several advantages: Different inadmissive algorithms help minimas. Since algorithms, expanded at most once across ALL searchesYet, still problems: No or bounds solution quality.Version 3 Anchor SearchSearch control expansions. In way, complete provide quality.The called Search.The ensure completness multi-heuristic A*."
    },
    {
      "title"    : "Embeddable Clac Execution Environment",
      "url"      : "/blog/2022/clac-embeddable.html",
      "tags"     : "Web, React",
      "date"     : "2022-04-05 00:00:00 +0000",
      "content"  : "DemoAn open-to-use, embeddable clac execution implemented with React and TypeScript. You can try it below!For example, to input the instruction : square 1 pick * ; 2 print into wedget below see what will happen!About This ProjectThis is an attempt build interactive web-based runtimes of a toy language used in 15-122 Principle Imperative Computation, Clac, TypeScript React. find source code at https://github.com/MarkChenYutian/TypeScript-Claculator.So Cool! How Can I deploy on my site?Download index.min.js file from Here, link your webpage with&amp;lt;!-- Place this line end page --&amp;gt;&amp;lt;script src=&quot;&amp;lt;your-installation-dir&amp;gt;/index.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;Then, where you want insert widget, line:&amp;lt;div id=&quot;claculator-interactive&quot; data-mode=&quot;embeddable&quot;&amp;gt;&amp;lt;/div&amp;gt;About The Clac LanguageNotes*: token causes 𝑛n be printed, followed by newline. quit interpreter stop. 32 bit, two’s complement language, so addition, subtraction, multiplication, exponentiation should behave just as C0 without raising any overflow errors. Division or modulus 0, division/modulus int_min() -1, which would result arithmetic error according definition (see 4 Reference), raise Clac. Negative exponents are undefined also error. if 𝑛n, value top stack, not strictly positive. skip negative; 0 acceptable.* Notes Notes: Since we implementing its core JavaScript, some specific numerical calculation may match original, version’s result."
    },
    {
      "title"    : "How to Type LaTeX Fast &amp; Elegant - A Guide from &amp; for Beginner",
      "url"      : "/blog/2022/type-LaTeX-fast.html",
      "tags"     : "Notes",
      "date"     : "2022-02-16 00:00:00 +0000",
      "content"  : "1 用 LaTeX, 而不是与 LaTeX 搏斗 的设计哲学是：让使用者付出最少的努力就能得到工整美观的排版然而，讽刺的是，大部分人（至少一开始）的体验似乎都与这个设计哲学正好相反。这是因为我们都习惯了使用 Word 这样“所见即所得”的排版软件/文字编辑器。当我们按下空格的时候，屏幕上就一定会出现一个空格。在 中，因为使用的是“编辑 - 编译 排版”的流程，我们不能直观的立刻看到我们在TeX文件中做出的改变。当我们在单词之间输入好几个空格却发现排版结果中只有一个空格时，自然会感觉非常奇怪和不适应。 实际上，很多时候在使用 时如果发现打起来非常麻烦/结果特别丑，大部分时候都是我们在作茧自缚，下面举几个常见的例子 （点击展开）： 通过 // 或者 newline 来打“回车”，抱怨行和行都“挤在一起” 在 中，// 代表“断行” 也就是说，下一行的内容与当前在同一段中，但是强制进行一次换行。所以 不会在这两行之间添加额外的空位。 大部分情况下，你可以将一整段话连续的写在同一行中。LaTeX 会自动根据页面宽度处理换行问题。如果你需要开启一个新的段落，在行和行之间添加一个空行即可。 正确的段落： [Paragraph 1] , random text with correct paragraph Pellentesque interdum sapien sed nulla. Proin tincidunt. Aliquam volutpat est vel massa. Sed dolor lacus, imperdiet non, ornare commodo eu, neque. Integer pretium semper justo. risus. Nullam id quam. Nam 2] Duis vitae wisi ullamcorper diam congue ultricies. Quisque ligula. Mauris vehicula. 错误的段落（用断行，而不是新段落）： textbf{[Paragraph 1]} line break 2]} 经典错上加错：在断行的基础上强行用 vspace 等指令拉大行之间的空白，营造一种“分段”的感觉 $...$ 写公式，抱怨公式都堆到左边，并且挤成一团 符号括起来写的公式是“行内公式” 也就是说，LaTeX 认为这些公式是跟普通文字写在同一行上的，所以会尽可能的压缩这些公式的高度，并且不会在行和行之间留下额外的空位 行内公式： $-frac{2a pm sqrt{b^2 4ac}}{b}$ 结果：$-frac{2a 如果需要打大公式，需要使用 $$...$$（或者 begin{equation}...end{equation}） 打一个“公式块” 这样渲染出来的公式会自动居中并且占用一个段落的空间 多行公式： begin{equation*} -frac{2a 4ac}}{b}end{equation*} 结果：$$ 4ac}}{b} $$ 如果你需要对齐多行公式（比如推导/化简长式子），使用 begin{equation}begin{aligned}…end{aligned}end{equation}。 带对齐的多行公式： begin{aligned} E[X + Y] &amp;amp;= sum_{j = 1}{s_jcdot P[X Y s_j]} sum_{k, l text{ s.t. } x_k y_l s_j}{P[X x_k, y_l]}} sum_{j}{sum_{k, s_j}{(x_k y_l)cdot l}{(x_k y_l]} l}{x_kcdot l}{y_lcdot sum_{k}x_k cdot sum_{l}{P[X cdots E[X] E[Y] end{aligned}end{equation*} 结果： 类似的例子还有很多…… 比如疯狂用 ; 来代替word里的“空格”， etc.实际上，对于排版时遇到的大部分场景，LaTeX 都有提供对应的指令或环境，如果不知道对应的指令用 vspace或者; 来 “蛮干”，“硬干”，相当于是在和 $LaTeX$ 搏斗，而不是使用它。当然，也有一些情况，$LaTeX$ 自带的排版没法满足我们的需求，这种时候，我们应该创建自己的环境/模版/样式，或者找合适的 Package与template，而不是强行拉扯 提供的默认排版。 命令/环境/语法 解释 效果 ![20220217124421](https://markdown-img-1304853431.file.myqcloud.com/20220217124421.png) 多行公式 ![20220217124434](https://markdown-img-1304853431.file.myqcloud.com/20220217124434.png) ![20220217124547](https://markdown-img-1304853431.file.myqcloud.com/20220217124547.png) 行内公式 ![20220217124604](https://markdown-img-1304853431.file.myqcloud.com/20220217124604.png) ![20220217125002](https://markdown-img-1304853431.file.myqcloud.com/20220217125002.png) 多行对齐公式 ![Screen Shot 2022-02-17 at 12.50.19 PM](https://markdown-img-1304853431.file.myqcloud.com/Screen PM.png) ![20220217124317](https://markdown-img-1304853431.file.myqcloud.com/20220217124317.png) 分页   ![20220217125308](https://markdown-img-1304853431.file.myqcloud.com/20220217125308.png) 无序列表 ![20220217125319](https://markdown-img-1304853431.file.myqcloud.com/20220217125319.png) ![20220217125340](https://markdown-img-1304853431.file.myqcloud.com/20220217125340.png) 有序列表 ![20220217125357](https://markdown-img-1304853431.file.myqcloud.com/20220217125357.png) ![20220217125456](https://markdown-img-1304853431.file.myqcloud.com/20220217125456.png) 无序列表（自定义编号） ![20220217125511](https://markdown-img-1304853431.file.myqcloud.com/20220217125511.png) 2 创建快捷指令2.1 基础快捷指令但是这又带来了新的问题 “是啊，LaTeX 有这些默认的模版，但是用起来麻烦死了，你看输入一个多行公式前前后后加起来要打四行，太浪费时间了” “虽然 打的公式很好看，但是真的好麻烦，打一个自然数的符号 $mathbb{N}$ 要 mathbb{N} 这么多个字符！”对于这个问题，LaTeX 自然也有对应的解决方法，我们可以使用 setnewcommand 命令为自己常用的符号设置“快捷键”。比如下面的TeX指令允许我们在接下来的 中使用 N 替代 mathbb{N}。newcommand{N}[0]{mathbb{N}}实际上，你可以将任何常用，但是很麻烦的指令用这种快捷键的形式简化，创建快捷键的语法是newcommand{你想用的快捷指令}[0]{实际上的复杂长指令} 注意：这些命令应该放在 begin{document} 前， usepackage{...} 后的位置 :warning: 每新建完一个指令以后，最好马上尝试重新编译一下文件，因为有时候新创建的快捷键会和 原有指令冲突，这种时候就会出现一些奇怪的编译错误。（比如 and 就是一个TeX的关键字，所以还是乖乖打 wedge 吧（狗头））2.2 带参数的快捷指令使用一些其它命令，你还可以创建有参数（甚至可以设定可选参数和其缺省值）的快捷指令。比如下面的 TeX 命令会创建一个叫 pic 的快捷指令usepackage{xparse} % 这个包让我们能够生成带“可选参数”的快捷指令% ...NewDocumentCommand{pic}{ O{textwidth} m O 可选参数，大括号内为缺省值，m 必须参数{ begin{center} begin{figure}[ht] centeringincludegraphics[width=#1]{assets/#2} 将参数1填到 #1 的位置，参数2填到 #2 的位置 end{figure} end{center}FloatBarrier}在这个定义之前，在 中插入与页面等宽的图片 assets/1.jpeg 要用这么长一段：begin{center} centeringincludegraphics[width=textwidth]{assets/1.jpeg} end{figure}end{center}FloatBarrier现在，我们只需要 pic{1.jpeg} 就可以做到一样的事情。如果我们想指定图片宽度为300pt，使用定义的可选参数 pic[300pt]{1.jpeg} 即可。3 使用 VS Code 插件 Workshop 插件链接 上配置和使用 的方法详见插件 Latex 的安装说明3.1 创建代码片段使用自定义的快捷指令可以大幅提高写 速度，但是会降低代码的可读性和灵活性（比如，在刚刚 的命令中，如果我想读取的照片不在 assets 文件夹中，就不能使用这个命令了）。同时，如果别人要读我的 文件，他看到 这个命令可能会一头雾水，因为这不是标准指令。这种时候，我们就可以使用 的 “Code Snippet” 功能，创建一个“代码模版”。输入特定指令后，在自动补全选项中选择对应的选项，VS 会自动向光标位置插入预制好的模版代码。这样，在保证输入效率的前提下，我们可以兼得灵活性和可读性。 输入设置好的模版简写，在自动补全列表中选中模版 按回车，模版被自动插入到文件中，光标自动移动到指定的位置 要设置这样的模版，在 VSCode 打开的 文件夹中（workspace）新建一个叫 .vscode 的文件夹，在其中新建 tex_snippet.code-snippets 文件，并使用这样的格式（JSON格式）书写：{ &quot;Clean Equation Block&quot; : { &quot;scope&quot;: &quot;latex&quot;, &quot;prefix&quot;: &quot;EQ*&quot;, &quot;body&quot;:[ &quot;begin{equation*}&quot;, &quot; $1&quot;, &quot;end{equation*}&quot; ] }, &quot;新的模版描述&quot; 我们的模版只在 文件中生效 &quot;WHATEVER&quot;, 模版的简写，一般用全大写字母，减小误触发可能 &quot;body&quot;: [ &quot;first of template&quot;, $1 &amp;lt;- cursor will stop here after applying &quot;end the template&quot; }}3.2 使用插件内置的快捷键/模版LaTeX workshop 插件内置了许多非常常用的快捷键和代码模版，这里提供其中一些常用的快捷键： 模版简写 BEN 有序列表（enumerate 环境） BIT 无序列表（itemize 指令 内容 @a alpha @A Alpha … …（大部分希腊字母都可以用 @ 对应英文字母打出来） @6 partial 偏微分符号 @/ frac{}{} 分数 4 创建自己的模版/样式 挖个坑，这里我自己也一知半解的，以后再填吧"
    },
    {
      "title"    : "The Fences | AR Web Application",
      "url"      : "/blog/2022/the-fences.html",
      "tags"     : "Web",
      "date"     : "2022-02-11 00:00:00 +0000",
      "content"  : "In a Sentence, What is It?Our inspiration came from The Fence at CMU:By providing synchronized, immersive AR experience across different platforms, we aim to build bond between virtual space and physical world, allowing people share their ideas openly, just like role of Fence.Short Demo iOS Application Web &amp;lt;img src=&quot;https://user-images.githubusercontent.com/47029019/152687716-21fb26b1-a8f5-4d14-b952-7df44f0b2eaa.gif&quot; style=&quot;height: 25rem&quot;/&amp;gt; ![web-demo-min](https://user-images.githubusercontent.com/47029019/152687732-d309165a-c033-444b-8bb8-8011d533efcf.gif) You can the web application here: https://the-fence-340405.web.app/frontend/viewer/. However, since requires specific QR-code detect board, you will not see any content unless print QR code denoting UL-6d44ae39 DR-6d44ae39 stick them on wall. :warning: Our relies QR-detector built in browser. it known that Chrome MacOS has memory leak problem. So webpage may use up 7GB if leave for 2hrs.How We Implement These Magical Apps? (Brief Version)Mobile ApplicationFor mobile application, upon Kit, ML Core Scene Kit. With recognizing environment, Kit initializing space, rendering content, our app provide user with fluent experience.Web WebRTC, OpenCV WebAssembly create chance view all users without need installing application.Specifically, Code only identify current board’s ID, but also calculate perspective matrix frame draw overlay browser.Serverless BackendFor backend support, deploy product Firebase Cloud Run Google Platform. nature cloud service allow have low latency high availability splatforms.Technical Details - ApplicationWhy call this Pseudo-AR Experience?The special project (showing AR-like boards wall) makes possible real-time renderer purely through technical stack (Javascript WebAssembly).Unlike broad definition objects (which float 3D around or some “anchor”), render ensured stay plane.How Render, Actually?Since an as anchor (Up-Left corner content), transform using original dimension detected contour Code.As same plane Code, it’s safe us assume they matrix. Therefore, re-apply resulted transformation raw image it.function getPerspectiveMatrix(p1, p2, p3, p4, bboxW, bboxH)// Originally p1, p4 detected.{ let corner1 = new cv.Point(p1.x, p1.y); corner2 cv.Point(p2.x, p2.y); corner3 cv.Point(p3.x, p3.y); corner4 cv.Point(p4.x, p4.y); perspectiveArray [ corner1.x, corner1.y, corner2.x, corner2.y, corner3.x, corner3.y, corner4.x, corner4.y ]; srcArray 0, bboxH, bboxH perspectiveMat cv.matFromArray(4, 1, cv.CV_32FC2, perspectiveArray); srcMat srcArray); T cv.getPerspectiveTransform(srcMat, perspectiveMat); srcMat.delete(); perspectiveMat.delete(); return T;}function renderPerspective(p0, bboxH) { boardMat undefined; (isLoaded(document.getElementById(&quot;board-src&quot;))){ cv.imread(&quot;board-src&quot;); } else cv.imread(&quot;loading&quot;); getPerspectiveMatrix(p0, bboxH); cv.Mat(boardElem.height, boardElem.width, cv.CV_8UC4); dsize cv.Size(overlayElem.width, overlayElem.height); cv.warpPerspective( boardMat, perspectiveMat, T, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, cv.Scalar() ); cv.imshow(overlayElemID, boardMat.delete(); T.delete(); calculateRatio();}By laying video, rendered output canvas, HTML Document Elements stack, pseudo-AR users, even when device does support standard WebXR APIs.When detection result arrives, two cases don’t update result: No (the Detector occationally miss codes view) Countinuity Enhancement Intervened almost previous one Stability IntervenedContinuity EnhancementThe barcodeDetector provided by fast, unstable. Minor change camera position lead loss 1-2 frames result.When there are no detected, Not clear canvas once. Instead, begin count number result. If counter reach 10, then be cleared. This greatly relief flickering problem Content.Stability EnhancementIf every based Scanner directly, highly unstable poor experience. Before Stabilization After ![BadExample-min](https://user-images.githubusercontent.com/47029019/152672103-b7260f7c-171b-4b82-894c-69c18187a250.gif) ![GoodExample-min](https://user-images.githubusercontent.com/47029019/152672171-288b6b09-8fe7-4a75-8b52-c317f3769cdb.gif) When P1 within three pixels away previos (P1&#39;), NOT Render. minimize “shaking” better Illustration Explaination ![illustration](https://user-images.githubusercontent.com/47029019/152673584-0124049d-506e-456f-802f-09d08c06fbe7.jpeg) black square t, re-rendered case green frames. t + 1 red bounding box, re-rendered."
    },
    {
      "title"    : "Serverless File System based on AWS S3",
      "url"      : "/blog/2022/serverless-file-system.html",
      "tags"     : "Web",
      "date"     : "2022-01-19 00:00:00 +0000",
      "content"  : "This system is deployed on My blog’s file Sharing Page as a front-end application.Reference Information: Viewing Photo stored in S3 Buckets AWS SDK for JavaScript Cognito Identity PoolHow these Work?A user identity pool created using Cognito. Any authenticated / unauthenticated join this will be automatically assigned with an role. Then, we create key corresponding to pool. Anyone access Service and given get role called Cognito_MyBlogFilesUnAuth_Role.Using IAM, can assign permission some specific Resource. In case, only allow users the storage bucket yutian-public them List Get objects from bucket.{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;VisualEditor0&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListBucket&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::yutian-public&quot; }, &quot;VisualEditor1&quot;, &quot;s3:GetObject&quot;, &quot;arn:aws:s3:::yutian-public/*&quot; } ]}"
    },
    {
      "title"    : "NLP 101: Transformer Model",
      "url"      : "/blog/2022/Transformers.html",
      "tags"     : "NLP, Neural Network",
      "date"     : "2022-01-09 00:00:00 +0000",
      "content"  : "0 背景知识 词嵌入 - Word Embedding 一种将自然语言在转化为向量表示的同时保留词汇原有的语义余上下文信息的方法（将高维的自然语言“嵌入”到低维向量空间） 编码器-解码器结构 Encoder-Decoder Architecture 编码器-解码器结构将任务分成两个步骤：先由编码器将输入编码/总结，再通过解码器将编码结果解析成真正的输出 注意力机制 Attention Mechanism 一种通过动态赋予编码器所有隐藏状态权重让解码器充分，有重点的获取信息的方法。 1 Self-Attention 自注意力机制1.1 与 的区别注意力机制的提出是作为解决 Seq2Seq 模型中的信息瓶颈与中间状态丢失问题的一个解决方案。然而，在 Google 2018 年发表的论文 is All You Need 中，研究人员们创新性的提出了“自注意力机制”。在这种注意力机制的变种中，注意力机制不再作为连接模型两个部分的中间件出现。 Fig 1. vs. 自注意力机制如 所示，在自注意力机制中，我们让 $q_t = k_t v_t h_t$，并将注意力权重在各个隐藏状态上的加权平均直接输出。这也是这个结构名称“自注意力机制”的来由 —— 用来计算注意力权重的 $q_i$ $k_i$ 都来自于同一层数据（自己）。 2. 自注意力机制的 $q$, $k$, $v$ 都来自于“自己”1.2 删去传统 NLP 模型中的 RNN 结构 Need！仔细分析 2 中的结构，我们会发现实际上自注意力机制的结构还可以更加简单。我们在 模型中使用 LSTM 是为了让模型获知整个输入序列的上下文内容。然而，在 模型中，这么做似乎没有什么意义。因为注意力机制单独可以保证输出层可以获得整个输入序列的上下文。所以，我们实际上可以直接删去 结构中的 而不影响模型获取的信息量。这也是论文题目 Attnetion 的意思了 我们的模型实际上可以只使用自注意力机制，完全不使用之前十多年中各类解决 问题的模型的核心结构 递归神经网络 RNN。 3. 删去 连接后的自注意力层，输出依然可以获得整个输入序列的上下文1.3 自注意力机制 vs 全连接层？观察 2，不难发现自注意力结构的输出结果其实就是输入的线性结合而已。如果是这样的话，那自注意力层与全连接层有什么区别呢？难道经过了十多年的发展，神经网络的研究者们又用 fancy 的方法重新发明了一次全连接层吗？ 4. 自注意力层与全连接层非常相似 从某种意义上说实际上自注意力机制可以看成一种更加高级，抽象的全连接层。与全连接层直接学习神经元之间的权重不同，自注意力机制在训练过程中会学习如何分配神经元之间权重使得损失函数最小化。 如果说全连接层是在直接学习 $y Wx$ 中的权重参数 $W$，那么自注意力机制则是在学习 $g: x rightarrow W$ 这样一个根据输入动态计算权重的函数。同时，因为自注意力机制不是直接学习神经元之间的权重，我们可以在不定长度的输入上使用自注意力机制。1.4 递归神经网络？自注意力机制在建立输出与整个输入序列之间的联系的同时避免了递归神经网络的许多缺点：因为在自注意力机制中没有递归调用自身参数，我们不会有梯度消失/爆炸问题。同时，因为在递归神经网络中，每一个时刻网络的状态都由该时刻前网络的状态所决定，我们不能并行的处理输入序列。在自注意力机制中，因为输出中的每一个分量都是互相独立的，我们可以并行的计算所有输出分量。这可以让模型的计算速度大幅增加。在论文中，作者比较了 自注意力机制，递归神经网络和卷积的时间复杂度与并行运算时间 （假设词向量维度为 $d$，输入序列长度为 $n$，卷积核尺寸为 $ktimes k$）   Time Complexity Work Span $O(n^2cdot d)$ $O(1)$ Recurrent NN $O(ncdot d^2)$ $O(n)$ Convolution $O(kcdot ncdot 可以发现，在输入序列长度不超过词向量维度的情况下，自注意力机制的时间复杂度与并行运算时间都是三种模型中最小的。2 Multi-Head 多头注意力机制现在我们将上文提到的自注意力机制封装成一个模块 向这个模块输入长度相同的向量 $K$，$V$ 和 $Q$，模块会输出长度相同的一个结果 $Y$。 5. 为了方便下文讨论，我们将自注意力层封装成一个模块讨论虽然在上文关于自注意力机制的讨论中，我们为了方便起见，让 $q_i k_i v_i x_i$，在实际的 模型中，我们会分别对 $x$ 进行不同的操作得到不同的 $Q$, $K$, $V$。我们可以将这些操作用矩阵 $W$ 表示：$$Q W_q X,quad K W_k V W_v X$$其中，这三个 矩阵都是模型中可学习的参数。而我们上面的例子中则使用的是 $W_q I$ 的一个特殊情况。我们把这样一个自注意力层 + Q，K，V 分别的线性变换操作合称为一个“单头注意力”。 6. 单头注意力模型由一个自注意力层与三个对输入的线性变换构成将多个单头注意力合并在同一层上，就形成了一个“多头注意力层(Multi-head Attention)”。 理论上，多头注意力中的每一个自注意力层会学习到不同的权重参数，从而提高编码器的表达力。 7. 多头注意力由多个单头注意力堆叠而成 3 Transformer 的结构3.1 编码器 Encoder在 中，一个编码器模块由一个多头注意力与一个前馈网络构成。前馈神经网络会单独处理多头注意力的每一个输出 token。 8. 中的每一个解码器模块都由两个部分构成，两个部分各司其职。同时，模块内部的组件之间有 Shortcut Connection 保证梯度的传递这样，在解码器的每一个模块中其实对输入信息做了两步处理： 将输入的 tokens 通过多头注意力“混合”起来，使得每一个输出token都得到了所有输入中所需的信息 将“混合”后的 token 通过前馈神经网络进行特征提取，对每一个 进行真正的“解读” 与此同时，作者为了防止重复堆叠编码器模块导致梯度消失/爆炸，模仿 ResNet 的做法在每一个模块的两个组件之间都添加了短路连接来帮助梯度反向传播。在输入序列进入堆叠的编码器模块前要先经过词嵌入层与位置编码层。词嵌入层通过类似查表的方式将自然语言输入转化为 $mathbb{R}^n$ 向量空间中可以计算的向量形式。位置编码层则将输入token之间的绝对位置关系通过加法的形式写入到token中传递给编码器。 9. 的编码器结构3.2 解码器 DecoderTransformer 的解码器与编码器类似，也由重复堆叠的解码模块构成。每一个解码模块的结构如下 10. 的解码模块中有一个 Masked Multi-head Attention，一个 前馈神经网络在解码器中出现了一个之前没有提及的“Masked Attention”。这里的“Masked”指的是加在原始注意力权重 $g(q, k)$ 上的一个矩阵。 11. Multihead 的计算图，可以看到遮罩是放在 Q，K 的运算结果（原始注意力权重）上的这个遮罩可以防止解码器利用“未来”的信息。比如解码器已经输出了 “I / am fine .”，我们现在将这些token输入到解码器中，让解码器预测下一个token。由于解码器输出 “I” 的时候 “am .” 还没有生成，I 和这些 没有关系。通过遮罩，我们可以“手动”将这些没有因果关系的注意力权重设置为0. 12. 中，我们可以用遮罩手动，显式的移除这个 与解码器在未来的输出之间的关系3.3 整体将编码器与解码器合并起来，我们就的到了 的模型：4 参考来源 Sources CMU 11-785 21 Fall Lecture 19: &amp;amp; GNN Illustrated Guide to Transformers Neural Network Stack Overflow How Understand in Difference between Self-attention and Fully Layer"
    },
    {
      "title"    : "NLP 101: Attention Mechanism",
      "url"      : "/blog/2022/Attention-Mechanism.html",
      "tags"     : "NLP, Neural Network",
      "date"     : "2022-01-04 00:00:00 +0000",
      "content"  : "Seq2Seq 模型的问题在之前关于 模型的文章中，我们在最后提到了编码器与解码器之间的信息瓶颈问题 Fig 1. 模型中编码器与解码器之间的“瓶颈” 由于编码器与解码器之间只使用总结向量连接，当向编码器输入长序列时，总结向量由于维度限制可能无法包涵输入序列中的所有信息。 同时，因为我们只将编码器的最后时刻的隐藏状态作为总结向量传递给了解码器，编码器中间隐藏状态的信息不可避免的被丢失了。Attention Mechanism 最开始被提出就是为了解决 模型的这两个问题。使用平均隐藏状态作为总结向量？ 2. 将编码器所有隐藏状态取平均后在每一个时刻作为输入的一部分传递给解码器 在这样的一个模型中，我们将编码器的所有隐藏状态取平均后通过与解码器的输入直接拼接将编码器的信息传递给解码器。通过计算编码器所有隐藏状态的平均值，我们解决了问题2 - 现在传递的“总结向量” $h_{avg}$ 包涵了编码器中所有隐藏状态的信息。 虽然在上图中编码器与解码器中看起来有大量的连接，但是信息瓶颈的问题并没有在这个模型中得到解决。因为在编码器与解码器之间所有的信息传递还是由一个单独的向量 完成的。实际上，由于这个总结向量要现在要传递的信息变得更多了（以前只用传递时刻 $t$ 的隐藏状态中的信息，现在要传递时刻 $0$ 到 所有隐藏状态中的信息），在这个模型中信息瓶颈问题反而变得更加显著了。 这个模型还有一个缺陷 因为我们直接对所有时刻的隐藏状态取平均值，编码器每个时刻的隐藏状态权重都是一样的。这并不符合实际解决问题时的经验 当我们在翻译句子的第 $i$ 个词的时候，我们往往只会关心原句中特定的一两个词。 总结： 对于直接将编码器隐藏状态取平均后传递给解码器的模型，有以下这些优缺点： :+1: 解码器接收到了编码器所有隐藏状态的信息 :-1: 编码器与解码器之间的信息瓶颈问题变得更加显著 编码器每个时刻的隐藏状态权重一样，解码器在解码时没有“重点”。 Attention ｜ 注意力机制 既然直接对所有编码器隐藏状态直接取平均会产生新的问题，那么我们有么有可能给解码器在每一时刻都输入一个独特的，所有编码器隐藏状态的加权平均值呢？这种动态加权平均就是 机制的核心思路 3. 假如解码器生成的序列长度为$n$，我们生成 $n$ 个不同的总结向量，每一个总结向量都是对编码器所有隐藏状态的加权平均 对于解码器的每一个时刻 ，我们都使用不同的权重计算编码器中所有隐藏状态的加权平均，并将计算结果 $c_t$ 与解码器在 $t 1$ 时刻的输出 $y_{t-1}$ 拼接 ( concatenate) 后作为解码器在该时刻的输入。 假设输入序列长度为 $N$，在时刻 输入到解码器中的总结向量 可以这样表示 $$c_t = sum_{i=0}^{N}{w_icdot h_i}$$ 其中 $w_i$ 被称为 注意力权重（Attention Weight）。因为 会“帮助”解码器在解码过程中“集中注意”到编码器的特定隐藏状态上。在下面的例子中，我们让模型将 “我昨天吃了一个苹果” 翻译为英文。可以看到，一个良好训练的模型会通过注意力权重帮助解码器将其“注意力”“聚焦”到编码器特定的隐藏状态上。 4. 注意力权重帮助解码器在编码器所有隐藏状态中“选择性获取”所需的信息 上图的一些解释： &amp;lt;SOS&amp;gt; 表示 “Start of Sequence” 我们使用这个 token 向模型表示“可以开始解码了”。 为了得到英文翻译结果的主语 “I” ，模型获取只需要中文输入的主语 “我” 就有足够的信息了，所以 $c_0$ 的注意力权重只在 输入的隐藏状态 $h_0$ 上有较大权重 要得到英文翻译结果中的谓语 “ate”，解码器不但要知道中文的谓语 “吃” ，还要知道 中文输入的时态 “昨天”（过去），“了”（动作已经完成）。所以 $c_1$ 的注意力权重虽然在 $h_2$ 上最高，在 $h_1$ （“昨天”）与 $h_3$ （“了”） 也显著大于其它值。 注意力机制可以同时解决 模型中的两个主要问题： 信息瓶颈问题 通过不同的注意力权重，编码器与解码器之间会传递 个不同的总结向量。这大大拓宽了编码器与解码器之间的信息通道。 中间信息丢失问题 注意力权重机制理论上允许解码器获得编码器中的任意隐藏状态。 那么，这个能够帮助解码器“集中注意”的神奇“注意力权重”到底是怎么实现的呢？ 的实现与q, K, V表示法 虽然在第一个提出注意力机制的论文 Neural Machine Translation by Jointly Learning to Align and Translate 中，作者并没有使用 query-Key-Value (q, V)的表示方法，将注意力机制真正发扬光大的论文 is All You Need 中提出的 q, V 表示方法一定程度上成为了事实上的“标准”。 中的模型实际上是一种简化的表示方法。在实际实现注意力机制的过程中，我们会让编码器在对每一个输入 $x_t$ 输出一对 Key-value pair $K_t$ 与 $V_t$。对于解码器的每一个隐藏状态 $s_t$，我们会让解码器在输出 $y_t$ 的同时输出一个 query 值 $q_{t + 1}$。 假如我们在解码器输出完第 $t-1$ 个token后有 $$K leftlangle K_0, K_1, cdots, K_m rightrangle$$ $$V V_0, V_1, V_m $$e^t_i g(K_i, q_t)$$ 那么 可以通过这样的方式计算： $$e^t g(k_0, q_t), g(k_1, g(k_m, q_t)rightrangle$$ $$w^t Softmax (e^t)$$ w^tcdot V$$ 写成伪代码的形式，我们有 func compute_context(q: Mat, K: Vec&amp;lt;Mat&amp;gt;, V: Vec&amp;lt;Mat&amp;gt;) e new Vec&amp;lt;float&amp;gt;(m) for t 1:m e[t] raw_attention(q, K[t]) # Function &#39;g&#39; in math above end w softmax(e) c Mat&amp;lt;float&amp;gt; Initialize as a zero tensor += w[t] * V[t] return cend 5. 使用 q，K，V 结构实现的 模型 现在我们离完全实现一个注意力结构只剩下一步之遥了 在上面的伪代码中有一个神奇的函数 raw_attention 给定一个 张量与 Key 张量，这个函数会返回一个浮点数表示分配到这个 所对应的 Value 张量上的注意力权重。 这个函数的实现出人意料的简单：对于两个向量 $K$ $q$，它会返回这两个向量的点乘结果。 $$g(K, q) frac{k_icdot q}{sqrt{dim{k_i}}}$$ 2021/01/11 Update 这里我们在乘法运算完了以后还要对结果进行一个缩放 i.e. 上面公式中除以 $sqrt{dim{k_i}}$ 的步骤。这是为了得到更加平滑的参数梯度。Source 对 Raw Score 进行 而不是直接正则化 ($w_i frac{w_i}{sum_{w}}$) 则是为了让正则化后的结果“大的值更大，小的值更小”，让模型更加稳定（输出的结果更加确定）。Source 2021/01/09 直接将 $q$ 点乘是最简单的 Weight 计算函数，其它函数包括 $$g(k_i, q^{top}Wk_i$$ 其中，$W$ 是一个可学习的参数权重矩阵。 注意力权重的分布：英语-法语翻译模型中的例子 在下图中可以看到注意力权重的值主要分布在对角线上 —— 这是因为英语和法语句子中的语序在很大程度上是相似的。这也证明注意力权重确实可以学习到输入与输出之间的对应关系。 6. 英语-法语 机器翻译模型中的注意力权重"
    },
    {
      "title"    : "NLP 101: Seq2Seq 模型",
      "url"      : "/blog/2021/Seq2Seq.html",
      "tags"     : "NLP, Neural Network",
      "date"     : "2021-12-28 00:00:00 +0000",
      "content"  : "0 四种时间序列问题在与时间序列相关的问题中，我们通过“时序对齐（Alignment）”与“时序同步性（Synchronous）”两个维度将所有问题分为四个不同的类型   **对齐** **不对齐** &amp;lt;img src=&quot;https://markdown-img-1304853431.file.myqcloud.com/Screen%20Shot%202021-12-29%20at%2011.41.39%20AM.png&quot; style=&quot;height: 100px;&quot;/&amp;gt; **同步** 输入时同时输出，一帧输入与一帧输出对应（视频标注） 模型：LSTM，Naive RNN src=&quot;https://markdown-img-1304853431.file.myqcloud.com/Screen%20Shot%202021-12-29%20at%2011.45.28%20AM.png&quot; 100px&quot;/&amp;gt; src=&quot;https://markdown-img-1304853431.file.myqcloud.com/Screen%20Shot%202021-12-29%20at%2011.43.43%20AM.png&quot; **不同步** 输入与输出的顺序相同，但是没有一一对应的关系（语音识别） 输入一个序列，在整个输入完成后输出一个顺序不一定对应的序列 （机器翻译） 模型：Connectionist Temporal Classification (CTC) 模型：**Seq2Seq** 下文提到的 Seq2Seq 模型是处理“不对齐，不同步”序列问题的一种模型。一个典型的不对齐不同步问题是机器翻译。假如我们要让模型将英语 “I ate an apple” 翻译为德语 “Ich habe einen apfel gegessen”，我们会发现翻译结果中的语序和原来并不相同，同时，一些翻译结果并不能与英语中的词汇一一对应到。Fig 1. 机器翻译输入与输出并没有简单的一一对应关系 ｜ 图片来源：CMU 11-785 Lecture 18 page 51 如何确保模型获得了所需的信息？在不对齐不同步问题中，我们不能直接使用LSTM这样的模型，因为在时间序列的 $t$ 时刻，我们并不能确定此时的模型是否已经获得了所有输出正确结果所需要的信息。因此，我们的解决方案是：先处理完所有的输入，将所有输入编码（encode）到一个隐藏状态（Hidden State），然后再逐步对这个隐藏状态进行解码（decode）。通过这样的结构，我们能确定在解码过程中模型一定收到了所有所需的信息。在运行这个模型之前，我们还有两个小问题没有解决 如何让模型知道当前的输入已经结束了，可以开始解码隐藏状态了 一个递归神经网络理论上可以给出无限长的输出序列，我们应该怎样获知模型已经完成了对隐藏状态的解码，并停止接受模型的输出？实际上这两个问题的解决方案是一致的 - 我们可以在模型的词汇表中添加一个特殊的 token &amp;lt;EOS&amp;gt; 这个 代表“End Of Sentence”。当我们向模型输入一个 时，模型就知道当前输入已经结束，并开始输出隐藏状态的解码结果。当模型在解码阶段输出 时，我们就可以获知模型已经完成了对隐藏状态的解码。Fig 2. 一种能够确保模型在输出阶段获得了所有所需信息的模型2 确保解码结果的上下文相关性上面的模型在解决了输入信息完整性的同时还有一个明显的缺陷：在解码阶段中，每一个输出只和当前隐藏状态有关，与之前的输出没有联系。在现实问题中，模型输出的序列一般都会有上下文相关性 也就是说，知道模型在 $t 1$ 时刻的输出会改变模型在 时刻输出的概率分布 $P(w_t mid w_{t-1}) neq P(w_t)$。比如在机器翻译的任务中，如果第 个词是 “an”，那么第 $dark$ 的概率就应该很很低。为了解决这个问题，我们可以将模型在 $t-1$ 时刻的输出作为模型的输入传递到 时刻。这样带来的好处非常明显： 我们可以直接在 时刻与 时刻建立联系 在解码过程中，模型在过去时刻的输出也会被编码到模型的hidden state中，所以模型可以“知道”自己在整个解码阶段中曾经输出过什么内容。Fig 3. 一种能够考虑到解码结果上下文相关性的 Encoder-Decoder 模型在图三这种模型中，接受输入的部分被称为编码器（Encoder）。编码器会“总结”输入内容并将结果总结到自己的隐藏状态中。当编码器接受完整个输入后，其隐藏状态被称为 “Summary Vector”，因为这个张量包含了整个输入的语义。接着，Summary Vector 被传递到了解码器（Decoder）的隐藏状态。解码器会解析传入的隐藏状态并（在这个例子中）给出翻译结果。这样一种由 Encoder 和 Decoder 构成的模型就是我们所说的 模型了。3 模型与词嵌入 我们如何解读解码结果？ Partially Adapted from Lec. Notes P45 P56 词嵌入 (Word Embedding) 是一种将高维度的，使用 One-hot 编码的词汇表嵌入到低维空间的方法。这里泛指用向量表示自然语言。解码器在运行时会输出向量，我们可以通过“查表”的方法将自然语言转化为向量，但是我们如何去解读解码器输出的结果来将向量转化回自然语言呢？为了方便起见，我们在下文中先假设所有词汇都是通过 one-hot 方式编码的。同时，我们使用 $y_t^{A}$ 描述在时刻模型在时刻 输出的向量中表述词汇为 $A$ 的概率。任意一种解读解码结果的目标都是一样的 对于解码器给出的一串向量输出 $y_1, cdots, y_t$，我们要从中找到对应的词汇 $O_1, O_n$ 使得 $P(O_1, O_n x_1,cdots, x_m)$ 最大化。也就是说，我们希望解读方法能够做到下面这样的效果：$$text{argmax}_{O_1, O_n}(y_1^{O_1}cdots y_n^{O_n})$$3.1 贪心算法解读解码结果一种简单的思路是使用贪心算法 在每一时刻 $t$，我们都选择当前输出向量 $y_t$ 所代表的，（相似度）概率最高的词向量 $O$ 作为 $O_t$ 的解读结果。$$DeclareMathOperator*{argmax}{argmax}O_t = argmax_{O_t}(y_t^{O_t})$$然而，这样的方法有一个弊端：如果在时刻 模型的最优输出并不是正确的结果，从 + 开始的每个时刻，模型都会受到这样一个错误输出的影响，最后导致模型“越走越偏”。Fig 4. 直接使用贪心算法对解码器输出进行解读可能导致未来的序列被“误导”3.2 既然不够信息做选择，我全都要！如果因为贪心算法存在上一段描述的缺陷就拒绝使用贪心算法，我们会遇到一个问题：在 时刻做出错误的选择一定会导致整个序列的错误与偏差，但是我们在 时刻并不知道哪个选择是错误的。那么我们怎么解决这个问题呢？ 实际上，我们的大脑每时每刻都在处理同样的问题 自然语言中充斥着模糊性，这种模糊性来自于词法(Lexical Ambiguity)，结构(Structural Ambiguity) 语音(Acoustic 。而大脑在日常交流中在无时无刻的进行去模糊化的动作。用于去模糊化的信息主要来自于对话的上下文和场景。 也就是说 在日常交流的过程中我们的大脑会先保留时刻 的语言模糊性，等到积累了足够的上下文后再对 时刻的结果进行去模糊化操作。也许相似的过程也能用在我们对 模型的输出解读上！既然我们在时刻 无法得知足够的信息来做出选择，那么我们就不做出选择 直到我们积累了足够多的信息来做出选择我们再返回来 时刻进行决择。在每个时刻，我们选择概率最高的$n$个词向量作为对解码器在 时刻输出的解读。我们将解码器 “分叉到不同的时间线”上 在每个分叉中，我们使用不同的词向量作为 时刻的解码器输入。Fig 5. 每一个时刻，如果概率最高的两个解读结果概率差距不大，我们可以将解码器“分叉”，在不同的assumption 上继续推理并在未来回溯至该时刻进行选择当模型在某个分支上输出了 这个特殊的token时，这个分支就结束了。因为 是约定的结束解码器输出序列的标志符。Fig 6. 解码器每个时刻因为对解码结果的不同解读产生不同的分叉。每个分叉在输出&amp;lt;EOS&amp;gt;时结束当解码器所有的分支都结束输出以后，我们可以对每一个分支输出的序列进行评估并在其中选择最优的序列。 因为分支的数量随序列长度成指数上升，这里我们一般会在评估时使用一种叫 Beam Search 的启发式搜索算法对需要评估的分支进行剪枝。4 模型的训练在训练 模型时，我们不用对模型在编码阶段的输出做任何评估。我们只需要对比模型在解码阶段给出的输出即可。在训练阶段，我们并不会将解码器在 时刻的输出作为输入传输给 时刻（我们在模型推理阶段会这么做来建立模型输出的上下文联系）。我们会直接将正确的 ground truth 中的第 时刻的内容作为输入传输给 时刻。Fig 7. 训练阶段的 模型，梯度沿紫色箭头路线反向传播在训练阶段中，如果我们选择 SGD 作为优化方法，我们可以这样训练模型： 随机在训练集中选择一个 (input, output) 数据 使用这个数据让模型进行前向计算 随机选择模型在解码阶段的一个输出进行 Loss 计算并进行反向传播 更新模型权重参数5 的缺陷与改进方法Seq2Seq 模型到现在依然是解决非同步非对齐序列预测问题的经典模型之一。然而，它的结构存在一个缺陷 这个缺陷会在模型接受长输入序列时被暴露无遗。注意到图3中的编码器-解码器模型。在这个模型中，编码器与解码器只通过隐藏状态（总结向量）连接起来。这直接导致了两个问题： 当输入序列较长时，这个隐藏状态可能无法完全容纳输入中蕴含的所有信息量，从而导致模型接受信息的损失。【编码器与解码器之间的连接太狭窄，无法传递所有信息】 如果输入序列较长，一些信息可能会在编码器接受新信息的过程中被“稀释”，这可能会导致解码器遗漏输入中的关键信息。【编码器中所有的隐藏状态都含有独特的信息，但是只有最终状态被传递给了解码器】而这两个问题的解决方案则是目前大有一统 CNN，RNN，多模态学习 之势的 Transformer 模型的底层结构 注意力机制（Attention Mechanism）"
    },
    {
      "title"    : "Batch Normalization 浅入深出",
      "url"      : "/blog/2021/Batch-Normalization.html",
      "tags"     : "Neural Network",
      "date"     : "2021-12-26 00:00:00 +0000",
      "content"  : "0 符号表 符号 意义 $nabla_{W}f$ 函数 $f$ 关于变量（集合）$W$ 的梯度 $N$ 训练集中数据总量 $C$ 损失函数（Cost Function），对于给定模型输出 $hat{y}$ 与目标输出 $y$ 进行差距评估 $f(x, W)$ 拥有权重参数 $W$ 神经网络对于输入 $x$ 的输出 $D$ 目标函数（Ground Truth） $X$ 训练数据集 $X’$ 训练数据集中的一个 mini-batch， $X’subseteq X$ 1 Mini-Batch 增量训练法与协方差问题在进行神经网络训练的过程中，我们使用以下公式计算神经网络的权重参数梯度$$nabla_{W} L(W) = frac{1}{N}sum_{x}{nabla_{W}C(f(x, W), D(x))}$$对于训练集中的每一个数据 $x$，我们都计算出权重参数的梯度，将他们相加后除以$N$得到一个“平均梯度”。因为（我们假设）训练集中的数据分布于生产/测试环境一致，当使用整个训练集的结果进行梯度计算和参数更新时，网络 能够更加准确的拟合到完整的目标函数 上，而非目标函数 一部分特殊的定义域上。Fig 1. 当训练集数据分布与测试集不同时（右图），模型拟合结果会显著降低然而，这样的参数更新方法虽然能够最大化模型的拟合准确率，由于每次进行参数更新前必须得知训练集中所有的输入 对应的损失函数 $C(f(x, D(x))$ 和权重梯度 $nabla_{W}C$，模型的权重更新速度会非常缓慢。为了解决这个问题，我们可以使用 Mini-batch 增量训练方法。每次我们从一个拥有 个数据的训练集中随机，不重复的选择 $B$ 个数据作为一个 Batch。得到这 个数据的损失函数和对应的梯度后，我们马上对模型进行一次参数更新。Fig 2. 使用 mini-batch 方法训练的模型更新参数的频率有显著提升可惜，天下没有免费的午餐，当我们使用 来训练神经网络的时候实际上我们有一个隐含的假设：mini-batch 中的数据分布于训练集相同。$$text{argmin}{W}{left( sum{xin X’}{C(f(x, D(x))}right)}Leftrightarrowtext{argmin}{W}{left( X}{C(f(x, D(x))}right)}$$上面这两个最优化目标只有在 （Mini-batch 中的数据） 与 （Training Set 的数据分布一致时才是一致的。然而这个假设在很多情况下是不成立的。mini-batch 中的数据可能会有较大的协方差 (Covariance) - 也就是说，当前 的数据分布与训练集的数据分布并不相同。数据分布的差异会导致模型在优化权重参数时的目标 “最优化模型在当前 上的表现” 这个目标与我们真正的目标 —— “最优化模型在训练集上的表现”之间的偏差。Fig 3. 当我们训练模型时，我们构建的逻辑链条2 Batch Normalization 理论为了解决这个问题，Sergey Ioffe 和 Christian Szegedy 在 2015 年提出了 （下文简称BN）的方法。BN 的理解实际上很简单 我们可以将所有的 移动到一个特殊的位置 ($mu 0$, $sigma =1$)，来“正则化（Normalize）” mini-batch，让所有的 拥有一致的数据分布。然而，如果 BN 只有这一步，我们会不可避免的丢失数据本身的部分信息 训练集本身的平均值与方差。对于一个训练集 $X$，我们可以求出其平均值 $mu_X$ 与方差 $sigma_X$。这两个数据本身也是数据集的信息之一。为了解决这个问题，我们要向BN中添加两个可训练的参数 $gamma$ $beta$。在将mini-batch正则化后，我们通过计算 $gamma x + beta$ 把所有的 batch 统一移动到 $mu beta$，$sigma gamma$ 的位置。Fig 4. 的正则化过程可以分为三步：1. Centering （$mu=0$）2. Scaling ($sigma 1$) Moving （$mu beta$, gamma$)通过BN的操作，我们可以尽可能减小 中数据分布与训练集的不一致性，a.k.a 的协方差。3 实现Fig 5. 一个使用了BN的神经元，可以看到BN实际上是在每个神经元中对输入加权&amp;amp;偏置的值进行正则化可以将 看作插入在神经元中的一个中间件。图5中的蓝色变量都是神经网络 中可训练的参数集合 中的变量。如果我们用计算图的形式表现变量之间相互依赖的关系，我们会得到下面这样一张计算图：其中，我们有$$mu_B frac{1}{B}sum_{i=1}^B{z_i}$$$$sigma^2B frac{1}{B}sum{i=1}^B{(z_i mu_B)^2}$$$$u_i frac{z_i u_B}{sqrt{sigma^2_B epsilon}},quadtext{Where }epsilontext{ is a smooth factor}$$$$hat{z}_i gamma u_i beta$$4 反向传播数学推导 Adapted from CMU 11785 Lecture 8 Notes假设我们现在已知 $nabla_{hat{z}} C(f(x, D(x))$，我们希望让这个梯度通过含有 的神经元，反向传播到 $nabla_x D(x))$，那么我们需要计算 $frac{partial C}{partial x_1}$，… ，$frac{partial x_n}$。根据偏微分的链式法则，我们知道$$frac{partial x_1} sum_{i=1}^{n}{frac{partial hat{z}_i}frac{partial hat{z}_i}{partial x_1}}$$不失一般性的，因为在神经元的计算中，每一个 分量的计算都是相同的，我们可以通过计算 x_1}$得出计算 x_i}$ 的通项公式。所以在下文中，我们会以计算 $x_1$ 的梯度为例子进行计算与推导。因为从 $u_i$ 开始，向量中的每个分量都是单独计算的，我们可以得知对于任意 $ineq j$，我们有 $partial hat{z}_i /partial u_j 0$：$$frac{partial u_i} sum_{j=1}^n{frac{partial hat z_j}frac{partial z_j}{partial u_i}} frac{partial z_i}frac{partial z_i}{partial z_i}cdot gamma$$4.1 BN中的直接连接反向传播公式推导重新回顾一下之前的BN计算图，我们不难发现 $z_1$ 的值计算到 $u_1$ 有三条不同的路线。我们需要计算 {u_i}/{partial z_i}$ 时，需要计算三条路线上的微分并相加起来。$$frac{partial u_1}{partial z_1} mu_B}frac{partial mu_B}{partial sigma^2_B}frac{partial sigma^2_B}{partial z_1}$$对于上式第一项（计算图中的黑色路线），$partial u_1/partial z_1$，这里的直接连接来自于公式$$u_i epsilon}}$$所以我们可以直接计算出$$frac{partial frac{1}{sqrt{sigma^2_B epsilon}}$$对于第二项（计算图中的蓝色路线），我们需要分别计算单独一个 对整个 的平均数 $mu_B$ 的偏导数以及平均数 对于BN结果 的偏导数。因为我们有$$mu_B frac{1}{B}sum_{i=1}^B{z_i}$$不难得出$$frac{partial frac{1}{B}$$同时，对于 mu_B/partial u_1$，我们有$$u_i epsilon}}$$所以有$$frac{partial mu_B} -frac{1}{sqrt{sigma_B^2 epsilon}}$$将两个偏导数乘起来，我们就能得到计算图中蓝色路线的反向传播公式：$$-frac{1}{Bsqrt{sigma_B^2 epsilon}}$$对于第三项（计算图中的紫色路线），我们需要分别计算两条“支路”的偏微分之和$$frac{partial u_i}{partial sigma^2_B}left( z_1}right)$$从 的计算公式，我们可以得知$$frac{partial sigma^2B} }{partial sigma^2_B}frac{z_1 epsilon}} -frac{z_1 mu_B}{2(sigma_B^2 epsilon)^{3/2}}$$因为有方差$sigma_B^2$的计算公式$$sigma^2B mu_B)^2}$$我们可以得知 sigma_B^2 / partial z_1$$$frac{partial sigma_B^2}{partial z_1}frac{(z_1 mu_B)^2}{B} 2frac{z_1 mu_B}{B}$$同时，我们有$$frac{partial frac{1}{B}sum_{i=1}^B{-2(z_i mu_B) -frac{2}{B}left(sum_{i=1}^B{z_i} sum_{i=1}^B{mu_B}right)} 0$$因此，计算图中的紫色路线的反向传播公式是：$$-frac{z_1 epsilon)^{3/2}} cdot mu_B}{B} -frac{(z_1 mu_B)^2}{(sigma_B^2 epsilon)^{3/2}B}$$将三条路线的反向传播公式相加，我们就能得到“直接连接“的反向传播公式$$frac{partial z_i} -frac{1}{Bsqrt{sigma_B^2 mu_B)^2}{B(sigma_B^2 epsilon)^{3/2}}$$4.2 中的跨越连接反向传播公式推导对于跨越连接（$partial u_i/partial z_j$, where j$），计算图中只有蓝色与紫色两条路径，所以我们有$$frac{partial z_j} begin{cases}frac{1}{sqrt{sigma^2_B &amp;amp; i=j-frac{1}{Bsqrt{sigma_B^2 ineq jend{cases}$$"
    },
    {
      "title"    : "NLP 101: Word Embedding 词嵌入",
      "url"      : "/blog/2021/Word-Embedding.html",
      "tags"     : "Machine Learning, NLP, Neural Network",
      "date"     : "2021-11-24 00:00:00 +0000",
      "content"  : "什么是词嵌入在处理自然语言时，模型的输入是文本字符串，然而，我们并不能对字符串进行运算操作。为了解决这个问题，我们尝试将自然语言的词汇转换为一个连续向量空间中的向量。这个过程被称为“词嵌入“。用更加形式化的语言来描述，词嵌入的过程可以这样表达：$$text{Natural Language} rightarrow mathbb{R}^n$$用 One-hot 编码进行词嵌入？一种符合直觉，也是最简单的词嵌入方法是使用 编码。One-hot 编码指一个 $1times n$ 向量中只有一个分量为1，其它分量都是0。比如说我们现在想将四个单词构成的词汇表转化为向量空间，我们可以这样做：$$begin{aligned}text{Nice} &amp;amp;rightarrow [1, 0, 0]text{to} [0, 1, 0]text{meet} 0]text{you} 1]end{aligned}$$但是这样有几个很明显的坏处： 如果我们的词汇表中有 10,000 个单词，作为映射目标的向量空间会拥有 个维度。这会导致任何试图对词向量进行运算的尝试都需要极大的计算量，也就是常说的“维度灾难”问题 在进行完词嵌入后，词语的“意思”被完全丢失了。在进行完映射后，任何词语之间的向量距离都是相同的。一个理想的映射应该在进行完词嵌入后尽可能的保留词汇本身的信息。比如我们会希望代表 “my” 和 “me” 的词向量之间的距离小于代表 “sun” 的词向量之间的距离。使用神经网络“拟合”词嵌入函数为了解决这些问题，我们可以使用一种新的 approach。假设存在一个理想的函数 $f$ 能够将自然词汇映射为一个有意义的词向量。我们可以训练一个神经网络来拟合这个函数但是这引入了一个新的问题 - 神经网络在训练过程中需要一个明确定义的损失函数来进行反向传播与参数更新。然而我们是不知道最佳词嵌入函数的输出的，也就是说如果直接拟合词嵌入函数的话我们没有 Ground Truth / Labeled Data解决这个问题的方法非常简单：我们先给神经网络一个已经 well-defined 的问题来进行训练，然后使用训练好的模型在推理阶段来创建自然语言到词向量空间之间的映射。在寻找词嵌入这个问题上，我们可以在训练阶段给定模型上下文（context）让模型预测在一个特定位置的词的概率分布。NNLM 第一批试图解决NLP问题的神经网络用NNLM预测词汇序列NNLM 是 “Neural Net Language Model” 的缩写。这是第一批用来解决自然语言处理问题的神经网络模型之一。NNLM 一开始的目的是给定第$n$个到第$n + k 1$个词汇 ，预测第 $n k$ 个词汇的概率分布。一个NNLM模型由三个部分组成： 使用一个参数矩阵 $C$ 将 编码的词向量转换为 $mathbb{R}^n$ 向量空间中的一个向量 将上一步得到的词向量拼接起来，我们可以得到一个“上下文”向量 $x$。通过一个非线性的隐藏层 $b Wx tanh{(b_2 W_2x)}$的计算，我们会得到在 位置的词汇“概率分布”。这里的“概率分布”打了引号因为这时候的向量并不满足一些概率分布的特征：比如各个分量都为非负数且相加之和为1。 为了将最后输出的向量变成真正的概率分布，我们需要用 Softmax 函数处理（正则化）这个向量 NNLM 构建词嵌入然而，正如在前文所说的一样，训练好的NNLM 实际上表示着一种创建词嵌入的函数。假如我们的词汇表只有四个单词 “Once”, “upon”, “a”, “time”，我们现在给定 “upon” “a” “time”，想预测 “there” 这个位置的词汇。“Once upon a time there …”这个词汇并不在我们的词汇表中，这种情况下，我们可以将这个词的词向量以“预测结果的词向量的加权和”来定义：$$C(j) leftarrow sum_{iin V}{C(i)P(i mid w_{t-n+1}^{t-1})}$$下面是一个描述这种构建方法的 toy demoWord2Vec 模型在Word2Vec 论文中，作者建立了两种不同的神经网络模型来进行词嵌入。Word2Vec CBOW 模型CBOW “Continuous Bag of Words” 的缩写。这是一种用目标词汇周围的单词进行采样的词嵌入模型。这个模型是基于 的基础上进行改进得到的，它与NNLM不一样的地方主要有两点： CBOW为了预测 $t$ 位置的单词，这个模型会接受 周围的单词 $t-1$, $t-2$,…, $t+2$ 位置的词汇，而 只会接受 之前的单词。 中在第二部里面会将所有的词向量拼接起来，而 会对这些词向量进行按位相加。因为加法是满足交换律的，所以这些输入的词汇的顺序是无关紧要的。这也是为什么这个模型叫做 “Bag Word” 词汇的顺序是无关紧要的。 通过和 一样的方法，我们可以从训练好的 模型中获得自然语言与词向量空间之间的映射关系。Word2Vec Skip Gram 模型Skip 是一种和 完全相反的模型 给定第 $k$ 个词，Skip gram 模型会预测这个词周边的词的概率分布。CBOW 还是 Gram?在论文中，作者表示 Skip-gram 模型在小数据集上表现更好，而且对于词频较低的词汇依然能够较好的提取词向量。而 的训练速度普遍高于 并且对于高词频词汇的词向量估计质量更高。词嵌入真的能够保留词汇的意思吗？我认为是可以的！这里是一个论文中举的很神奇的demo：vec(&quot;king&quot;) vec(&quot;man&quot;) vec(&quot;woman&quot;) = vec(&quot;queen&quot;)也就是说，当你将 “king” 的词向量与 “man”的词向量相减后，你会得到一种表示类似”王权“语义的词向量，当在这个语义的基础上加上表示女性的词向量你就会得到 “queen”。参考材料https://arxiv.org/pdf/1301.3781.pdfhttps://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314https://www.baeldung.com/cs/word-embeddings-cbow-vs-skip-gramhttps://zhuanlan.zhihu.com/p/206878986https://www.youtube.com/watch?v=kEMJRjEdNzM&amp;amp;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z"
    },
    {
      "title"    : "MAGC Map Structural Design",
      "url"      : "/blog/2021/magc-map-intro.html",
      "tags"     : "Web",
      "date"     : "2021-10-06 00:00:00 +0000",
      "content"  : "AboutThis project is one of the HackCMU 2021 projects. The MAGC Map won 3rd prize in 2021. DevPost LinkWhat MapThe a non-linear structured knowledge map that support real-time collaboration.Technical DetailsWe use traditional client/server structure for this project.The client will run directly on browser through JavaScript and maintain GUI animation.The server written Flask (Python 3) store dataPage StructureHome Page | |-- Board 1 Node 2 Message Block 3 ...Data StructureEach board stored as json file format{ &quot;nodes&quot;: [ { &quot;id&quot;: &quot;string (uuid4)&quot;, &quot;label&quot;: &quot;Label Of Node&quot;, &quot;styles&quot;: &quot;color&quot;: &quot;CSS-like color string&quot; }, &quot;block&quot;: &quot;content_id1&quot;, &quot;content_id2&quot; ] } ], &quot;edges&quot;: &quot;from&quot;: &quot;nodeID1&quot;, &quot;to&quot;: &quot;nodeID2&quot; &quot;contents&quot;: &quot;content_id1&quot;: &quot;type&quot;: &quot;markdown&quot;, &quot;content&quot;: &quot;This an **Example**.&quot; &quot;content_id2&quot;: &quot;Another $LaTeX$ Example.&quot; }}Update Protocol v2This protocol defines how (browser) communicate with server.Protocol Format{ &quot;version&quot;: (uuid)&quot;, &quot;operation&quot;: {ADD, DEL, MOD, SYC, NOP, NEW}&quot;, &quot;property&quot;: {node, edge, content}&quot;, &quot;value&quot;: &quot;string&quot;, &quot;src&quot;: [Board Name]&quot;}Protocol Operation DefinitionIn following passage, we call node, content Client to Server ADD Ask add new entity require DEL Remove from storage expired MOD Modify (overwrite) SYC Request sync Provide later versions NOP – Do nothing, already up-to-date NEW Create Completely Reload JSON File refresh all (since 100+ version behind server) Lock System (Conflict Avoiding Access Control)To synchronize changes between users resolve conflicts relatively simple way, Mutex Locks message block.This means each block can have at most user editing same time.Step1 - When click ‘edit’ block, try acquire lock POST method route lock.Step 1a If successfully acquired, function enable block.Step 1b occupied, deny request edit current editing, status locks are server. At time, other tried be denied.Step 2a While send XML ‘renew’ every three minutes. reason design ‘renew system’ described detail step 3a.Step ‘Finish Edit’, update data using Update Protocol. After receiving protocol, release corresponding automatically.Step 3a To avoid dead case gets off-line before hitting Edit’. We specially designed series policy’ lock. For 5 minutes, scan over locks. any not renewed more than released automatically.Synchronize SystemTo server, developed system allows Incremental Update.Each time info v2, implement push payload into stack called cacheStack size 100.Every minute, v2 operation SYN. number also included reactions: equals latest return NOP. This no further action required. smaller but bigger oldest cacheStack. list Protocols sequence old new. then execute by processing sequentially. protocols processed, cacheStack, NEW. In case, automatically reload whole window fetch"
    },
    {
      "title"    : "Uniswap 3 - Always profitable for Liquidity Provider?",
      "url"      : "/blog/2021/uniswap3-3.html",
      "tags"     : "Cryptocurrency, Decentralized Finance",
      "date"     : "2021-09-26 00:00:00 +0000",
      "content"  : "引子：Uniswap是一门稳赚不赔的买卖吗？在前文中，我们提到 Uniswap 的流动性提供者会将两种代笔放入协议中，在保证两种代币的数量之积不变的情况下接受代币兑换从而提供代币间的流动性。每笔使用流动性池子进行的代笔兑换都会给流动性提供者支付 1% - 0.05% 不等的手续费。看起来似乎自动做市商（AMM）们可以通过手续费稳赚不赔了？实际上并不然——也许你还记得在之前文章中提到过，Uniswap 保持代币兑换价格与市场价格的一致性是通过鼓励套现实现的。Uniswap 与市场价值的同步在 的流动性池子中，代币之间的“汇率”总是随着交易的进行而改变。当Uniswap协议中的当前汇率与市场实际汇率不同时，参与者会通过两侧的价差进行套利，在这个过程中帮助Uniswap汇率与实际汇率同步变化。流动性提供者的损失假设一位流动性提供者在 1ETH = 100 USDT 时 ETH 流动性池子提供了1 + 的流动性资产，现在池子的总资产为 10,000 USDT，流动性提供者占有池子1%的比重当前uniswap协议参数：k ETH_Pool * USDT_Pool 1,000,000ETH_Price / 100ETH_Pool= sqrt(k/ETH_Price) 100USDT_Pool sqrt(k ETH_Price) 10,000假设这时候，市场价格出现波动……现在 1 120 USDT根据 的常数积特性，$k$ 值不变k 120ETH_Pool 91.2871USDT_Pool 10954.45由于 1USDT 几乎等同于 1USD，我们不妨将池子中的所有资产换算为 USDT现在流动性提供者在合约中的资产实际为：91.2871 109.5445 219.08902$然而，如果流动性提供者不将手上的资产放入Uniswap协议中，现在 与 的实际价值将是：120 220$也就是说，市场价格的波动实际上让流动性提供者亏损了 220 219.08902 0.911$ 的资产。这部分损失被称为“无常损失”，又称为“分歧损失”（因为这个损失是由市场与Uniswap协议之间的价格分歧导致的）实际上，这部分损失也就是前文所讲的“Uniswap 鼓励交易者在出现价格分歧时套利”时的“利”。$$text{Divergent Loss} 2timesfrac{sqrt{text{Price Proportion}}}{1 text{Price Proportion}} 1$$上图中，纵轴表示价格的比值 当前价格与向流动性池子中投入资产时价格的比值，横轴表示分歧损失占总资产的百分比。蓝线描述了分歧损失是如何随着价格的波动而增大的。黄线，绿线和红线分别表示 0.05%， 0.3% 和 这三个Uniswap中常见的手续费位置。也就是说 如果你要在 中稳赚不赔，需要价格波动幅度在一个固定的区间内 协议手续费 价格波动区间 75.2745% ~ 132.8471% 85.6318% 116.779% 93.8701% 106.5302%"
    },
    {
      "title"    : "SQL - Basic Query, Union and Inner Join",
      "url"      : "/blog/2021/sql-lecture-1.html",
      "tags"     : "Notes",
      "date"     : "2021-09-21 00:00:00 +0000",
      "content"  : "SQL = Structured Query LanguageWe use query to poll data from databaseQuery and Select with SQLSQL - just write the queryin SQL, we usually CAPITAL distinct keyword out. Generally, put a newline before each KEYWORD make easier readSELECT QuerySELECT [data] FROM [tableName];Select all columnsSELECT *FROM cs_data;This will return whole table (all columns)Select Multiple ColumnsSELECT Col1, Col2 table_name;Use ORDER Sort DataSELECT [colName]FROM [DataTableName]ORDER BY [colName2] {ASC, DESC};database columns given by [colName] [DataTableName]. Then, sort rows value on in Ascending Rank if ASC Descending DESC Example SELECT cs_dataORDER Language ASC; We can introduce “tie breaker” appending several sorting conditionsSELECT ASC, [colName3] DESC;Get colName DataTableName, then colName2 ascending order. If there are same rank, them of colName3 descending order.Limit Rows returned LIMIT keywordSELECT Rating DESCLIMIT 3;The above code get top 3 CS coursesGet Distinct values database DISTINCT LanguageFROM cs_data;SELECT [col1], [col2]FROM [table_name];SELECT Type, ColorFROM food_dataORDER Type ASC;Get possible Color arrange order respect Type.Filter using WHERE KeywordSELECT [table_name]WHERE [col_name]=[value];Besides WHERE, also boolean operations between conditions for instance AND, OR NOT.Example cs_dataWHERE Language=&quot;C&quot; AND &amp;gt;= 4; Conditioning LIKE Keyword% Pattern Matching (“Star”)%STR Represents condition that String end “STR”123% Represent start “123”%ABC% contain “ABC” inside it_ (“Wildcard”)a_c represent pattern some string ends c single char thema_c -&amp;gt; abc, a+c, …Get vegetables name doesn’t c:SELECT food_dataWHERE Type=&quot;vegetables&quot; NOT Name &quot;c%&quot;;Operations SQLAlgorithmic OperationsSELECT Number % 1000, ROUND(Hours) cs_data;Return where property is mod 1000 Hours roundedAlias AS keywordUsing AS, give column ‘nickname’SELECT ShortNumberFROM cs_data;Getting Sum Avg SUM, AVG COUNT COUNT(*), SUM(Hours), AVG(Rating)FROM language &quot;Python&quot;;COUNT(*) counting rowsGrouping GROUP Language, Count(*), cs_dataGROUP Language;Use JOIN UNIONCombine Results UNIONSELECT cs_tableUNIONSELECT b cs_tableIf UNION, repeated result be removedIf UNION ALL, reservedCombine Data Different Table JOININNER ... ON... combine conditionSELECT NAME, SUM(CostPerPound * Pounds) TotalCostFROM order_dataINNER price_dataON order_data.OrderID price_data.FoodIDGROUP Name;Creating variables CREATE VIEWYou create variable as specific view VIEW command."
    },
    {
      "title"    : "2048 Project (1)",
      "url"      : "/blog/2021/2048-Project-1.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-09-14 00:00:00 +0000",
      "content"  : "The 2048 ProjectWe try to use Artificial Intelligence, Machine Learning, and traditional algorithms create a bot that out-performs human when playing 2048BenchmarkHow evaluate one game: sum of all numbers in the state game is overBelow data: Let each agent play 2,000 games calculate summary statistics from scores.   Std. Med Mean Max Min Greedy Agent 193.1929 526 549.5292 1254 122 Genetic Algorithm 222.4283 538 564.619 1730 142 Tree Evaluate Agent* 337.8625 1016 1006.532 2096 212 * Under sampling setting (True, 3) depth max(4, 7 - len(get_empty_tile(self.state)))Agents DeployedGreedy AgentGreedy always choose action can merge most amount tiles.Genetic AgentGenetic will an based on three factors Factor Description Empty Tile Number $w_1 $ number empty tiles $w_2$ maximum Action Preference $b_1$ Agent’s own preference (up, down, left, right) $$Evaluate(a, s) = w_1cdot EmptyTile + w_2 cdot MaxTile b_1$$Tree AgentTree function tree_evaluation action.def tree_evaluation( state: List[List], evaluate_fn, comb_fn, depth: int, sampling: Tuple[bool, int] (False, 0), useMultiProcess: bool False, gameOverScore: float 0):The process be described four parts: Sampling Creating possible states for action. There are two types enumerate random. detail later section. Evaluating If reach 0, leaf using given parameter evaluate_fn. Combine evaluations then record combined score as Maximize For state, return max 4 actions this state.SamplingThere random deterministic.When sampling, first value True. In case, n by generating times (n second element parameter).When determinstic false.In states."
    },
    {
      "title"    : "Uniswap 3 - Starting from Uniswap v1",
      "url"      : "/blog/2021/uniswap3-2.html",
      "tags"     : "Cryptocurrency, Decentralized Finance",
      "date"     : "2021-08-20 00:00:00 +0000",
      "content"  : "Uniswap v1 是什么Source The V1 Protocol ERC-20 Token StandardUniswap 是由一系列 ETH-ERC20 交换协议构成的 什么是 ERC20 代币？ 是一种描述可交换代币的以太坊标准 这个标准为以太坊上的可交换代币的智能合约提供了统一的 API - Link: Standard如何使用 Factory 为 生成 Protocal每种 代币有且只有一个 协议。如果一种代币没有 协议，任何人可以使用 factory contract 来为代币生成一个 协议。流动性贡献者的贡献比例计算方式每一个智能合约会保存以太坊和相关联的 代币。每个人都可以通过向智能合约贡献资产成为流动性贡献者之一。与一般的买卖双方市场不同，流动性贡献者需要提供等价的以太坊和 代币。一种内置的 代币 （池子币, Pool Token）被用来记录每个流动性贡献者的贡献比例。 当流动性贡献者将资产加入 流动性池子时，池子币会被“铸造 (mint) ” 当流动性贡献者将资产从流动性池子中取出时，池子币会被“销毁 (burn) 是如何工作的Sources 🦄 Whitepaper HackMDETH ⇄ 交易每一个 ETH⇄ERC20 的流动性池子都由一个 协议控制，Uniswap 协议约束流动性池子中的 ETH 与 资产之乘积是一定的。sizeof(eth_pool) * sizeof(token_pool) = K, where K is constant例子： 一个 流动性池子中，有流动性提供者供给的 10 和 500 OMG （一种 ERC20）代币。每一次自动做市商AMM的交易都会收取 0.3% 的手续费$$text{ETH pool}times text{OMG pool} K$$$$K=ETH times 5000$$这时候，一个交易者向流动性池子给出 1 买方给出 手续费 0.00333 流动性池子中的以太坊资产 + 10.99667 流动性池子中应有的 资产 5000 / 454.68309 应该给到买方的 45.31691 OMG这时候流动性池子已经达到了新的平衡 (K 5000)，然后我们把 的手续费自动注入流动性池子…… 11 新的乘积常数 5001.51399可以看到，随着手续费的注入，池子的规模又扩大了一点。ERC20 交易当使用 交换两种 时， 会将第一种 token 换成 ETH，再在第二个池中将 换成第二种 Token交换(Swap) vs 转换(Transfer)Swap 会将兑换后的结果直接返回给原账户Transfer 可以将兑换完的 给到指定的新账户提供流动性增加流动性添加流动性需要向 的 合约添加相匹配的 代币。前文提到 使用 Token）来计算流动性池子中每一个流动性提供者的贡献。Uniswap 中向合约注入资产的 Py-EVM 代码@public@payabledef addLiquidity(): token_amount: uint256 msg.value token_pool eth_pool liquidity_minted: total_liquidity eth_added: shares_minted: (eth_added self.total_shares) self.eth_pool tokens_added: (shares_minted self.token_pool) self.shares[msg.sender] shares_minted self.total_shares eth_added self.token_pool tokens_added self.token.transferFrom(msg.sender, self, tokens_added)每次向 合约注入资产时都会触发 的铸造（Mint），Pool 的铸造数量遵循此公式：$$amountMint=TotalAmount frac{ethDeposited}{ethPool}$$向 合约注入 后必须维持合约的乘积恒等式，所以应该注入的 数量可以这样计算：$$tokensDeposited tokenPool frac{ethDeposited}{ethPool}$$移除流动性当流动性提供者从 合约中撤回自己投入的资产时，我们称其“移除了流动性”当流动性被移除时, 会被焚毁 (Burn)"
    },
    {
      "title"    : "CS188 Chapter 15 Probabilistic Reasoning over Time",
      "url"      : "/blog/2021/CS188-Chapter15.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-08-15 00:00:00 +0000",
      "content"  : "In which we try to interpret the present, understand past, and perhaps predict future, even when very little is crystal clear.belief state that represents states of world are currently possible. From belief a transition model, agent can how might evolve in next step.From information from sensor agents update state.In previous section, only tell possible, but can’t say likely or unlikely. this quantify degree state.15.1 Time UncertaintyIn have talked about Bayesian Network. network perform probabilistic reasoning static world. The value random variable at each moment independent with its value.However, many scenarios, DO influence current state. To utilize such information, use model called Markov chain.15.1.1 States observationsWe view as series snapshots (a.k.a. time slices not continuous)$mathbf{X}_t$ denote set variables $t$$mathbf{E}_t$ observable evidence $t$$mathbf{E}_t = e_t$ where $e_t$​ observed for variable.We will assume sequence starts $t=0$ arriving $t=1$.15.1.2 Transition Sensor ModelsTransition specifies probability distribution over latest given values, is,$$mathbf{P}left(mathbf{X}t mid mathbf{X}{0:t-1}right)$$However, leads problem: $xrightarrow infty$, size $mathbf{X}_{0:t-1}$ has an unbounded size. solve problem, introduce Assumption. AssumptionMarkov process memoryless, means Current State depends on finite fixed number states.Process satisfying assumption Process Chains.First Order - $mathbf{X}_{t}$ related $mathbf{X}_{t-1}$​$$mathbf{P}(mathbf{X}mid mathbf{X}_{0:t-1}) mathbf{P}(mathbf{X}mid mathbf{X}_{t-1})$$Beyond first-order process, there second, third, …, n-th order Process.N-order Process$$mathbf{P}(mathbf{X}mid mathbf{X}{0:t-1}) lbracemathbf{X}{t-1}, mathbf{X}{t-2}, cdots, mathbf{X}{t-n}rbrace)$$Therefore, conditional $mathbf{P}(mathbf{X_t}mid mathbf{X}_{t-1})$Besides Assumption, also stationary. At any $t$, mathbf{X}_{t-1})$ same.Stationary Assumption$$mathbf{P}(mathbf{X_m}mid mathbf{X}_{m-1})equiv mathbf{P}(mathbf{X_n}mid mathbf{X}_{n-1}) forall m, n$$During learn status through sensor. sensors read give us number. Therefore, it’s safe thatSensor Assumption$$mathbf{P}(mathbf{E}_tmidmathbf{X}_{0:t}, mathbf{E}_{0:t-1}) mathbf{P}(mathbf{E}_t mathbf{X}_t)$$$mathbf{P}(mathbf{E}_t mathbf{X}_t)$ Model, sometimes Observation Model.15.1.3 Stationary ModelIn most cases, exists stationary is, some $mathbf{X}_ t$ $mathbf{P}(mathbf{X}_ t) mathbf{P}(mathbf{X}_ {t+1})$The converge case.15.1.4* Improve Model?Generally, two methods increase precision Model: Increase Model variables.By increasing multiple ticks calculate $t$.Increasing always be reformulated variables.15.2 Inference Temporal ModelsThere four basic inference tasks must solved generic temporal model: Filtering computing Belief posterior recent all date. $$mathbf{P}(mathbf{X_t}mid e_{1:t})$$​ With filtering, keep track make rational decisions. Prediction future state, $$ mathbf{P}(mathbf{X_{t+k}}mid e_{1:t})$$ useful evaluating possible courses action based their expected outcomes. Smoothing past up present. mathbf{P}(mathbf{X}kmid e{1:t}) , text{where }1 leq kleq t$$ provides better estimate than was available time, because it incorporates more evidence. Most explanation Given observations, wish find generated those observations. text{argmax}{mathbf{x}{1:t}}P(mathbf{x_{1:t}mid e_{1:t}})$$ 15.2.1 PredictionFilteringFiltering algorithm should compute {t+1})$ tmid e _ {1:t})$ new $mathbf{P}(e_ {t+1})$.$$mathbf{P}(mathbf{X}{t+1}mid e{1:t+1}) f(e_{t+1}, mathbf{P}(mathbf{X}{t}mid e{1:t}))$$For function $f$, recursive estimation.Below, reformulate filtering ways describe using etc. Split $e_ {1:t+1}$ {1:t}, e_ {t+1}$$$begin{aligned}mathbf{P}(mathbf{X}{t+1}mid &amp;amp;= mathbf{P}(mathbf{X}{t+1}mid e{1:t}, e_{t+1})end{aligned}$$ Apply Bayes formula Reference Formula$$mathbf{P}(mathbf{X}_ {t+1}mid {t+1}) frac{mathbf{P}(e_ {1+t} mathbf{X}_ {t+1}, {1:t})mathbf{P}(mathbf{X}_ {t+1} {1:t})}{mathbf{P}(e_ {1+t}mid {1:t})}$$ Due hidden $mathbf{e_ {1+t}}$ {1:t}}$. $$mathbf{P}(mathbf{X}_ {1+t})}$$In case, change {1+t})$ normalization constant $alpha$.$$= alpha mathbf{P}(e_ {1:t})$$ Hidden Model$$= {t+1})mathbf{P}(mathbf{X}_ Expand last term$$= x_t) mathbf{P}(mathbf{x}_ t {1:t})$$In short, filter {t+1}$ formulaFiltering Formula$$mathbf{P}(mathbf{X}_{t+1}mid e_{1:t+1}) overbrace{mathbf{P}(e_ {t+1})}^{text{Sensor Model}}underbrace{mathbf{P}(mathbf{X}_ mathbf{x}_ t)}_{text{Transition Model}}overbrace{mathbf{P}(mathbf{x}_ {1:t})}^{text{Recursive Filtering}}$$*$alpha$ {0}mid {1:0})$ NO CLUE provided. prior knowledge.PredictionPrediction e_{1:t}) alphaunderbrace{mathbf{P}(mathbf{X}_ x_ {t})}_{text{Transition e_{1:t})}^{text{Previous constantBy applying repeatedly, $t+2$, $t+3$, etc.Case Study: Rain &amp;amp; UmbrellaYou basement, you want know whether raining outside. get people basement umbrella hands.Prior Knowledge $$mathbf{P}(R_t R_ {t 1}) left[begin{matrix}P(neg r_ 0.3 P(r_ 0.7 P(neg neg 0.3end{matrix}right]$$ If rains day rain $t+1$ 0.7, if … $$mathbf{P}(u R) left[begin{matrix}0.9 0.2end{matrix}right]$$ having rainy $0.9$. However, rainy, seeing $0.2$. Initial Distribution On 0, believe $P(Rain) Rain) 0.5$, other words, $mathbf{P}(R_0) langle0.5, 0.5rangle$ FilteringWithout $mathbf{P}(R_1)$ by model.$$mathbf{P}(R_1) alphamathbf{P}(R_0)mathbf{P}(R_1mid R_0) alphaleft[begin{matrix}0.5 0.5end{matrix}right] times left[begin{matrix}0.3 0.3end{matrix}right] left[begin{matrix}0.5, 0.5end{matrix}right]$$Seems useless, ugh? But, things becomes interesting receive message: see so $U_1 t$Now run process:$$begin{aligned}mathbf{P}(R_1 u_1) mathbf{P}(u_1mid R_1)mathbf{P}(R_1mid R_0)&amp;amp;= alphaleft[begin{matrix}0.9 0.2end{matrix}right]times left[begin{matrix}0.5 0.5end{matrix}right]&amp;amp;= left[begin{matrix}0.45 0.1end{matrix}right]&amp;amp;approx left[begin{matrix}0.818 0.182end{matrix}right] end{aligned}$$15.2.2 SmoothingSmoothing possibility formal mathematical language, smoothing evaluating:$$mathbf{P}(X_kmid {1:t}), quad k [1, t)$$To evaluate expression, could take following steps: set$$mathbf{P}(X_kmid {1:t}) mathbf{P}(X_kmid {1:k}, {k+1: t})$$ Rule, {1:k}$​ (Reference Formula)$$= mathbf{P}(X_ {1:k}) {k+1:t} X_k, {1:k})$$ According HMM, {k+1:t}$ {1:k}$$$begin{aligned}&amp;amp;=alphamathbf{P}(X_kmid mathbf {P}(e_ X_k) &amp;amp;=alphatext{ Filtering}(X_k) text{Backward}(X_k, {k+1:t})&amp;amp;=alpha {k} {k}) {k 1} {1: k-1}) {k+1:t}) end{aligned}$$For “Filtering” part, call described above. Below discuss “Backward” part. Backward broadcast “future” apply on. Conditioning + 1}$$$mathbf sum_ {x_ 1}}{ mathbf{P}(mathbf{e}_ 1 : t} {k}, {k})}$$ Conditional Independence$$= Evidence set$$= 1}, mathbf{e}_ 2 {k})}$$4.$$= P (mathbf{e}_ {k})}$$We $mathbf X_k)$’s expression contains {k+2:t} X_ 1})$. So evaluation process.$$begin{aligned}mathbf mathbf{b}_ 1: t}&amp;amp;= text{Backward}(mathbf{b}_ 2: t}, 1})end{aligned}$$But one problem increase, operation (as requires recursively $k$ $t$).To strategy “fixed-lag smoothing” proposed. For $X_k$, $k+n$ $n$ constant.15.2.3 Finding sequenceSometimes, sensor, most-likely lead value. Using finding expression:$$max_ 1cdots, t}mathbf{P}(x_ 1, t, {1:t+1})$$There relationship between sequence.$$=alpha max_ {mathbf{x}_ t}{( {t}) 1cdots P(x_ })}$$"
    },
    {
      "title"    : "Uniswap 3 - Liquidity, Liquidity Provider and AMM",
      "url"      : "/blog/2021/uniswap3-1.html",
      "tags"     : "Cryptocurrency, Decentralized Finance",
      "date"     : "2021-08-07 00:00:00 +0000",
      "content"  : "流动性 LiquiditySource: Cryptocurrency Liquidity - How to Find Best Provider? (b2broker.com) Crypto Liquidity, The Complete Guide Leverate 什么是流动性加密货币的流动性描述一种加密货币被简单转化为其它加密货币或法币的能力。低流动性说明市场价值不稳定（波动率高），高流动性说明市场价值稳定（波动率低）高流动性的好处理想的高流动性市场中，供给与需求在数量和金额上平衡，买卖双方的需求都得到满足高流动性的情况下，加密货币的市场价格趋于稳定，大额交易不会显著影响货币价值什么决定流动性 交易量 高交易（交换）量为人们提供了更多交换加密货币和提现的机会 可用性 加密货币被用作支付媒介的频率越高，它的流动性越高 这也是为什么商人支持加密货币支付往往会导致流动性提升 监管 监管（例如允许/禁止交易所，是否对加密货币收税）也会直接影响加密货币流动性 流动性提供者 ProviderSource Provider流动性提供者通过将自己拥有的加密货币资产注入流动性池协助平台上的交易并从中获得被动收入。流动性池由去中心化交易所的自动做市商(Automated Market Maker, AMM) 维护。这些智能合约让低流动性的两种加密货币（或稳定币）可以在一定的价值范围内进行自动交易。 例子： BTC / ETH 交易所中，Alice 想用 1 交换 20 ETH，但是由于流动性低没人接单 维护 Bob 流动性池子的 AMM 发现这笔订单的价值在设定的区间以内：(18ETH &amp;lt; 1BTC 22 ETH)，于是自动通过了交易，提高了 &amp;lt;-&amp;gt; 的流动性 在完全自动化的操作下，Bob 现在少了 20ETH，多了 1BTC当流动性提供者为加密货币兑换提供流动性时，他们会收到交易发起人的部分交易费作为被动收入。自动做市商 Automated Makers (AMM)Source What Is an Maker (AMM)?什么是 AMMAMM 是去中心化金融体系 (Decentralized Finance, DeFi) 中的一环。在传统的去中心化交易所中，卖方将订单挂在市场上，买方选择订单而成交。由于加密货币市场中买卖双方数量都不大，这种传统的方法效率较低。AMM 创建流动性池子并让流动性提供者提供两种加密货币资产。这些流动性池子允许全自动化的交易。任何拥有 ERC-20 代币的人都可以通过向 的流动性池子提供资产称为流动性提供者并获得一定的报酬。这些报酬来自于与流动性池子交互的交易者。等乘积公式 Constant Product FormulaAMM 是 DeFi 中交易代币资产的主要方式之一，而其中最关键的一部分是这样一个数学公式tokenA_balance(p) * tokenB_balence(p) = k在 Uniswap 中，这个公式被表述为x y k常数 k 表示流动性池子中两种资产的乘积始终是恒定的，为了满足这种关系，两种代币间的“汇率”是浮动的。例如一个池子中有 和 两种代币， 如果 在短时间内被大量兑换为 ETH，那么因为池子中的 数量越来越多，每 能兑换的 数量就会越来越少 （BTC 的价格降低）。当 被大量兑换为 时， 数量会越来越少 （ETH价格降低）。同时，AMM 的设计鼓励交易者在 汇率与市场价格有差距时套现。随着套现的进行，两种资产在池中的比例逐渐变化并最终使得两种资产之间的“汇率”与市场价格相符。"
    },
    {
      "title"    : "CS188 Chapter 14 Probabilistic Reasoning",
      "url"      : "/blog/2021/CS188-Chapter14.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-06-13 00:00:00 +0000",
      "content"  : "14.1 Representing Knowledge in an Uncertain DomainThis section will introduce a data structure called Bayesian network to represent the dependencies between variables. can any full-joint probability distribution and many cases do so very concisely.A is directed acyclic graph (DAC) where each node annotated with quantitative information. Each corresponds random variable, which may be discrete or continuous. A set of links arrows connects pairs nodes. If there arrow from $X$ $Y$, said parent $Y$. $X_i$ has conditional $mathbf{P}(X_imid Parents(X_i))$ that quantifies effect parents on node.In network, table (CPT) stored. For instance, “$Toothache$” stores $mathbf{P}(Toothache mid Cavity)$.In general, for Boolean variable $k$ contains $2^k$ independently specifiable probabilities.14.2 The Semantics Networks14.2.1 full joint distributionThe variables $X_1$ $X_n$ represented this way:$$P(x_1, cdots, x_n) = prod_{i=1}^{n}{P(x_i parents(X_i))}$$Where $parents(X_i)$ nodes $X_i$. This equation defines what given means.How construct NetworksExcept above, another way calculate $P(x_1, x_n)$. Using product rule, we also it P(x_n x_{n-1}, x_{n-2}, x_1)P(x_{n-1}, x_1)$$Applying rule recursively x_n)$ long product:$$P(x_1, x_1)P(x_{n-1} x_1)cdots P(x_2 x_1)P(x_1) x_{i-1} cdots x_1)}$$Therefore, learn that$$P(X_imid X_{i-1}. cdots. X_i) P(X_i parents(X_i))$$This indicates …$$P(Xmid Parents(X));bot; P(Ancestor(X) Parents(X))$$ Nodes: First find $X_1, X_n$ included into Bayes Network. more compact if are ordered such cause precede Links $i 1$ $n$, Choose X_{i-1}$ minimal $X_i$, Equation $P(X_imid parents(X_i))$ satisfied. insert link $X_{i}$ Write down table, $mathbf{P}(X_i correct representation domain only conditionally independent its other predecessors ordering, parents.Some information omitted here as they requires sophisticated knowledge 2D Gaussian distribution, topology, etc. You them Chapter 14.2 - 14.314.4 Exact Inference NetworksThe basic task probabilistic inference system compute posterior query variables, some observed event (the assignment values evidence variables).$$text{All Variables} text{Query Variables }cuptext{ Evidence Hidden Variables}$$A typical asks $mathbf{P}(Xmid mathbf{e})$14.4.1 by EnumerationA $mathbf{P}(X mathbf{e})$ answered using below:$$mathbf{P}(X mathbf{e}) alpha mathbf{P}(X, sum_y{mathbf{P}(X,mathbf{e}, mathbf{y})}$$A Network computing sums products probabilities network. Example Suppose have We use $B$ $Burglary$, $m$ $j$ known value $JohnCalls$ $MaryCalls$ (True False). Now want $mathbf{P}(Bmid m, j)$ $$begin{aligned} mathbf{P}(Bmid j) &amp;amp;= leftlangle frac{P(b, j, m)}{P(j, m)}, frac{P(neg b, m)} rightrangle underbrace{P(b, m)}_{text{Expand}}, P(neg m)rightrangleend{aligned}$$ Chain Rule, expand $P(b, E, A)$ $$begin{aligned}P(b, m) sum_E{sum_A{P(b, A)}}&amp;amp;= sum_E{sum_A{P(m A, b)P(j b)P(A b)P(Emid b)P(b)}}end{aligned}$$ Note: simplicity $xbot y$ shorten $P(x)bot P(y)$ y a$ $P(xmid a) bot P(ymid a)$ y, z a)bot P(zmid According Network, know $m j$, E A$, $j A$ $bmid E$. Therefore, simplify formula above b)P(b)}}&amp;amp;= sum_E{sum_A{P(mmid A)P(j A)P(Amid b)P(E)P(b)}}end{aligned}$$ To formula, “extract common factor” out nested sum$sum$. $$begin{aligned}&amp;amp;P(b, m)= &amp;amp;P(b)sum_Eleft({P(E)sum_Aleft({P(m A)P(jmid b)}right)}right)= &amp;amp;P(b)sum_Eleft({P(E)sum_Aleft({underbrace{P(mmid Parents(m))P(jmid Parents(j))P(Amid Parents(A))}_{text{Find these Network}}}right)}right)end{aligned}$$The worst time complexity enumeration $O(n2^n)$To formally describe process Enumeration, two functions $text{ENUMERATION-ASK}$ $text{ENUMERATE-ALL}$. $times$ represents pointwise vectors instead scalar product.Here’s how $text{ENUMERATE-ALL}$ evaluate $text{ENUMERATION-ASK}(B, lbrace j,mrbrace, bn)$.Some here. 14.4.2 14.4.414.5 Approximate NetworksThis describes randomized sampling algorithms, Monte Carlo provide approximate answers whose accuracy depends number samples generated.14.5.1 Direct Sampling MethodsPrior SampleStep 1. Use topological sort all Network.Step 2. Assign first no Parents) randomly $mathbf{P}(X_1)$.Step 3. next $mathbf{P}(X_2 Parents(X_2))$Step 4. Repeat Step 3 until assignmentAfter step 4, successfully sample By repeating times, Probability e)$.Suppose $S_{PS}(x_1, getting $X_1 x_1, X_n=x_n$.$$S_{PS}(x_1cdots prod_{i=1}^n{P(x_imid Parents(X_i))}$$Suppose taken $N$ direct among them, $N_{PS}(x_1cdots $X_1=x_1cdots X_n=x_n$. ration $N_{SP}$ converge approach $infty$.$$lim_{Nrightarrowinfty}{frac{N_{PS}(x_1cdots x_n)}{N}} S_{PS}(x_1, x_n)=P(x_1, x_n)$$The estimated becomes exact large-sample limit. Such estimate consistent.$$P(x_1, x_m)approx N_{PS}(x_1, x_m)/N$$Rejection SamplingRejection general method producing hard-to-sample easy-to-sample distribution. It produce consistent estimation true probability.The biggest problem rejection rejects too samples! being rejected increases exponentially increases."
    },
    {
      "title"    : "CS188 Ch13. Case Study - Recognize MNIST base on Naive Bayes",
      "url"      : "/blog/2021/CS188-Naive-Bayes-MNIST.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-06-04 00:00:00 +0000",
      "content"  : "开始之前……先下载 Case Study Package，其中包括了 Jupyter Notebook 文件，MNIST 数据集，和 Python 文件Download the Case-Study Package 提取码：gwcsUsing Naive Bayes’ Network to Recognize MNIST Handwriting FiguresThis dataset contains two files - mnist_test.csv and mnist_train.csv. They are in data directory. You can also download them from this linkWhat is MNIST?MNIST a set of hand-writing images collected by NIST. Each image cropped $28px times 28px$. There exist single digit each image.The gray-scaled. pixel has value range $[0, 255]$. Where $0$ represents “white” $255$ “black”.Now, let’s take look at first.def load_csv(pathToCSV: str) -&amp;gt; list: &quot;&quot;&quot; 加载 csv 数据 = [] lines open(pathToCSV, &quot;r&quot;).read().strip().split(&quot;n&quot;) [list(map(int, line.split(&quot;,&quot;))) for line lines] return datatrain_set load_csv(&quot;./data/mnist_train.csv&quot;) # 训练集，共 60,000 张（行）test_set load_csv(&quot;./data/mnist_test.csv&quot;) 测试集，共 10,000 张（行）def display_image(pixels: list) None: Display using ASCII char, show label on assert len(pixels) == 1 + 28 * 28, &quot;Unable display other than size label&quot; gray_chars &quot; .:-=+*#%@&quot; gray_scale 9 print(&quot;Label: {}&quot;.format(pixels[0])) index, enumerate(pixels[1:]): if(index % 28) 0: print() print(gray_chars[pixel // 255], end=&quot; &quot;) print(&quot;n&quot;)Code:display_image(train_set[1])Output:Label: 0 . : @ Simplification image: BinarizationTo further simplify model (and reduce memory requirement naive Bayes classifier), we binarize image.def binarize_image(pixels: list, threshold=120): [Label, Pixel 1, 2, ..., 784] binaryImg [pixels[0]] include += [0 if &amp;lt; threshold else pixels[1:]] based binaryImgdef display_binary_image(pixels: list): display_image([pixels[0]] [pixel 255 pixels[1:]])binary_train_set [binarize_image(img) img train_set]binary_test_set test_set]Code:display_binary_image(binarize_image(train_set[5]))Output:Label: 2 Image Recognition?To begin with, assume that binary values conditionally independent under condition label.$$mathbf{P}(Pixel_1 mid Label) bot mathbf{P}(Pixel_2 … mathbf{P}(Pixel_{784} Label)$$Since know input image, pixel, easily calculate $mathbf{P}(pixel_1, pixel_2, cdots ,pixel_{784} Label)$ equation:$$mathbf{P}(pixel_1, cdots, pixel_{784} prod_{i [1, 784]}{mathbf{P}(pixel_i Label)}$$For simplicity, use $X$ denotes $lbrace pixel_1, rbrace$$$begin{aligned}mathbf{P}(Label X) &amp;amp;= alpha mathbf{P}(X Label)mathbf{P}(Label) langle P(X label_0)P(label_0), P(Xmid label_1)P(label_1), label_9)P(label_9)rangle prod{P(pixel_i label_0)cdot P(label 0), cdots}rangleend{aligned}$$LabelCount [0] 10 Counter Label, used P(Label)PixelCount [[0] 784 _ range(10)] | P(pixel label)for binary_train_set: LabelCount[img[0]] index range(1, len(img)): PixelCount[img[0]][index 1] img[index] +1 black, otherwiseLabelDistribution [LabelCountElem / len(train_set) LabelCountElem LabelCount]PixelDistribution [ LabelCount[i] PixelCount[i]] i range(10)]Code:print(&quot;Label Distribution:n&quot;, LabelDistribution)Output ($mathbf{P}(Label)$)：Label Distribution: [0.09871666666666666, 0.11236666666666667, 0.0993, 0.10218333333333333, 0.09736666666666667, 0.09035, 0.09863333333333334, 0.10441666666666667, 0.09751666666666667, 0.09915]With statistical Training set, now construct our classifier.def get_pixel_prob(index, value, label): global PixelDistribution try: black_probability PixelDistribution[label][index] except: print(label, index) value: black_probabilitydef predict_image(pixels): PixelDistribution, LabelDistribution 784, &quot;only predict without 0&quot; pred_probability pred_label range(10): posterior_probability_list [get_pixel_prob(index, pred_label) enumerate(pixels)] posterior_probability prob posterior_probability_list: *= label_pred)} pred_probability[pred_label] LabelDistribution[pred_label] sum(pred_probability) [prob pred_probability]Classification Test SetCode:selected_image_index 3101print(&quot;Predict Probability:n&quot;, list(predict_image(binary_test_set[selected_image_index][1:])))display_image(test_set[selected_image_index])Output:Predict Probability: [0.0, 0.0, 1.3577222853703937e-55, 2.3620356632673247e-37, 1.0415370695140759e-36, 0.9999999999999999, 6.262374232930145e-42, 1.1556946478312145e-16]Label: 7"
    },
    {
      "title"    : "CS188 Chapter 13 Quantifying Uncertainty",
      "url"      : "/blog/2021/CS188-Chapter13.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-05-30 00:00:00 +0000",
      "content"  : "13.1 Acting Under UncertaintyAn intelligent agent in reality needs to handle the uncertainty due partial observability and nondeterminism.In previous chapters, agents by keeping track of a belief state - representation set all possible states that it might be in.Based on states, contingency plan handles every eventuality its sensors may report during execution will generated.However, such method has significant draw back When interpreting sensor information, logical must consider logically explanation for observations this lead impossibly large complex representations. A correct can grow arbitrarily unlikely contingency. Sometimes, there does not exist is guaranteed achieve goal. However, should able compare plans even if they are guaranteed.If we using + technique solve real-world problem, hardly generate valid solution. Suppose want our schedule airport, think “we leave at 9 a.m., as long weather good”. Then, requirement situation, begin “what bad”, bridge falls down storm”, …” finally reach solution “you 2 months earlier airport get time”.So what’s problem with method? By definition, make sure arrive time any but question do really need certainty? Do an earthquake? This leads concept rational decision. Rational Decision decision depends both relative importance goal likelihood that, degree which, achieved.13.1.1 Summarizing uncertaintySuppose aims high GPA deployed. The wants list actions low GPA:$$Low rightarrow Low Test Scode vee AbsentCourse PlayGames cdots$$It clear almost unlimited problems cause GPA. Some people try reverse relationship:$$Low TestScore LowGPA$$Which, unfortunately also false, test score So definite relationship between $LowTestScore$ $LowGPA$ anyway. In describe them belief, probability theory. Probability provides way summarizing comes from laziness1 ignorance2Probability statements made respect knowledge state, real world. say student $0.8$ GPA, inference based world (as either have or GPA).13.1.2 Uncertainty DecisionsConsider mentioned above again. What choose final result? one ago 100% you time, 3 hours before plane take off?To choices, first preferences different outcomes various plans. We use utility theory represent reason preferences. Utility Theory: Every usefulness, utility, prefer higher utility$$text{Decision Theory} = text{Probability text{Utility Theory}$$ Principle Maximum Expected (MEU): An only chooses action yields highest expected averaged over action. MEU statistical mean (expectation) under best situation.13.2 Notation13.2.1 Probabilities aboutProbabilistic assertions talk about how probable situation occur. worlds called sample space ($Omega$). exclusive exhaustive moment, ($omega$) actual world.$$0leq P(omega) leq 1 text{ } omega }sum_{omegainOmega}{P(omega)} =1$$Usually, won’t probabilistic queries particular worlds, them. For instance, know possibility rolling two dices their sum up 11. Artificial Intelligence, proposition ($phi$).$$text{For }phitext{ , }P(phi) sum_{omegainphi}{P(omega)}$$Probabilities like $P(X=0)$ unconditional prior probabilities (先验概率). It refers degrees propositions absence other information. most situations, some known information query. Such evidence, event given evidence conditional posterior (后验概率). imporant contents below, so fully understand continue reading. decision, observed used calculate probabilities.When $P(X=0mid 0leq X 5)$ means “the $X=0$ $0leq Xleq 5$ no further information”.$$P(amid b) frac{P(a wedge b)}{P(b)}, quadquad P(awedge P(amid b)P(b)$$13.2.2 Language AssertionsVariables random variables. variable domain value assigned to.When values variable, $mathbf{P}$ notation. Example: $$P(Weather=sunny) 0.6P(Weather rain) 0.1P(Weather cloudy) 0.29P(Weather snow) 0.01$$ case, simplify form: $$mathbf{P}(Weather) langle 0.6, 0.1, 0.29, 0.01 rangle$$The statement defines distribution variable.$mathbf{P}(Xmid Y)$ $X$ $Y$ is, $P(X=i mid Y=j)$ $i, j$ pairs.$mathbf{P}(X, joint which pairs j$.A defined assignment variables consideration.The full consideration.13.3 Inference Full Joint DistributionIn section, simple computation query evidence.Suppose three Boolean $Toothache$, $Cavity$ $Catch$. table shows $mathbf{P}(Cavity, Catch, Toothache)$.The type marginal i.e., variable. Example, $mathbf{P}(Cavity)$.$$begin{aligned}mathbf{P}(Cavity) &amp;amp;mathbf{P}(Cavity, neg catch, toothache) mathbf{P}(Cavity, toothache)=&amp;amp;langle 0.008, 0.576rangle 0.012, 0.064 rangle 0.072, 0.144 0.108, 0.016rangle=&amp;amp;langle 0.2, 0.8rangleend{aligned}$$This process marginalization each variables, thereby taking out equation. Marginalization $$ mathbf{P}(Y) sum_{zin Z} {mathbf{P}(Y, z)} example above, rewrite calculation into “standard” form:$$mathbf{P}(Cavity) sum_{zinlbrace Toothacherbrace}{P(Y, z)}$$A variant rule involves instead Product rule. Conditioning Z}{mathbf{P}(Ymid z)P(z)} cases, interested computing others.Using Equation $$P(Amid B) frac{P(A B)}{P(B)}$$, probability.In evaluate $cavity$ $toothache$.$$P(cavity frac{P(cavity toothache)}{P(toothache)} 0.6P(neg cavity frac{P(neg 0.4$$During calculation, notice $P(cavitymid toothache)$ $P(neg multiplied factor $frac{1}{P(toothache)}$. call $frac{1}{P(toothache)}$ normalization constant, denote $alpha$.Combining Normalization, general equation distribution. General Conditional mathbf{P}(Xmid mathbf{e}) underbrace{alphamathbf{P}(Xmid mathbf{e})}_{text{Normalization constant alpha} alpha cdot underbrace{ sum_{mathbf{y}in Y}{overbrace{ mathbf{P}(X,mathbf{e}, mathbf{y})}^{text{Full distribution}} }}_{text{Remove unrelated mathbf{y}} Given table, answer scale well. If $n$ boolean consider, size $O(2^n)$ takes table.To tool independence variables.13.4 IndependenceTo with, let’s see case again adding fourth $Weather lbrace sunny, cloudy rbrace$.How $P(toothache, cavity, cloudy)$ related cavity)$ related? According Rule, that$$P(toothache, P(toothache, P(cloudy)$$To write form notation$$mathbf{P}(Toothache, Cavity, Weather) mathbf{P}(Toothache, Cavity mathbf{P}(Weather)$$Since don’t expect $Weather$ affect $Toothache, Catch ,Cavity$, that$$mathbf{P}(Toothache, Cavity)$$Therefore, say$$mathbf{P}(Toothache, Cavity) mathbf{P}(Weather)$$This independence. Formally speaking, $A$ $B$ independent Independence Random Variables mathbf{P}(A, mathbf{P}(A)mathbf{P}(B)quadtext{iff }Atext{ }Btext{ independent} Except ways $B$:$$mathbf{P}(Amid mathbf{P}(A)quadmathbf{P}(Bmid A) mathbf{P}(B)$$By separating considered several tables. coins denoted $C_1$, $C_2$, $cdots$, $C_n$. build full-joint contain $2^n$ entries. $$mathbf{P}(C_1, C_2, cdots, C_n) overrightarrow{text{ }}lbrace mathbf{P}(C_1), mathbf{P}(C_2), mathbf{P}(C_n)rbrace$$ since coin’s coins, joint-distribution single coin other.13.5 Bayes’ Rule Its UseIn introduced product $P(awedge P(a b)P(b)$ second P(bmid a)P(a)$.Combining these forms together divide sides $P(a)$, Bayes&#39; a) frac{P(amid b)P(b)}{P(a)} more background condition $e$.$$P(Ymid X, e) frac{P(Xmid Y, e)P(Ymid e)}{P(Xmid e)}$$13.5.1 Applying Rule: caseIn application, usually $effect$ unknown $cause$, would determine effect. becomes$$P(causemid effect) frac{P(effectmid cause)P(cause)}{P(effect)}$$Evaluation $P(effectmid cause)$ quantifies causal direction (因果关系)Evaluation $P(cause effect)$ quantify diagnostic Example $P(cough) 0.1$ $P(covid) 0.001$. checking Covid-19 patient separately, learn $P(cough covid) 0.6$. Now $P(covid cough)$. $$P(covid cough) frac{P(cough P(covid)}{P(cough)} frac{0.6times 0.001}{0.1} 0.006$$ sometimes hard (in $P(cough)$). still find $P(covidmid cough)$ bypassing $P(cough)$ normalization. $$mathbf{P}(Covid P(cough covid)P(covid), P(cough, covid)P(neg covid)rangle$$ Where $alpha$ makes $mathbf{P}(Covid $1$.13.5.2 Using rule: Combining EvidenceWe before, here, introduce new kind independence.$X$ if$$mathbf{P}(X, Ymid Z) mathbf{P}(Ymid Z)$$Suppose $cause$ $effects$, Naive Bayes mathbf{P}(Cause, Effect_1, Effect_2, cdots ,Effect_n) mathbf{P}(Cause)prod_{0le ile n}{mathbf{P}(Effect_i)} Naïve “naïve” often simplification) cases where effect actually conditionally other.Notes Laziness: It’s too much work complete antecedents consequent needed ensure exceptionless rules &amp;#8617; Ignorance: domain. &amp;#8617;"
    },
    {
      "title"    : "二维前缀和 2D Prefix Sum",
      "url"      : "/blog/2021/2D-Prefix-Sum.html",
      "tags"     : "Algorithm",
      "date"     : "2021-05-26 00:00:00 +0000",
      "content"  : "应用场景在一些算法题中，我们需要快速求出二维数组内一个特定区域的所有值的和。这种时候，如果我们每次都使用遍历的方法求和，每次查询的时间复杂度是 $O(n^2)$，对于铜组以上的算法题来说这种时间复杂度一般是不可接受的。二维前缀和就是专门用于解决这个问题的一种数据结构。二位前缀和会在初始化的时候使用 $O(n^2)$ 的时间复杂度建立一张二维数组从当前位置到 $[0][0]$ 的所有数字的和的表格。当初始化完成后，每次 $query$ 操作只需要 $O(1)$ 的时间复杂度就可以完成。⚠ 注意这种数据结构并不适合在二维数组需要大量更新的情况下使用，因为二位前缀和数组每次更新需要重新构造从更新位置开始的所有表格。每次更改的时间复杂度是 $O(n^2)$原理二位前缀和数据结构会在内部维护两张表格 $T$ 和 $S$。$S[y][x]$ 处存储的值等于 中所有 $(0, 0)$ 到 $(x, y)$ 的位置的值之和。当我们想查询两个点 $(x_1, y_1)$ 与 $(x_2, y_2)$ 构成的矩形内部所有数字的和时，我们可以这样计算：表格 $S$ 可以使用下面这个公式遍历的方法生成$$S[x][y] = S[x - 1][y] 1][y 1] + S[x][y T[x][y]$$ 注意上面 中内容的运算顺序，对于 Java 等数值类型有最大值的语言，这样的顺序可以一定程度上的避免出现 Overflow 问题实现下面是基于 范型 (Generic Type) 实现的一个二维数组。它可以存储任意数字类型的二维数组，但是查询时返回的内容总是 double 类型。import java.util.ArrayList;public class PrefixSum2D&amp;lt;T extends Number&amp;gt; { public static void main(String[] args) Integer[][] arr new {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}; PrefixSum2D&amp;lt;Integer&amp;gt; test PrefixSum2D&amp;lt;Integer&amp;gt;(arr); System.out.println(test.query2DSum(1, 0, 2)); } private ArrayList&amp;lt;ArrayList&amp;lt;T&amp;gt;&amp;gt; valueTable ArrayList&amp;lt;ArrayList&amp;lt;T&amp;gt;&amp;gt;(); ArrayList&amp;lt;ArrayList&amp;lt;Double&amp;gt;&amp;gt; sumTable ArrayList&amp;lt;ArrayList&amp;lt;Double&amp;gt;&amp;gt;(); PrefixSum2D(T[][] valueTable){ for (int i 0; &amp;lt; valueTable.length; ++){ if (i == this.valueTable.size()){ this.valueTable.add(new ArrayList&amp;lt;T&amp;gt;()); j valueTable[0].length; this.valueTable.get(i).add(valueTable[i][j]); this.initializeTable(valueTable[0].length, valueTable.length); this.constructTable(0, 0); query2DSum(int x1, int y1, x2, y2){ /* Query the sum of all numbers in range ([x1, x2], [y1, y2]) with Time Complexity O(1) (x1, y1) ------------- (x2, | y2) */ x1 -= 1; y1 (x1 0 &amp;amp;&amp;amp; 0){ return this.getTable(x2, y2); else 0) y1); (y1 this.getTable(x1, slowUpdateTable(int x, y, T value){ Update 2D Prefix Sum Table O(n^2) complexity this.valueTable.get(y).set(x, value); this.constructTable(x, y); initializeTable(int y){ Initialize SumTable size x * y and filled null y; this.sumTable.add(new ArrayList&amp;lt;Double&amp;gt;()); x; this.sumTable.get(this.sumTable.size() 1).add(null); constructTable(int Construct from T[y][x] Complexity: O(n^2), slow, don&#39;t call this method frequently this.sumTable.size(); ( this.sumTable.get(0).size(); value this.valueTable.get(i).get(j).doubleValue(); 1 &amp;gt;= += this.sumTable.get(i 1).get(j); 1).get(j 1); (j this.sumTable.get(i).get(j this.sumTable.get(i).set(j, getTable(int this.sumTable.get(y).get(x); }}问题练习 USACO 2019 Silver Feb #2, Painting The Barn 2020 Dec Rectangular Pasture Gold #3,"
    },
    {
      "title"    : "线段树 Segment Tree",
      "url"      : "/blog/2021/Segment-Tree.html",
      "tags"     : "Algorithm",
      "date"     : "2021-05-21 00:00:00 +0000",
      "content"  : "使用场景线段树的应用场景与二进制索引树相似，当我们需要多次查询数组子区间的特性/数据并同时高效修改数组内容的时候，我们可以使用线段树。线段树并不是一种单一的数据结构 - 它代表了一类具有相同思想方法的数据结构 通过二叉树做到区间内容的高效查询，这里的内容可以是区间最大/最小值，区间和，等等 。数据结构线段树是一个二叉树，线段树中的每一个节点代表序列中的一个区间。假设对于 长度为 $N$ 的 array $A$，我们有对应的线段树 $T$，那么…… $T$ 的根节点代表整个 $A$ 的每个叶子节点都代表 中的一个值 $A[i]$，$0leq ilt N$ 中的每一个非叶节点都代表 的一个子序列 $A[i:j]$，$0leq j lt 在一个线段树中，所有的叶子节点一定代表原数组中的一个值 注意线段树不一定是满二叉树时间复杂度初始化复杂度 $O(n)$对于一个长度为 $n$ array，对应的线段树中最多一共有 $2n + 1$ 个节点。每个节点的初始化都是 $O(1)$ 的时间复杂度，所以线段树的初始化复杂度是 $O(n)$。更新复杂度 $O(log{n})$对于一个长度为 array，每次修改一个单一的值需要修改这个节点的所有父节点与“祖先节点”（例如父节点的父节点，父节点的父节点的父节点……）。对于一颗线段树，最多有 $log_2{n}$ 的高度，所以更新一次线段树的值的时间复杂度是 $O(log_2{n}) = O(log{n})$查询复杂度 $O(log{n})$查询节点数量最多的情况出现于查询 $[l, l]$ 时，这时候我们需要从根节点一路递归的遍历到叶子节点，一共遍历 $O(log{n})$ 个节点。所以查询区间的时间复杂度是 $O(log{n})$Java实现一个线段树有三个主要的方法： 初始化（Constructor）- 给定一个 Array，构建这个 Array 对应的线段树 查询 （Query）- 给定一个区间范围 r]$，返回这个区间的信息（最大值，最小值，和 etc） 更新 （Update）- 给定 index $i$ 与新的值 $v$，更新线段树下面，我们会实现一个基于 范型 (Generic Type) 的最小线段树。对于任意实现了 Comparable 接口的类型 T ArrayList&amp;lt;T&amp;gt;，我们都可以使用这个线段树来求出区间 r]$ 中的最小对象 $T$。Helper Functions在正式实现线段树前，我们先写一些后面可以用到的 Helper Functions。 genericMin 函数通过比对 T.compareTo 的值来返回两个 对象中较小的一个对象 getLChild 计算出当前节点的左子节点的 getRChild 计算出当前节点的右子节点的 inInterval 计算出区间 $[l1, r1]$ 和 $[l2, r2]$ 之间的关系public class SegmentTree &amp;lt;T extends Comparable&amp;lt;T&amp;gt;&amp;gt;{ private ArrayList&amp;lt;T&amp;gt; tree; T[] value; int getLChild(int index){ return * 2 1; } getRChild(int 2; genericMin(T o1, o2){ if (o1.compareTo(o2) &amp;gt; 0){ o2; o1; inInterval(int l1, r1, l2, r2){ (r2 &amp;lt; l1 || l2 r1){ 0; // Intervals do not have any intersection else (l2 &amp;gt;= &amp;amp;&amp;amp; r2 &amp;lt;= Interval complete in 1 else{ partially intersect with }} 注意我们的 tree 属性使用的是 ArrayList 而不是 这是因为 Java 中不能创造 Generic Type ArrayConstruct Segment Tree我们使用递归的方法来构建线段树 根节点的范围是 $[0, arr.length 1]$，计算出中间的节点 $mid (arr.length 1) / 2$，左节点的范围就是 mid]$，右节点的范围是 $[mid 1, 1]$。当节点的范围是 且 $l r$ 时，节点的值就是 中对应元素的值 此时这个节点时叶子节点。public SegmentTree(T[] values){ this.tree new ArrayList&amp;lt;&amp;gt;(Collections.nCopies(values.length null)); this.value values; this.constructTree(0, 0, values.length 1);}private void constructTree(int node, l, r) { (l == tree.set(node, value[l]); mid this.constructTree(this.getLChild(node), mid); this.constructTree(this.getRChild(node), r); this.genericMin(tree.get(this.getLChild(node)), tree.get(this.getRChild(node)))); }}Update Tree类似的，我们在更新 Tree 时也使用递归的方法更新 如果要修改的 在当前节点的范围内，我们就递归的修改下一层，最后再 bottom-up 的更新整条路径上的 个节点public updateTree(int index, val){ this.updateTree(0, this.value.length val);}private r, r){ this.tree.set(node, val); this.value[l] val; mid){ this.updateTree(this.getLChild(node), mid, this.updateTree(this.getRChild(node), this.genericMin(this.tree.get(this.getLChild(node)), this.tree.get(this.getRChild(node)))); }}Query Minimum在查询线段树中的区间最小值时，我们把所有情况分为三种： 当前节点代表的区间完全在查询的区间内 当前节点代表的区间部分在查询的区间内 当前节点代表的区间完全不在查询的范围内对这三种情况，我们采取不同的动作 情况 操作 节点区间完全在查询区间内 返回当前节点的值 节点区间部分在查询区间内 继续向下递归，返回左节点与右节点返回值的较小值 节点区间完全不在查询区间内 返回 null public queryMin(int queryMin(0, r);}private start, end, (this.inInterval(l, end) null; 1){ this.tree.get(node); (start leftInterval this.queryMin(this.getLChild(node), rightInterval this.queryMin(this.getRChild(node), (leftInterval null){ rightInterval; (rightInterval leftInterval; this.genericMin(leftInterval, rightInterval); }}对于基于数组Integer[]{1, 2, 3, 4, 5, 6}的线段树，我们执行 queryMin(2, 3) 时函数的递归情况如下Full CodeClick to see Full Code /* Tree, */import java.util.*;public static main(String[] args) SegmentTree&amp;lt;Integer&amp;gt; test SegmentTree&amp;lt;&amp;gt;(new Integer[]{1, 6}); System.out.println(test.dumpTree()); test.updateTree(0, 7); System.out.println(test.queryMin(2, 5)); 1); dumpTree(){ this.tree; 问题练习 Leetcode 307. Range Sum Query Mutable 非常 straight-forward 问题 218. The Skyline Problem 318. Count of Small Numbers After Self USACO 2020 US Open Contest, Gold 1. Haircut 2017 January Balanced Photo February 3. Why Did the Cow Cross Road III"
    },
    {
      "title"    : "CS188 Chapter 6 Constraint Satisfaction Problems",
      "url"      : "/blog/2021/CS188-Chapter6.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-05-11 00:00:00 +0000",
      "content"  : "6.1 Define Constraint Satisfaction ProblemsA CSP contains three components - $X$, $D$ and $C$. $X$ is a set of variables domains, one for each variable. $C$ constraints that specify the allowable combination between variables.Each constraint can be represented in two parameters $scope$ $relation$. The define are related with this constraint. $relation$ values take.The either an explicit list all legal value tuple get or abstract relation. Example 1 (Abstract, Implicit Relation) : If $x &amp;lt; y$. formal way to represent will be: $$langle scope:(x, y),quad relation:;ltrangle$$ 2 (Explicit Relation): we have $0 x 4$ y 3$, way: scope: (x, relation: [(1, 1), (1, 2), cdots, (3, 2)]rangle$$To solve Problem (abbr. as below), need solution state space first. Each defined by **assignment** some variables.An assignment does NOT violate any called consistent (or, assignment).A Complete Assignment where every variable assigned.The Solution both Consistent Assignment.6.2 Why CSPIn real world, many problems converted CSP. As long solver, generalize solver different little difficulty. It easier use generalized than design custom using domain-specific knowledge.6.3 Solving CSPWhen finding CSP, once find out partial not solution, immediately discard further refinements assignment.6.3.1 Types Constraints Type Explanation Unary only contain scope Example: $langle (x), xneq 2rangle$ Binary y), rangle$ k-ary $k$ y, z), max(x, z) 5 Global involving $X$Example: $Alldiff$ requires has assigned value. Every finite-domain binary if enough auxiliary introduced. Therefore, Transform into only.6.3.2 Propagation: Inference CSPA regular search algorithm do thing: search. In specific type inference propagation Using reduce number variable, which, turn another variable.Constraint work during process pre-processing step.The key idea local consistency. see node, edge graph, consistency part whole graph.Basically, you pruning algorithms running on By cutting off domain workload greatly reduced.Node Consistency Node Check tighten unary constraintA single node-consistent variable’s satisfy constraints.It always possible eliminate node consistency.Arc Arc arc-consistent its satisfies constraints.Formally speaking, $X_i$ respect $X_j$ $D_i$ there exist $D_j$ such satisfied. Note iff stands ifAC3 most popular arc To make arc-consistent, AC-3 maintains queue arcs consider. Initially, then pops arbitrary $(X_i, X_j)$ from makes $X_j$.If step unchanged, move forward next arc.If not, add $(X_k, X_i)$ $X_k$ neighbor $X_i$. This because change may lead reduction $D_k$, even previously considered $X_k$.An arc-consistency equivalent original but faster smaller domains.Path Path implicit inferred triples variablesIn Consistency, optimize domain. For cases, works well directly (every restricted value) prove no (at least 0 valid value).However, situation, nothing 3. A situation doesn’t expected $X = {x, z}$ $D {[Red, Blue], [Red, Blue]}$ $C {langle(x, yrangle, langle(z, zneq langle(x, zrangle}$ changed. (When Red$, $y Blue$ vice versa). However, it clear solution.To problem, introduce thought Consistency.Formal description Consistency:A two-variable ${x_i, x_j}$ path third-variable ${x_k}$ ${x_i a, x_j=b}$ $x_i$ $x_j$, exists $x_k$ $x_i$, $x_j$ violated.$k$-ConsistencyA $k$-consistency. $k$-consistent $k-1$ these variables, $k$th 1-consistency, 2-consistency, 3-consistencyA strongly k-consistent also $(k-1)$-consistent, $(k-2)$-consistent … $1$-consistent."
    },
    {
      "title"    : "物体检测模型 R-CNN",
      "url"      : "/blog/2021/R-CNN.html",
      "tags"     : "Computer Vision, Neural Network",
      "date"     : "2021-05-02 00:00:00 +0000",
      "content"  : "论文链接三种不同的 CV 任务一般来说，我们可以将 任务按照输出的数据量分为以下三种： 图像分类 - 给定一张图片，输出一个一维向量，对整张图片进行分类 物体识别 给定一张照片，输出若干坐标对，在照片上用方形的 box 框出所有特定类型的物体 图像分割 给定一张照片，输出一个同样大小的 mask，标注具体每一个像素属于什么类型这三种任务中，模型输出的信息量是递增的。R-CNN (Regions with CNN features) 是第一个使用神经网络的物体识别模型 在 PASCAL VOC 2010 数据集中，模型将 mAP （mean Average Precision) 的值从之前最好的 $35.1%$ 一举提升到了 $53.7%$。这篇文章接下来会详细解读 R-CNN 的论文 Rich feature hierarchies for accurate object detection and semantic segmentation。后来许多的模型都基于这个模型的改进 例如 Fast R-CNN, Faster 等。在 之前的物体识别模型在 出现前，主要有两种做 Object Detection 的模型 第一种是将寻找 的位置作为一个回归问题来处理的，第二种则是使用一个滑动窗口用 一个个判别 window 中的内容是否是一个特定的类别。这两种方法最终结果的精度与速度都无法和 相比。模型结构R-CNN 模型可以分为三个部分 类型无关的候选区域生成 提供一系列（区域无关的）的候选区域让识别器进行识别 使用 对候选区域进行特征提取 对 提取出的特征向量使用每个分类单独训练的 SVM 进行具体分类1 候选区域生成对于一张任意尺寸的输入图片，R-CNN 会先使用 Selective Search 算法对图片中所有的像素进行聚类分析 相似颜色/纹路的像素被合并为同一个区域，如果区域的面积足够大 就会认为这一片区域可能有物体并将这个（矩形）区域作为一个 Region Proposal 传递到下一步。需要注意的是，在这一步中，Selective 算法不会对自己输出的 进行任何物体类型识别，算法本身也没有关于物体分类的先验知识。因此，这一步返回的候选区域被称为 Category-independent （类型无关区域提案）。更多关于 的信息在 中，模型会从一张图片中提取 2000 个候选区域进行接下来的特征提取和物体识别。2 候选区域特征提取对于每一个输入的候选区域，模型会使用一个 由5个卷积层和2个全连接层构成的 进行特征提取，将一个输入的候选区域转化为 $1times 4096$ 维的特征向量。Selective 的输出是任意尺寸的矩形，但是 要求输入一定是 $227times 227$ 的尺寸。为了解决这个问题，作者尝试了三种方式将 转化为 的尺寸： Tightest-square Context 在矩形的 把框变为正方形产生 的输入图片。 without 直接用空白填充 和目标的 $227 times 正方形之间的空袭 Wrap 直接将 各向异性的（也就是说照片的各个轴缩放系数不同）缩放为 的正方形 (i) Context, (ii) (iii) Wrap最后选择使用 wrap 的方法直接将 接受的尺寸除了 以外，作者还对所有的 加上了 16 个像素的 Padding 外围加上厚度 个像素的边框来收集 周围的环境信息。R-CNN 使用的特征提取 拥有 5 个卷积与池化层和 2 个全连接层。3 分类 提取出的特征向量2000 张输入的 的照片被 处理为 的特征向量后，我们可以将它们合并为一个 $2000times 的特征矩阵，并使用 对这个特征矩阵的每一个行向量（每个特征向量）进行分类。假如有 $N$ 个 class，则 的权重向量可以合并为一个 $4096 N$ 的权重矩阵。通过矩阵相乘，我们可以快速的判定每一个 属于哪个类。R-CNN 的优势 无论要求模型进行多少分类的任务，花费在 和 特征提取上的时间都是一致的，同时，CNN 特征提取的参数对于所有 是共享的，这可以大大减少参数量和运算量 模型中间部分的 特征提取极大的缩减了每个 proposal 的特征向量维度，让第三部分 分类更加具备可拓展性。（因为只有 4096 维，所以就算是 100k 分类问题 也只需要占用 1.5G 内存，而之前的 UVA 模型则需要占用 134 G 内存）输出优化模型输出 box，每个 拥有自己的分类和分值（来自于 SVM， background 也算一个类型）。为了防止出现多个 框定同一个物体的情况，作者对 的输出做出了优化 如果两个框有重叠部分，并且 之间的 交并比 (Intersection Over Union, IOU) 超过一个训练得到的数值，就删除两个 中得分较低的 box。 黑色矩形与蓝色矩形的 IOU 值 $$IOU = frac{text{Black }captext{ Blue}}{text{Black }cup text{ Blue}} frac{S_3}{S_1 + S_2 S_3}$$模型训练这里只讲述模型的 特征提取部分的训练方法监督预训练CNN 模型一开始在 ILSVRC2012 数据集上进行有监督的预训练。这个数据集的数据量较大，但是没有物体的 标签，只有图像分类标签。在多个 epoch 的训练后，CNN 达到与 Krizhevsky et al. 相似的准确率（稍低 $2.2%$）。特定领域微调在 模型完成有监督预训练后，作者对模型进行了微调。作者通过提供给 已经调整完尺寸的 来进一步训练模型。在这个过程中，模型的学习率被设定为 $0.001$ 预训练过程中的 $1/10$，通过设置较小的学习率，模型不会在微调过程中破坏在预训练过程中习得的特征提取参数。在生成微调使用的数据集时，作者将所有与标记 的 值大于等于 0.5 都当作同样的分类 box。通过这种方法，作者手动将物体识别的数据集增大了 30 倍。 在上面的图中，红色的框是人工标记的 Ground Truth，蓝色的框因为与红框的 $geq 0.5$，所以也被认为是标记 Text box。灰色的框因为与红框的 小于 0.5，所以不能够被看作是标记 的框分层研究 (Ablation Study)作者对 中各层的输出结果做了研究与比较，结果说明：在预训练过程中 最后一层全连接层的泛化能力比倒数第二层差 这意味着在这个阶段删除最后一个全连接层 $fc_7$，即缩减模型 $29%$ 的参数后模型的表现不会劣化 在移除最后两层全连接层以后，CNN 模型只使用卷积和池化层（约占整个模型参数量的 $6%$）依然可以达到较好的效果在微调过程中 模型的物体识别准确率 (mAP) 提升了 $8%$ 研究发现模型识别准确率的提升主要来自于 $fc_6$ 与 $fc_7$ 这两个全连接层的参数更新 这说明最后一个池化层（倒数第三层）从预训练数据集中学习到的特征提取参数拥有泛用性，模型的提升来自于基于模型前面卷积与池化提取出的特征进行推断的分类器的训练。"
    },
    {
      "title"    : "CS188 Chapter 5 Adversarial Search",
      "url"      : "/blog/2021/CS188-Chapter5.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-04-22 00:00:00 +0000",
      "content"  : "5.1 GamesThis chapter describes the Competitive Environments for agents, where their goals are conflict. Such problem is called adversarial search problems - often known as games.In field of AI, most common games a special kind game Deterministic, Turn-taking, Two-player, Zero-sum Perfect Information (such chess).Games interesting since they hard to solve using direct branching factor too large that it impossible through all possible states. Also, penalize inefficiency severely, so program should be fast possible.Pruning （剪枝） allows us ignore portions tree make no difference final choice. Heuristic Evaluation Functions allow approximate true utility state without doing complete search.Suppose there two agents “MAX” and “MIN”. In game, move first, take turn until over. The winner get points loser penalty.5.1.1 Formally Defined GameA can formally defined with these elements Element Explanation $S_0$ Initial State (the setup game) $Player(s)$ Defines which player has in current $s$ $Actions(s)$ Returns list legal actions $Result(s, a)$ *state transition model*, defines result an action $a$ $Terminal-Test(s)$ if over, false otherwise $Utility(s, p)$ A function numeric value ends terminal $p$ one total payoff players same every instance game.The initial $S_0$, $Action$ $Result$ define nodes states edges actions.In tree, we record from point view $MAX$ agent.Though well-defined finite amount it, better thought theoretical construct can’t realize physical world many Go $10^40$ nodes, tic-tac-toe more than $3times 10^5$ nodes). We usually use term represent extracted full contains enough determine what make.5.2 Optimal Decision GamesIn scene, MAX agent must find contingent strategy. An optimal strategy leads outcomes at least good other when playing infallible opponent. graph above, maximum node $A$ 3, change choice MIN agent, worst situation (no matter choose, will always select successor min MAX), takes $a_1$.In theory, combine “one move”, call half-moves “ply”.Given determined mini-max each node. assuming both play optimally end game.$$MINMAX(s) = begin{cases}Utility(s) &amp;amp; text{if }TERMINAL-TEST(s)max_{ain Action(s)}{MINIMAX(RESULT(s, a))} }Player(s) MAXmin_{ain MINend{cases}$$The image above shows decision root tree: $a_1$ because highest value. maximize worst-case outcome MAX.Other strategies may do suboptimal but case, necessarily worse decision.5.2.1 Mini-max AlgorithmThe algorithm computes state. recursion proceeds way down leaves then back up back.def minValue(s) -&amp;gt; int: &quot;&quot;&quot; return minimum achieve s assume this agent&#39;s TERMINAL_TEST(s): UTILITY(s) minVal float(&#39;inf&#39;) ACTION(s): min(minVal, maxValue(RESULT(s, a))) minValdef maxValue(s) maxVal -1 * max(maxVal, minValue(RESULT(s, maxValdef mini-maxDecision(s) Action: Return resAction None maxMinimax a)) &amp;gt; maxMinimax: resActionThough discuss zero-sum alliances still Collaboration emerge purely selfish behavior.5.3 Alpha-Beta PruningWhen algorithm, have travel DFS. explore grow exponentially depth grow. Though eliminate exponential time complexity, effectively reduce its size by applying pruning methods.Here, apply alpha-beta on standard tree. It would prunes away branches possibly influence decision.The idea comes very simple observation some cases, don’t need successors’ utilities calculate For instance, fig see $C$ 2, know smaller $B$’s (which 3) (dash line) under $C$.If Player $n$, $n$ never reached actual play. Therefore, once information about reach conclusion, prune it.Below general case pruning:$alpha=$ best (max-value) found far any along path MAX$beta=$ (min-value) MINAlpha-beta update $alpha$ $beta$ goes remaining soon or respectively.def maxValue(s, alpha, beta) returns integer (or last before pruned) mini-maxVal float(&quot;inf&quot;) max(mini-maxVal, a), beta)) &amp;gt;= beta: # Since optimal, scnerio occur following expansion pruned mini-maxValdef minValue(s, min(mini-maxVal, &amp;lt;= alpha: (as exist path) mini-maxValue mini-maxValueTo start searching root, maxValue(root, float(&quot;inf&quot;), float(&quot;inf&quot;))5.4 BacktrackingBacktracking space. When space, sometimes sure solution haven’t sequence.Suppose 4 sequence, lose only 2 yet. stop go previous step choose another (this reason why Backtracking)The effect backtracking significant identify whether not goal shallower such situation, much space pruned.A famous solved Backtracking “eight queens” problem. Detailed description (n-queen problem) link: UVA-11195 Another n-Queen Problem.def nQueen(state, currCol): currCol == len(state): 1 resultState 0 candidate range(len(state)): isValidState(state, candidate, newState state[:] newState[currCol] += nQueen(newState, + 1) resultStatedef currColumn): state: False queens row i, position enumerate(state): i currColumn: break abs(position candidate) (currColumn i): diagonal True"
    },
    {
      "title"    : "CS188 Chapter 3 Searching Methods",
      "url"      : "/blog/2021/CS188-Chapter3.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-02-28 00:00:00 +0000",
      "content"  : "The Relationship between Searching and AI As we have mentioned in chapter 1 2, an Intelligent Agent can maximize the utility a given environment by control its behavior. Algorithm is very useful algorithm to find sequence of actions that will utility. Terminologies **Term** **Explanation** State One status environment, which be represented using series parameters Space All states have. state space either finite or infinite. Action behavior Agent. Usually change (note: not *always*). Fringe about explore (expand) searching algorithm. Transition Function function describe how each other (how transit). Successor directly resulted from current state.$text{currState}quad underrightarrow{Action} quad text{Successors}$ 3.0 How do We Evaluate Search AlgorithmWe evaluate method several aspects, as shown below: Consistency, with Goal it, MUST able action leads goal state. Optimality, Given has Best Sequence lead Time Complexity, much computation time it takes for many memories uses State. 3.1 Breadth First (BFS) BFS both Consistent Optimal.In algorithm, shallowest expanded first.Due this feature, when there are multiple space, always Therefore, all same cost, least cost.The fringe Stack where FIFO policy applies.Code Exampledef breadthFirstSearch(initialState, getSuccessor, getValidActions): &quot;&quot;&quot; :param initialState: Initial problem (sometimes &#39;current state&#39;) getSuccessor: return successors getValidActions: A list valid under = stack() exploredStates set() # Add into before Actually Start. fringe.push(initialState) while len(fringe) &amp;gt; 0: currState fringe.pop() if exploredStates: continue else: exploredState.add(currState) Do Something Here getValidActions(currState): States successor getSuccessor(currState, action) fringe.push(successor)Pros Cons Pros **The Optimality Result** - nearest first **High Complexity** requires memory maintain fringe. Suppose $3$ successors, on tree height $10$, size $3^{10}approx 60000$. (Space Complexity $O(m^n)$) **Easy implement** no complex data structure required, foundation most algorithms at depth $n$, average $m$ complexity $O(m^{n+1})$ 3.2 Depth (DFS) DFS only Consistent, OptimalThe expand Deepest node spaceDepth need Much Less search nodes specific comparing BFS, but great since Optimal. In words, optimal solution first.In DFS, Queue, applies policy.def depthFirstSearch(initialState, queue() difference fringe.push(successor)3.2.1 Deep Limited Search3.3 UCS Uniform Cost SearchThere common DFS: They don’t care ACTUAL COST Though Shortest state, shortest may lowest like example below shows: number inside grid cost go through grid, $S$ initial $G$ case, $A$ Higher min-cost $A^*$.To solve problem, use ALWAYS minimal cumulative cost. To implement priority queue, weight sort queue.This strategy somehow similar used Min Span Tree.def uniformCostSearch(initialState, getValidActions, getActionCost): getActionCost: [] Instead storing fringe, tuple store 0th param 1th heapq.heappush(fringe, (0, initialState)) 0 heapq.heappop(fringe) deltaCost getActionCost(currrState, heapq.heappush((cost + deltaCost, successor))In Python, queue implemented internal library heapq. Tree v. Graph two types algorithms. graph theory loop transition space. any explored NEVER again. Search, hand, does record Every node, added cycle redundant part graph, exists more than one way get another. Symbols Used Symbol Meaning $f(n)$ evaluation $n$ $g(n)$ total (node) $h(n)$ heuristic estimate $c(n, a, n’)$ actual getting $n’$ $a$ 3.4 Informed SearchGreedy form informed search, is, information definition solutions efficiently uninformed strategy.Among greedy general approach.Each evaluated $f(n)$. $f(n)$’s value considered estimate. Greedy first. For function, (denoted $h(n)$) helps state.$$h(x) text{The estimated cheapest path } n text{ State}$$A non-negative, constraint: then $h(n) 0$.3.4.1 Best-first $h(x)$. That equal $h(x)$.A simple best-first search’s version incomplete even It’s complete space.If branching factor $alpha$, Search’s version’s worst $O(alpha^m)$, maximum However, rely quality function.3.5 A* SearchA* evaluates combining $g(n)$, reach $h(n)$, goal. written form:$$ f(n) g(n) h(n) $$In $n$.Provided satisfies certain conditions, optimal.The identical Uniform-Cost-Search except $g(n) h(n)$ $g(n)$.3.5.1 Conditions optimality: Admissibility ConsistencyAdmissibilityThe $f(n) g(n)$, admissibility means Never Overestimate along $n$.ConsistencyThe consistent every generated $a$, reaching greater step plus $n’$.$$h(n) leq c(n, n’) h(n’)$$*3.6 Prove admissible. consistent.Below show proof second argument. Lemma If consistent, values non-decreasing.Suppose $g(n’) some $a$. have$$f(n’) g(n’) h(n’) geq f(n)$$ Whenever selects expansion, been found.Suppose case exist passing lower conflict: Accroading lemma 0, nondecreasing, $f(n’) f(n)$, selected algorithm.From these lemma, draw conclusion non-decreasing order g(n)$ (as 0$), so must minimum $g(n)$."
    },
    {
      "title"    : "CS188 Chapter 2 Intelligent Agents",
      "url"      : "/blog/2021/CS188-Chapter2.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-02-28 00:00:00 +0000",
      "content"  : "Chapter 2 Intelligent AgentsIn chapter 1, we have mentioned the concept of rational agents as central approach to artificial intelligence, where are systems that can be reasonably called intelligent.2.1 Agents and Environmentsagent is anything viewed perceiving its environment through sensors acting upon actuators.We use Percept refer agent’s perceptual inputs at any given instant, a program’s Sequence complete history everything agent has perceived. An choice action instant depend on entire percept sequence observed date, but not it hasn’t perceived.We say behavior described by function maps an action.$$Percepts rightarrow Agentspace Function(Percepts) Actions$$Agent for will implemented program.It should noticed abstract mathematical description, program concrete implementation, running within some physical system.Model’s building up:Let’s suppose space ‘vacuum-cleaner world’, shown in figure belowThere two areas, area A B, dirt appear both rooms.The vacuum cleaner ‘Suck’, ‘Go Right’ Left’.Artificial Intelligence operates artifacts significant computational resources task requires nontrivial decision-making.2.2 Good Behavior: The Concept RationalityA one does right thing. We define standard ‘doing thing’ considering behavior.If desirable, then performed well.Performance Measure process evaluate whether state seen ‘desirable’.Notice talking about Environment Status, Agent StatusAs general rule, better design performance measures according what actually wants environment, instead thinking agent."
    },
    {
      "title"    : "CS188 Chapter 1 What is AI",
      "url"      : "/blog/2021/CS188-Chapter1.html",
      "tags"     : "Machine Learning",
      "date"     : "2021-02-25 00:00:00 +0000",
      "content"  : "1.1 What is AIThere are different kinds of definition on ‘what an artificial intelligence’, which shown below:   Humanly Rationally Thinking Acting The column ‘humanly’ measures the success in terms fidelity to human performance, other word, how alike AI comparing a real being.The ‘rationally’ ideal called rationality. ‘rationality’ system that doing ‘right thing’.Rationality: Maximizing expected revenue.1.1.1 Humanly: Turing Test ApproachTerm Definition designed provide satisfactory operational intelligence.A compouter passes test if interrogator (Someone who ask question program and people), after posing some written questions, cannot tell whether responses come from person or computer.A can pass should have these components: Natural Language Processing: ability Communicate Knowledge Representation: Store what it knows hears Automated Reasoning: Use Stored information Answer Questions draw new conclusions Machine Learning: Adapt circumstances detect Extrapolate patternsThe does not allow physical contact with itself since unnecessary. However, Total robot limited ways.To Test, need additional Computer Vision perceive objects Robotics manipulate move aboutAt beginning, we try mimic brain. necessary make ‘Artificial Intelligence’ really look like being.Though, learn brain get useful characteristics produce intelligence.Two important characteristics: Memory StimulationLike aircraft, only extract characteristic being’s thinking process but ‘look like’ beings.1.1.2 Cognitive Modeling ApproachIn order let computer ‘think human’, first know actual working minds. And here use Science Artificial Intelligence.The brings together models experimental techniques psychology construct precise testable theories mind.1.1.3 Rationally: ‘Laws Thought’ ApproachThe Greek philosopher Aristotle was people law thought. His syllogisms (三段论) provided patterns for argument structures always yield correct premises.However, there two main obstacles this approach. It easy take informal knowledge state formal required by logical notation, particularly when 100% certain There big difference solving problem ‘in principle’ practice’. These points obstacle apply any attempt build up computational reasoning system.1.1.4 Rational Agent ApproachA rational agent one acts achieve best outcome, or, exists uncertainty, outcome.Making Correct Inference Part being agent. Since situations, no provably things do*, something still has be done.The goal building much more approachable Laws Thought standard Rationality perfectly defined Mathematic, very General.Perfect Rationality, implies will do thing possible all situations. easier Limited acquire acting appropriately enough time computations might like.1.2 Foundations Intelligence1.2.1 Philosophy Can rules used valid conclusions? How mid arise brain? Where from? lead Actions?These been thought 384 B.C..Aristotle provides Syllogisms, principle generate mechanically initial conditions given.Many years later, Vienna Circle, theory Logical Positivism up, claimed characterized connected.Conformation analyze acquisition experience. Carnap Explicit Computational Procedure extracting elementary experiencesAfter that, begin concern Actions justified connection between goals action’s outcome. Though quite true us Intelligence, doesn’t say several actions action completely.1.2.2 Mathematics computed? reason uncertain information?Though foundation intelligence philosophy, uses theorems science.It based three areas mathematics: Logic, Computation, Probability.The logic developed also Aristotle, First Order Logic till now invented 18th century. In 1931, Godel’s Incompleteness Theorem(哥德尔不完备性定理) showed as strong Peano Arithmatic（皮亚诺公理系统）, True Statements UNDECIDABLE sense they prove within theory.About Computable Problem, Alan imagine kind machine ‘Turing machine’, compute computable given function’s solution, then he were functions compute. For example, general return answer run forever.Comparing Computable, Tractability fact important. A Intractable complexity solve Exponential, problems intractable NP Problem. If solved $O(2^n)$, ‘NP - Complete’Besides computation, another part mathematics Probability. As Thomas Bayes proposed rule updating probabilities light evidence, fundamental basis nowadays Uncertain Reasoning.1.2.3 Economics decisions maximizing payoff? others may go along? payoff far future?Economics consisting individual agents their own economic well-beingThe economists ‘utility’ help decision, means choose step most benefit itself.Decision Theory, combines probability utility theory, complete framework decisions.The Division Theory ‘large’ situation, is, affect whole environment’s status.When ‘small’ Game change environment its decisions.A game where player significantly another.It proven specific games, better adopt policies (at least looks like) Randomized.Operation Search decision finding solution particular needs complex management decisions.After find class sequential Markov Decision Process.Like said before, many either impossible nor inefficient ‘Best’ making ‘good enough’.1.2.4 Neuroscience brains information?Neuroscience study nervous system, People mathematical system.People modeling tool neuron science.People conclude collection simple cells thought, consciousness1.2.5 Psychology humans animals think act?Cognitive Psychology, views processing device.Craik specified key steps agent: stimulus must translated into internal representation manipulated cognitive derive representations. turn retranslated action.1.2.6 Engineering efficient computer?1.2.7 Control Cybernetics artifacts operate under controlPeople behavior arising regulatory mechanism trying minimize ‘error’, current state.People homeostatic devices containing appropriate feedback loops stable adaptive behavior.Tools inference computation allowed researchers consider such language, vision, planning fell completely outside control theorist’s preview.1.2.8 Linguistics language relate thought?Born ‘AI’, interesting hybrid field linguistics Processing (NLP). Then soon out understanding requires subject context, just structure sentences."
    },
    {
      "title"    : "USACO 2017 Dec Gold Analysis",
      "url"      : "/blog/2020/USACO-2017-Dec-Gold.html",
      "tags"     : "Algorithm",
      "date"     : "2020-12-10 00:00:00 +0000",
      "content"  : "Problem 1. A Pie For PieProblem DescriptionBessie and Elsie have each baked $N$ pies pie has two tasty value - one from Bessie Elsie. In the begining, gave a to Elsie.If receive that she think of $n$, will try give back her is in range $n leq n’ n + D$. If such does not exist, ‘exile’ herself.If Elsie, same thing happen.Such cycle continue, until cow exile herself or they 0 for them. input case, we solve minimum number could be gifted happy gift exchange started with Bessie’s $i$. no $i$ happy, then should print out single integer $-1$ instead. :warning: Notice can only sent once can’t send other sent.Proposed SolutionIn this question, use bottom-to-up method. Instead checking how many exchanged given beginning pie, search reversely end point start point. way, apply on all get result time complexity $O(1)$ query.The actual program work like Sort Search taste both While searching, store query, find stored corresponding index.Time Complexity AnalysisThe steps above $O(nlog{n})$ $O(n)$ query total $O(n)$."
    },
    {
      "title"    : "USACO 2017 Feb Gold Analysis",
      "url"      : "/blog/2020/USACO-2017-Feb-Gold.html",
      "tags"     : "Algorithm",
      "date"     : "2020-11-26 00:00:00 +0000",
      "content"  : "Problem 1. Why did the Cow Cross RoadProblem DescriptionBessie cow wants to move from upper-left corner of field bottom-right field. Each time it goes one grid other, $T$ unit will be consumed. Bessie pass through 3 grids, she stop at and begin eating. The eating in each is different provided input.$3 leq N 100, 0leq Tleq 1times 10^6$Proposed SolutionThe first thought on this problem solve by using Unified Cost Search (UCS). By maintain a fringe Priority Queue that sorted according consumes arrive specific position, promised state we have met arrived destination LEAST destination.Therefore, can represent State $S$ formState newState = new State(Time, num, x, y);And accordingly, transition function somehow like thispublic ArrayList&amp;lt;State&amp;gt; StateTransition(State currState){ int currTime currState.getTime(); num currState.getNum() + 1; currX currState.getX(); currY currState.gety(); nextStates ArrayList&amp;lt;&amp;gt;(); Move[] validMove this.getValidMove(x, y); for (Move : validMove){ nextTime currTime; int[] change move.getChange(); nextX change[0]; nextY change[1]; if (num % == 0){ += this.Time[nextX][nextY] } nextStates.add(new State(nextTime, nextX, nextY)); }}*NOT Pure UCSSpecifically, question, access has already accessed avoid grass extremely consuming. Therefore, should not use HashMap object exclude explored states simply.However, set visited lead EXTREMELY LARGE FRINGE. Suppose there exist where required eat $T$, while all other fields requires $30T$ grass.30T 30T ... 30T30T T ...30T30T 30T...30T 30TIn case, pure UCS algorithm without excluding repeated explore with repeatedly 30 times (after times, (1, 1) top PQ), which build tree height before exploring states. Since 4 average, size approx $4^{30}$! This definitely TLE need pruning.Reconsider state, know defined two variables - Position Number 3. construct an array $T_{rec}$ $Ntimes Ntimes 3$, $T_{rec}[x][y][i]$ represents minimum takes get position (x, y) step remainder $i$ (somehow similar Dynamic Programming). If getTransitionStates same y, i more time, simply discard does add into fringe.Time Complexity AnalysisSince iterate bounded explicitly explicit relationship between data scale number iteration, hard calculate accurate complexity. Below, try estimate upper bound.First, are $N^2$ vertexes graph, suppose node $N$ (which over-estimation), complexity travel graph $O(N^3)$. push pop priority queue maintained binary heap, &amp;amp; $O(log n)$. overall less than $O(N^3 log(n))$.Since $3leq Nleq 100$, log{n})$ acceptable.import java.util.*;import java.io.*;public class USACO2017FebGold1 { public static void main(String[] args) throws IOException{ BufferedReader br BufferedReader(new FileReader(&quot;visitfj.in&quot;)); PrintWriter pr PrintWriter(new BufferedWriter(new FileWriter(&quot;visitfj.out&quot;))); // Read StringTokenizer st StringTokenizer(br.readLine()); Integer.parseInt(st.nextToken()); int[][] int[N][N]; int[][][] timeRec int[N][N][3]; (int x 0; &amp;lt; N; ++){ y z 3; timeRec[x][y][z] Integer.MAX_VALUE; j grid[i][j] leastTimeResult -1; PriorityQueue&amp;lt;State&amp;gt; PriorityQueue&amp;lt;&amp;gt;(); fringe.add(new State(0, 0, 0)); (!fringe.isEmpty()){ currState fringe.poll(); /*if (currState.getX() 1 &amp;amp;&amp;amp; currState.getY() 1){ break; destination, least STOP further searching }*/ (State nextState getTransitionState(currState, N, T, grid)){ (isBetterSolution(nextState, timeRec)){ fringe.add(nextState); timeRec[nextState.getX()][nextState.getY()][nextState.getNum()%3] nextState.getTime(); Math.min(timeRec[N-1][N-1][0], timeRec[N-1][N-1][1]); Math.min(leastTimeResult, timeRec[N-1][N-1][2]); pr.println(leastTimeResult); Close Buffered Reader Writer prevent memory leak. pr.close(); br.close(); boolean isBetterSolution(State nextState, timeRec){ return (nextState.getTime() timeRec[nextState.getX()][nextState.getY()][nextState.getNum()%3]); getTransitionState(State currState, grid){ nextNum currState.getY(); ArrayList&amp;lt;String&amp;gt; validMoves getValidMoves(currState, N); result (String validMoves){ currTime;int nextX; nextY; switch (move) case &quot;L&quot;: 1;nextY currY;break; &quot;R&quot;: &quot;U&quot;: currX;nextY 1;break; default: (nextNum 0) grid[nextX][nextY]; T; result.add(new nextNum, result; getValidMoves(State N){ (x &amp;gt;= result.add(&quot;L&quot;); N) result.add(&quot;R&quot;); (y result.add(&quot;U&quot;); result.add(&quot;D&quot;); }}class implements Comparable&amp;lt;State&amp;gt;{ private final time; num; x; y; State(int this.time this.num this.x this.y getTime() getNum() getX() getY() compareTo(State otherState){ otherState.getTime(); //return (otherState.getX() * otherState.getY() this.y); @Override String toString(){ &quot;( &quot; ), num&quot; &quot;&quot;; hashCode(){ this.y; equals(Object o) (this true; (o null || getClass() != o.getClass()) false; (State) o; state.x state.y; }}Problem 2. Did Road IIProblem DescriptionJohn breeds cows pastures both sides road separately. Now, side side. breed ID. Only difference breed’s IDs smaller 4, “friendly” other.Given pasture only most link another no links cross over what maximum draw pastures?Proposed SolutionIn problem, fact finding out maximized valid pairs pasture. last (right link) $(a, b)$, $a$ $a^{th}$ row $b$ $b^{th}$ lower row. We notice left b)$ affect right b)$.Therefore, dynamic programming problem. Build up table N$, $T[a][b]$ b)$.Time AnalysisThe total solution $O(N^2)$. $0leq 1000$, finished seconds.Problem IIIProblem DescriptionThe John’s farm circular $2N$ points / Everyday, go door every used once (either out). John collected doors cows. He “cross over”. For instance, $1$ $3$ $2$ $4$, they over”.Proposed SolutionWe Binary Index Tree here problem.First, length initialized 0. Then, loop possible in/out gates. When passed point, do these things: Check point belongs yes, update current index previous gate Calculate sum BIT range $(text{previous gate}, text{current gate})$. not, value 0 import java.io.*;import java.util.*;public USACO2017FebGold3 FileReader(&quot;circlecross.in&quot;)); FileWriter(&quot;circlecross.out&quot;)); Integer.parseInt(br.readLine()); cowInfo int[2 N]; 2; cowInfo[i] HashMap&amp;lt;Integer, Integer&amp;gt; positionRec HashMap&amp;lt;&amp;gt;(); rec BIT(new N]); cowInfo[i]; (positionRec.keySet().contains(breed)){ rec.updatePoint(positionRec.get(breed), 0); rec.getSum(positionRec.get(breed), i); else{ positionRec.put(breed, rec.updatePoint(i, 1); pr.println(result); }}Time calculation $O(log{n})$ , $O(nlog{n})$.Since $1leq n 50000$, acceptable."
    },
    {
      "title"    : "Binary Index Tree (Fenwick Tree)",
      "url"      : "/blog/2020/Binary-Index-Tree.html",
      "tags"     : "Algorithm",
      "date"     : "2020-11-13 00:00:00 +0000",
      "content"  : "Why we Need Binary Index TreeTraditional Approach 1在实际生活中，我们常常需要计算一个给定array 特定范围内所有数的和。如果只有这一个需求的话，我们可以很方便的构建出一个静态的数组来达到$O(1)$的时间复杂度。在这样的一个数组中，每一个位置上的数符合：$$text{arr}[n] = text{arr}[n - 1] + x[n]$$$$text{arr}[0] x[0]$$这样，当我们需要计算数列x中m到n的数字的和时，我们只用计算 arr[n] arr[m]就可以了。然而，与计算的超高性能相比，这种方法要求我们操作的数列x是基本保持不变的，一旦x中的某一个值发生了变化，我们就要更新一次整个arr数组，这直接导致了修改的$O(n)$复杂度。Traditional 2如果我们想要我们的数据结构可以接受大量的修改，我们也可以使用一个更加朴素的方法 我们只存储数列x，每次要计算区间和时，我们就遍历一次整个区间从而计算区间内所有元素的和。使用这种朴素的方法，虽然计算区间和的复杂度位$O(n)$，每次我们对数组x进行修改却不需要额外的操作，只有$O(1)$的复杂度。Why Traditional Fail我们知道，一个算法的时间复杂度是由算法中最耗时间的步骤所决定的，也就是说，如果我们在一个循环中同时需要查询数组x的区间和并且修改x，那么整个循环内的时间复杂度会由其中最耗时间的步骤决定 $O(n)$。二进制索引树被设计出来处理这种情况，它很好的在两种传统方法间做出取舍，使得我们可以同时以$O(log{n})$的时间复杂度进行数组的修改和区间和查询操作。Data Structure BIT虽然BIT的名字是“二叉索引树”，实际上在程序中，我们并没有使用一个“树”的结构去存储BIT对象，而是将其放在一个数组中，这种结构被称为“树状数组”，许多树结构也使用了这样的形式 例如二叉堆模型。这是一个BIT数据结构的内部属性：public class BinaryIndexTree{ private int[] tree; val; // ... }BIT之所以中间有一个“index”，是因为BIT的构造和操作过程中都要使用索引的一个属性 索引( 1后)二进制中最后一个1的位置。Helper Function Least Significant One在 Java 中，我们可以写一个这样的函数来找到整数二进制最后一位的1在哪里：public int findLastBinaryOne(int index){ String binaryIndex Integer.toBinaryString(index 1); for (int i binaryIndex.length() 1; &amp;gt; -1; --){ if (binaryIndex.substring(i, 1).equals(&quot;1&quot;)){return i;} } return -1;}通过计算索引 1后的二进制的最后一位1在哪里，我们可以得到BIT中这个位置的节点在树中的高度。Construct BIT如果findLastBinaryOne 返回为1，数组中这个位置是BIT的叶子节点，只存储输入数列x在这个位置的值（例如在下图中的 index 0, 2, 4, 6, …）的位置。如果findLastBinaryOne(index)的返回是n 且$n 1$，在BIT中，这个位置的值等于x中这个位置的值加上BIT[index 2**0]， BIT[index 2 ** … (n 2)]假设我们计算BIT中一个位置的值（假设BIT树中前面的值都是正确的），我们可以这样写：private getBITVal(int i){ //return the BIT value on sum 0; power pos i; maxPower this.findLastBinaryOne(i); while (i &amp;gt;= 0 &amp;amp;&amp;amp; &amp;lt; maxPower){ (power == 0){sum += this.val[i];} else{sum this.tree[i];} pos; -= （int) Math.pow(2, power); ++; sum;}因为每次我们调用getBITVal函数的时候我们都假设BIT中左侧的地方已经被初始好了，当我们初始化整个BIT时，我们需要从左到右的计算数组中每一个位置的 BIT值private void initializeBIT(){ this.tree.length; ++){this.tree[i] this.getBITVal(i);}}考虑到每次调用getBITVal都需要$O(log{n})$的时间复杂度，我们初始化整个BIT数组的时间复杂度会是$O(n log{n})$。虽然高于传统方法的$O(n)$，但是考虑到一般初始化代码只会执行一次，这个时间复杂度是可以接受的Get Sum from BIT我们现在已经有了BIT，那么我们怎么使用它查询一个区间内的元素和呢？首先，我们先看如何通过BIT查询 index的区间和。观察上面的图，我们不难发现，一个BIT并不是单独的一棵树，而是很多棵子树所构成的，每个子树的根节点代表它所有叶子节点的和。那么，如果我们要计算0 index的区间和的话，我们只需要找到index的二进制，然后每次去掉其中排在最后的一个1即可。（对应的是index前的根节点） 例子：如果我们需要计算 6之间的区间和，我们要 binary (6 1) 1011 tree[1011] tree[1010] tree[1000] tree[7] tree[6] tree[4] 用java代码表示，就是这样：public getSum(int endIndex){ if(endIndex 0){return this.tree[0];} while(endIndex 0){ this.tree[endIndex]; endIndex (int) this.findLastBinaryOne(endIndex) sum;}注意到循环的执行次数最大为索引二进制数的长度，也就是$log_2{text{index}}$，这说明调用一次getSum函数只会有$O(log{n})$的时间复杂度有了从0到index的区间和，我们就可以很方便的计算出任意两个索引之间的区间和（因为同是求区间和，这里直接重载了之前的getSum函数）public startIndex, this.getSum(endIndex) this.getSum(startIndex);}Update Tree前文提到过BIT最大的优势是在保证快速求出区间和的同时可以快速进行数据结构的更新，接下来我们看看BIT是怎么进行数据结构的更新的：如果我们想要更改this.val中的数据，我们必须更新其对应的树结构。因为BIT中兄弟节点是互不影响的，我们只用更新被更新索引所在的BIT树的所有父节点就可以了。因为树的高度取决于索引二进制的长度，总共需要更新的节点数量的上限为$O(log{n})$，用Java代码可以这样写：private ArrayList&amp;lt;Integer&amp;gt; getParents(int parents new ArrayList&amp;lt;Integer&amp;gt;(); (true){ currStep this.findLastBinaryOne(index) currStep; if(index this.tree.length){break;} parents.add(index); parents;}public updatePoint(int index, newVal){ this.tree[index] this.val[index] newVal; this.getParents(index); parents.size(); ++){ this.tree[parents.get(i)] this.getBITVal(parents.get(i)); }}（上面的代码因为每个父节点更新都调用了一次getBITval函数，实际上的时间复杂度是$O((log{n})^2)$， 通过修改实现方式，我们可以达到 $O(log{n})$ 的时间复杂度）"
    },
    {
      "title"    : "USACO 2017 Jan Gold Analysis",
      "url"      : "/blog/2020/USACO-2017-Jan-Gold.html",
      "tags"     : "Algorithm",
      "date"     : "2020-11-11 00:00:00 +0000",
      "content"  : "Problem 1 Balanced PhotoLink to ProblemProblem SummaryJohn want arrange his $N$ , $1leq N leq 100,000$ cows take a photo. The height of $i$th cow is $h_i$. the heights all are distinct. In line, called “unbalanced” if number that higher than it on left two time (or half of) lower it. Given line cow, give out unbalanced in photo.Proposed SolutionFirst, we can range from high low, and fill array with cow’s height.cows = [34, 6, 23, 0, 5, 99, 2]arr [_ for _ range(len(cows))]arr.sort(key=lambda x: cows[x])After doing this, initialize new list used store whether has been counted. will be filled 0.l [0] * len(cows)After apply following steps, suppose dealing $k$th highest where cows[k] nTo decrease complexity solution, use data structure Binary Index Tree (BIT) $l$. Using BIT, calculate $L$, $R$, update $l$ $O(log{n})$. Calculate $L sum_{i 0}^n l[i]$. Since process shortest, result formula current stands its left. $R k - there $k-1$ one. NOT must stand right. Calculate$$frac{min{(L, R)}}{max{(L, R)}}$$If greater 2, add by 1. Set value $l[n] 1$. Time Complexity Analysis sorting $O(nlog{n})$ Travel through $O(n)$ L, R, $l[n]$ $O(log{n})$ Therefore, total $O(nlog{n})$.Problem 2. Hoof, Paper, ScissorsProblem SummaryHoof Paper Scissors game like paper, scissor, stone. game, Hoof &amp;gt; Scissors, Hoof. Bessie know sequence gesture Farmer John, but only change $k$ times, less 20.Given farmer John maximum ($k$) Bessie, what games win?Proposed SolutionWe dynamic programming solve this problem. First, noticed three variables needed represent state Bessie. using won gestureTherefore, build up 3D $T$ size $3times times k$, have. $T[0][n][k]$ win when “Hoof” at $n$th changed times.Suppose have function isWin(gesture, n) return win. If wins, 1; otherwise, 0. Then whole table these equations:$$begin{aligned}T[g][n][k] max{left( T[g][n-1][k]+ isWin(g, n),;T[(g+1)%3][n-1][k-1]+ n),;T[(g + 2)%3][n-1][k-1]+ right)} end{aligned}$$If either $n$ or bound (not $T$, 0.After calculating table, should check elements slice $T[][N][]$. (the may not require change). final k$ values.Time AnalysisSince Nleq kleq 20$, construct $3times100,000times20 6times 10^7$. need our program $1times 10^8$ computational steps $O(kN)$. edge TLE, Java problem.Problem 3. Cow NavigationLink SummaryBessie barn John. $Ntimes N$, some square cells impassable. starts lower-left corner (cell 1, 1) wants move right N, N).In each second, go forward, turn left, one instruction let enter an impassable square, skip instruction. At beginning, doesn’t she facing You shortest directions guide her goal regardless which case true. Once reaches goal, ignore further commands.Proposed SolutionThe difficult point problem don’t position make sure arrive destination. situation, series instructions same, BFS situation simultaneously.In BFS, “sub-state”, direction start pointing upward rightward. We also set reach same shorter length, series.We 4 4$. first part 4$ DP sub-state. second DP-table sub-state.The transition follow rules: $$T[S_1, S_2] min{(T[S_1, S_2], T[S_1’, S_2’] 1)}$$ $$Update(S_1, S_2) S_1, S_2’ text{ $S_1$ state}$$ S_1’,S_2 $S_2$ get into square}$$ AnalysisTherefore, search graph $O(N^4)$ nodes. (For sub-state, $N^2$ nodes, though most time, sub-states position, overall upper $O(N^4)$). $0leq proposed solution fast enough."
    },
    {
      "title"    : "USACO 2016 Dec Gold Analysis",
      "url"      : "/blog/2020/USACO-2016-Dec-Gold.html",
      "tags"     : "Algorithm",
      "date"     : "2020-11-06 00:00:00 +0000",
      "content"  : "Problem 1 Moo-castProblem SummaryCows want to communicate with each other by walkie-talkies. It is known that a walkie-talkie costs $X$ dollars will have broadcast radius of $sqrt{X}$. Given the location all cows in form $(x, y)$ coordinate, what minimum cost buy such every cow can (may not be directly but through several ‘hops’).Proposed SolutionBasically, we find this question greatest shortest distance between different points. For point, connect The amount money required ‘shortest distance’.However, requires more than this, since linking point nearest may lead subgraphs are connected other.Therefore, simply traverse possible pair and calculate their square if they same graph. Below draft codePoints = [(x1, y1), (x2, y2), ..., (xn, yn)]X -1for p1 range (len(Points)): Points[p1] for p2 (p1 + 1, len(Points)): b Points[p2] InSameGraph(a, b): X max(X, math.sqrt((a[0] - b[0])**2 (a[1] b[1])**2)return XThe function InSameGraph implemented storing points UFDS. With appropriate path compression methods, time complexity bound approx. $O(log{n})$.Time Complexity AnalysisThis proposed algorithm has $O(n^2log{n})$. Since number $n$ no 1000, computational step solution should $1times 10^7$, which means it use 4 sec run.Problem 2. Cow ChecklistProblem SummaryThere two types cows, noted as type H G. There $H$ $G$ However, John must access order from $H$, G $G$.The position given x-y moving $d$ energy $d^2$, consumption cows.Proposed SolutionWe dynamic programming solve problem. Let $E[0][h][g]$ represent consume visit $h$ H-type $g$ G-type finally stop at cow. $E[1][h][g]$ cow.Then, whole table.$$E[0][h 1][g] min(E[1][h][g]+Dist(G_g, H_{h+1})^2,, E[0][h][g] Dist(H_h, H_{h+1})^2)$$$$E[0][h][g+1] G_{g+1})^2,, G_{g+1})^2)$$… (the equation another 2 situations omitted)By doing so, result $E[0][H][G]$, final (since end his walk cow).Time AnalysisSince calculating one table $O(1)$, total $O(HG)$. Because $1leq Hleq 1000$ $1 leq 1000$, require most 10^7$ steps, Python 3 run sec.Problem 3. Lasers MirrorsProblem direct laser barn. can’t move generator. Therefore, decide install set mirrors change direction on fence post. generator, barn, posts, output reflection pass arrive barn.Proposed see post field lines, horizontal vertical. Each help us line vertical (and vice versa).We breadth first search (BFS) here. property BFS makes sure found path, break out loop long path. pseudocode like this:# Line (coordinate, horizontal?, reflectTime)fringe LinkList()fringe.append((x1, True, 0), (y1, False, 0))exploredEdge set()result -1while len(fringe) &amp;gt; 0: currEdge fringe.pop() (currEdge[0], currEdge[1]) exploredEdge: continue exploredEdge.add((currEdge[0], currEdge[1])) isResult(currEdge): currEdge[2] newEdge getTransitionEdge(currEdge): fringe.add((newEdge[0], newEdge[1], 1)) # changing edge been reflected time, also, (must be) changed after reflectionprint(result)Since there 10^5$ $O(n log{n})$. itself $O(n)$, implement isResult getTransitionEdge functions $O(log n)$.Here ways these functions:isResult its $y$ value equals $y_2$ or $x$ $x_2$, destination. This operation done $O(1)$.getTransitionEdge Here, need dictionaries us. One dictionary x-coordinate key, list y-coordinates. Another y-coordinate x-coordinates. When line, y -&amp;gt; x dictionary. $O(m)$, where $m$ values key.Time AnalysisThe $O(mn)$, Maximum posts posts. do exist some extreme case $mapprox n$. Under case, however, greatly decreasing, depth tree decrease drastically.Therefore, program able give less cases."
    },
    {
      "title"    : "Elliptical Curve Signature Algorithm",
      "url"      : "/blog/2020/Elliptical-Curve-Signature.html",
      "tags"     : "Cryptocurrency",
      "date"     : "2020-10-18 00:00:00 +0000",
      "content"  : "在传统的金融模型中，当人们需要在银行等金融机构中创建新的账户时，人们必须提供用于证明其身份的凭证（身份证，护照，etc）。然而，在比特币的新型隐私模型中，虽然每个账户之间的交易记录是公开的，但是账户拥有者的身份确不会被公开。为了防止比特币账户被冒用，比特币交易系统中使用了椭圆曲线签名的机制来确保账户操作者就是账户拥有者。1. 什么是椭圆曲线拥有这样的解析式的一类曲线被称作椭圆曲线:$$y^2 = x^3 + ax b$$这样的曲线拥有这如下图所示的形状：这样的曲线有两个非常重要的性质： 椭圆曲线是关于$x$轴对称的 任意一条直线只会与椭圆曲线有不超过3个交点有了这两个性质，我们可以在椭圆曲线上定义“点乘”和“叉乘”这两种运算2. 椭圆曲线上定义的运算符2.1 椭圆曲线上的加法假设我们有任意两点 $A,B$在椭圆曲线 $E$ 上，我们可以将两点链接起来得到一条直线，这条直线与椭圆曲线的第三个交点 $-C$ 。这时候，我们将得到的点 关于 $x$轴对称，得到点 $C$。 这样的一串操作可以被记录为 $A B C$如果我们把一次加法操作画在图上，那么 C$的计算过程会是下面这样：从上面的途中，我们可以发现椭圆曲线上的点乘是满足交换律的，因为点 $A,B$ 定义的直线与点 $B,A$ 定义的直线是同一条。一种特殊的情况是 A$。这样的情况下，我们得到的直线会是椭圆曲线在$A$点上的切线，也就是……2.2 椭圆曲线上的乘法如果一个椭圆曲线上进行了 $n$ 次$A A$这样的加法操作，我们可以将其简写为 $Atimes n$。例如：$Atimes 3$的计算过程可以用这样的几何方法表现出来：这个网站提供了椭圆曲线加法和乘法的可视化定义了这两种椭圆曲线上的运算以后，我们下面看看为了在计算机上更好的实现这个函数，我们都做了哪些改进。3. 椭圆曲线的改进为了在计算机上更准确的处理椭圆曲线，我们对椭圆曲线做了以下这些改进： 因为计算机内存储的浮点数都是精度有限的，为了避免浮点数溢出造成的计算误差，我们把原先定义在实数域上的椭圆曲线离散化到了整数域上 大部分编程语言中，整型变量的大小是有上限的，这个上限由程序分配多少内存来存储一个整型变量所决定，为了避免计算过程中出现过大的值从而导致整型变量溢出，我们通过模运算（取余）的方式人为定义了椭圆曲线的上界，当椭圆曲线的计算结果超出上界时，因为模运算的存在，最终结果会被映射在整型变量能够表达的数值范围中。所以，一个椭圆曲线是由这些参数所决定的：$$E text{Elliptical Curve}(p, a, b)$$这样的一条椭圆曲线拥有这样的代数表达式：$$y^2 equiv b quad (text{mod } p)$$4. 椭圆曲线与身份验证说了那么多，人们到底是怎么用椭圆曲线进行身份验证的呢？比特币所使用的椭圆函数签名协议是SECP256K1，这个签名协议中包括了一个椭圆函数 $y^2 =x^3+7$ 和一个起始点 $A$。现在，如果有一个人拥有一个数字$K$，他可以很快的用计算机算出在椭圆函数上的$Atimes K$。然而，给定$Atimes K$，计算出$K$的值却是几乎不可能的。这样一个非对称的难度让身份验证变得十分简单，只要私钥$K$的持有者不公开自己手中的私钥，其他人就几乎不可能通过私钥的生成结果$Atimes K$逆向获得私钥$K$。假如Bob要使用椭圆签名函数来验证Alice的身份，在此之前，Bob已经通过公开渠道得知Alice的公钥（椭圆函数计算结果是$Z_A$），Alice也通过公开渠道知道Bob的公钥（Bob用自己的椭圆函数私钥$K_B$计算出的结果$Z_B$）。那么Alice要做的事情就是向Bob传输$K_A times Z_B$。因为$Z_B$实际上是$Atimes K_B$的结果，我们也可以将传输的信息写作$K_Atimes K_Btimes A$。当Bob收到Alice发来的$K_Atimes Z_B$的结果后，他可以通过计算$Z_A K_B$ 并与Alice发出的结果相比对进行验证。如果对面确实是Alice在对账户进行操作，那么应该有$K_Atimes Z_B Z_A K_B$。证明如下：$$begin{aligned}&amp;amp;K_A Z_B=&amp;amp;K_A A K_B=&amp;amp;(K_Atimes A)times K_B=&amp;amp;Z_Atimes K_Bend{aligned}$$通过这样的方式，就可以在双方不透露自己私钥的情况下完成身份认证了。5. 比特币交易系统中的椭圆曲线在比特币的交易系统中，每个用户都会有一个随机生成的私钥，并且用SECP256K1算法计算出自己私钥所对应的公钥，在下面这张描述比特币交易流程的图中，最关键的部分之一就是通过上诉的身份验证算法确定确实是比特币的所有者在进行转账操作。"
    },
    {
      "title"    : "深度残差网络 Res-net",
      "url"      : "/blog/2020/Residual-Network.html",
      "tags"     : "Computer Vision, Neural Network",
      "date"     : "2020-10-11 00:00:00 +0000",
      "content"  : "在深度学习中，两个严重影响了模型效果的问题是梯度消失问题与梯度下降问题。这两个问题的出现与深度学习的根本机制 - 反向传播损失函数梯度有关。在很长一段时间里，人们认为超过100层的网络是“不可训练”的。然而残差网络 (Residual Network, ResNet) 的出现改变了这一切。通过设计“短路”机制，残差网络可以让梯度更好的在网络的层之间传播，从而使得训练500+层的超深神经网络成为了可能。相似的机制也启发了一大批拥有shortcut connection的神经网络，例如在医学图像处理领域常见的 U-net 和 Dense Net。深度残差网络 ResNet 解析论文链接 Deep Residual Learning for Image Recognition目录 什么是深度残差网络 深度残差网络解决了什么问题 深度残差网络的设计思路 深度残差网络的表现 深度残差网络与其他模型的交互1. 什么是深度残差网络深度残差网络是 Kaiming He et al. 提出的，一种运用了短路连接的神经网络形式。深度残差网络本身并没有一个固定的结构与参数，这使得深度残差网络非常灵活，可以有效的插入其他模型而提高模型表现。像下图表示的一样，深度残差网络本质上是通过在卷积层之间插入短路连接来达到传播梯度的效果。短路链接在越过了卷积层后会直接与卷积层的输出结果进行对位相加(pointwise addition)。当反向传播执行时，一半的梯度会通过短路链接直接被传导到靠后的卷积层，另一半则会加上被短路链接越过的两个卷积层的参数梯度后再传播到靠后的卷积层。通过重复叠加这样的“残差网络块”就得到了深度残差网络。2. 深度残差网络解决了什么问题在深度残差网络提出前，所有超过50层的深度学习模型都会或多或少的受到梯度消失与梯度爆炸的影响。这两个问题对模型表现的影响具体表现为模型的准确率非常不稳定，有的时候模型准确率会因为梯度过小而几乎不改变，有的时候模型准确率会由于梯度过大而急剧降低。这使得大部分的网络只能拥有较少的层数。因为每一层卷积层相当于提取一次输入的特征，层数的限制也限制了模型提取复杂特征的能力。从下图中我们可以发现，虽然理论上更深的网络可以提取更加复杂的信息，实际实验中过深的网络一般会表现的比浅网络差。虽然一些神经网络模型通过在模型中间添加额外的损失函数进行反向传播来减少梯度消失与梯度爆炸的影响，但这并没有从本质上解决问题。在深度残差网络中，通过残差网络上的短接路径，梯度可以在非常深的网络中连贯的传播而不受到过多卷积层梯度的叠加。这从本质上避免了梯度消失与梯度爆炸问题。3. 深度残差网络的设计思路残差网络的设计思路非常简单：一个深层的网络不应该表现的比浅层网络更差。基于这个考量，作者在卷积层之间加上了短路链接。本质上，短路链接可以看作是一个恒等变换。如果在训练中，两个卷积层由于种种原因没能有效提取图片中的有效特征，因为有短路链接的存在，模型整体的效果也不会被影响很多。如果两个卷积层提取到了有用的特征，那么后面的层就可以采用这两个卷积层的结果从而提高模型的表现。换句话说，如果我们的目标函数是 $H(x)$ 而输入为 $x$, 那么被短接的两个卷积层需要做的就是尽量拟合输入与目标函数之间的差距，也就是 $H(x) x$。这也是为什么这种网络被称作“残差网络， Net”的原因，每一层其实都在拟合当前输入与目标之间的差距值。一个有趣的现象是在人类的大脑中也有类似残差网络的结构出现在处理视觉信号的视觉神经中枢。在人脑的视觉神经中枢中神经元被分为5层，像一般的前馈神经网络一样，每一层都会接受前一层的处理结果并向后一层传输输出。一些研究发现，在第四层中的神经元会部分的直接与第一层中的神经元相连而跳过中间层。虽然人们目前还不完全清楚这样的结构在视觉神经中枢中的占比，但是这样的结构确实与深度残差网络结构不谋而合。[1] Wikipedia: Neural Network 4. 深度残差网络的表现在论文中，作者分别使用了两种 Block 来构建深度残差网络。一种被称作“building block”，这种block包含两个连续的$3times 3$ 卷积核，拥有较多的参数；而另一种被称作”bottleneck building block”，这种block包含三个卷积核，其中第一个和第三个是 $1times 1$卷积核，中间的是 $3times 卷积核，这样的block相对于基本的basic block来说拥有更小的参数量。通过重复使用这两种block，搭配上合适的池化函数，作者构建了若干个深度不同的深度残差网络。这些网络分别有18, 34, 50, 101, 152层，一般被大家简称为 ResNet18, ResNet34, …, ResNet152。同时，为了验证模型的短接通路对梯度传播的改善效果，作者还测试了非常极端的，拥有1202层的ResNet1202在CIFAR-10数据集上的表现。上图左侧表现了不同深度的简单卷积神经网络在数据集上的表现，我们可以发现简单的卷积神经网络随着深度的增加，错误率不降反增，表现最佳的Plain20神经网络在测试集上达到了10%的错误率。普通网络相比，在一般的深度范围内，深度残差网络的表现会随着深度的加深而提高。在中间的图中，我们可以看到深度残差网络达到了5%的错误率，比平常的前馈神经网络低了一半。5. 深度残差网络与其他类似模型5.1 DenseNet深度残差网络也启发了一些类似的网络类型，其中较为经典的包括 DenseNet， 在DenseNet中，短接链接的数量被增加了，每一个卷积层都会有一条专门的短接链接将自己的输出直接传播给较前的卷积层。因为DenseNet本质上包含了一个前馈神经网络的所有可能链接，所有的前馈神经网络都可以看作是DenseNet的一种特例来处理。这么多的链接也最大化了DenseNet本身进行特征提取和梯度传播的能力。5.2 U-netU-net 医学图像分割网络U-net 通过向下池化的操作来保证模型的健壮性，同时，通过skip connection将池化前的结果与膨胀卷积后的结果相拼接，模型可以保留输入图片在高分辨率下的一部分细节信息，这样的操作即提高了模型的健壮性，又不会输入图片内的大量细节。因为医学图像分割中常常会出现许多特征差异明显的正常&amp;amp;非正常样本（对模型的健壮性又很大考验），同时需要模型对输入信息做出精确分割（需要精确计算病灶体积/截面积），U-net在这个这个细分领域内大展身手。"
    },
    {
      "title"    : "Arc-consistency in Constraint Satisfaction Problem",
      "url"      : "/blog/2020/Constraint-Satisfaction-Problem.html",
      "tags"     : "Machine Learning",
      "date"     : "2020-10-09 00:00:00 +0000",
      "content"  : "约束满足问题(Constraint Satisfaction Problem, CSP)是一类在工程上非常常见的问题，问题由值域，变量和约束构成。求解约束满足问题指的是找到一组变量的赋值，使得网络中所有约束都被满足。在求解约束满足问题的研究中，弧一致性算法是重中之重，因为问题中的一切多元约束都可以被转化为若干个二元约束。这篇文章介绍了多种弧一致性算法，包括各种版本的时间复杂度，空间复杂度和特点Part I What is CSP CSP: 约束满足问题 一个CSP问题由三个主要部分组成： 变量，约束与值域，任何一个CSP问题都可以正则化为这三个集合 问题是Search Problem的一个较为特殊的子集，不难发现，我们完全可以使用Breath First Search, Depth Search 或者其他一般的搜索方法解决CSP问题。然而，由于CSP问题中的约束要求的复杂性，大量的变量空间和有时无穷大的状态空间，使用这些传统算法解决CSP问题不但会占用大量的计算时间，使用的内存消耗也会非常高。 目前大家普遍认为CSP问题是一种NP-Complete问题，也就是说一般普遍认为没有普适的，能够在多项式时间内解决CSP问题的算法存在Part II Backtracking 目前所有的解决CSP问题的算法的根本原理都是基于“回溯算法”，这种方法是一种完备的，可以解决任何有解的CSP问题的算法。然而，为了提高解决速度，目前普遍使用的工具都会集成一些启发式方法和局部搜索方法 这种方法通过尽可能的保证已赋值的变量不改变赋值来最大化解决问题的速度Part III Arc Consistency Algorithm 为了简化CSP问题，人们提出了很多种CSP约束传播算法；这些算法有以下两个主要功能： 验证CSP是否有解，注意任何单一的CSP约束传播算法都不能证明CSP有解，但是可以证明CSP问题无解 简化CSP模型，通过检测变量间的约束来减少每一个变量的可取值值域在这些算法中检测CSP问题中的Arc-Consistency的AC系列及其延伸算法被的研究最多，因为一般研究Arc Consistency时发现的算法可以有效的推广到更高等级的Path-Consistency 和 k-consistency 问题上，而且Arc 问题相对容易解决AC3 在AC系列中，第一个被提出并且广为接受的算法是AC3（AC1 AC2 在作者的论文中也有呈现，但是仅仅是作为迭代出AC3的步骤存在）AC3通过寻找一个变量的某个赋值是否能与周边的变量相容（不威胁约束）来减小值域，当找不到能够使得这个赋值与周边变量相容的情况时，从变量的值域中删去这一变量AC4 AC4算法是一种非常激进的算法，使用了非常多的方法试图降低时间复杂度 AC4算法致力于降低AC3的时间复杂度，使用了以空间换时间的策略，AC4通过大量的存储来降低时间复杂度使用一个二位数组来存储两个变量之间的约束可以支持这两个变量取什么值，通过这些存储，AC4可以避免重复检查变量间的约束关系AC4 算法的时间复杂度是最佳的 然而，AC4算法的初始化非常耗时，而且其空间复杂度非常高昂，这使得它与AC3对比并没有理论上预测的巨大优势 AC4算法也是AC系列的第一个“细粒度算法”，也就是说它的约束检测是基于变量的取值，而非基于变量间的弧约束，这可以避免一些重复的约束检测AC6 AC6算法意在保持AC4的最坏情况时间复杂度的同时降低空间复杂度的开销，并且像AC3一样，当遇到第一个满足Arc Consistency的赋值方法是就停止寻找其他方法AC7 AC7通过利用弧约束的双向性来进一步简化约束满足过程AC2001 AC2001 是一个粗粒度的算法，也就是说它对约束的检测是基于两个变量之间的约束进行的，这样的算法更为轻量而且更加容易维护，AC2001通过使用指针存储每个约束上的最低满足限度的支持约束的赋值来运行（而不是像AC6，使用二维数组，因此它的空间占用实际上比AC6低一些） AC2001是第一种达到最优复杂度的粗粒度算法AC3.3 AC3.3是人们基于AC3的基本架构，增加了对弧约束的双向性支持得到的算法，在日常情况中，AC3.3一般拥有最好的实际表现AC 算法的时间复杂度与版本树总结Part IV Other Methods for CSP[^1 ]*以下基于一个只有二元约束的CSP图（任意多元CSP问题都可以被转化为二元CSP问题）启发式算法解决CSP问题简而概之，使用启发式算法解决CSP问题的一种常用启发式算法是“找到威胁弧相容性最多的变量，在不改变其他任何变量的条件下，将一个在变量值域内的，威胁弧相容性最少的值赋给这个变量”，通过重复这个操作达到找到一个CSP完整的，满足相容性的解集局部搜索方法解决CSP问题结构优化法解决CSP问题树形的CSP约束问题可以在线性时间内解决，（例如使用“拓补排序”方法）将树线性化；一种CSP解决方法是割集条件设置，这种方法通过去掉图中产生环的关键节点来将有环的CSP约束图转化为若干个无环的CSP约束图，然后将每一个无环的CSP解加上之前删掉的关键节点后再次求解Part V CSP问题在实际生活中的应用例子使用CSP求解器预测蛋白质折叠结构蛋白折叠结构问题 - 使用CSP正则化变量：蛋白质中每个基团的方向 / 位置（三维向量）约束： 蛋白质侧链之间的静电力 洛伦兹力 亲（疏）水性 空间结构不可重叠（一个位置不能有两个原子） *如下图所示 蛋白质的激活位置 活性位置不能太大，不然无法实现酶催化的专一性 *如下图所示值域：三维空间内（可以离散化三维空间，使其转化为有限值域的CSP问题）"
    },
    {
      "title"    : "USACO 2016 Feb Gold Analysis",
      "url"      : "/blog/2020/USACO-2016-Feb-Gold-Analysis.html",
      "tags"     : "Algorithm",
      "date"     : "2020-10-08 00:00:00 +0000",
      "content"  : "Problem 1 Circular BarnLink to QuestionQuestion SummaryThe farmer has a circular barn with room numbered from $n, 3leq nleq 1times 10^5$ . Each is connected the rooms that adjacent it, and there one door in each opened outside space. Farmer wants single cow stay room. Currently, cows are staying randomly, which means some may have multiple or no it. The energy cost for $text{dist}^2$. question ask minimum make singly.Proposed SolutionObserving operation, we can notice this truth: If A’s destination after starting point of B, most energy-saving solution will need exchange A B.Based on solution, maintain queue store points cows. When meet empty room, pop out add up distance square cow’s moving distance.By repeating process all around barn, get cost.When always drop down per result be optimized. (Or, move more than round aside barn)The maintaining queue, using linked list, $O(1)$ push operation. Since $n$ cows, total time complexity $O(n)$ point.There totally possible points, so $O(n^2)$. This lead TLE since approx. $1times 10^{10}$ computational steps at most. Therefore, optimize our solutionThe main problem above go through point, consume lot time.To minimize try, first start random position, note number maximum queue. Then, directly position. lower try 2, $O(n)$.Time Complexity AnalysisSince $3leq 10^5$, $O(n)$, 10^6$ step AC Python 3 limit.Problem 2 Barn RevisitedLink QuestionProblem exactly $r_i$ $i$, where $0leq r_i leq 10^6$. Although John only want open $k$ doors let enter ($1leq k 7$). All ONLY walk clockwise inside barn. He know entering barn.Proposed SolutionOne method analyze “circular” structure it discuss linear structure, obviously easier. Consider line left right. We soon obvious facts: MUST left-most arrive Suppose enters $k-1$, must its before $k$th door, just less walking Using these two facts, use dynamic programming solve problem.Let $T$ represent table size $ntimes (k-1)$. value $T[n’][k’]$ walked when there’s $k’+1$ (since open) $n’$ doors. calculation pseudocode:$$begin{aligned}&amp;amp;text{each element }T = infty&amp;amp;T[0][0] leftarrow (0, 1)&amp;amp;text{for }T[i][j] text{ } T&amp;amp;quad quadtext{if }T[i+1][j+1][0] &amp;gt; T[i][j][0]&amp;amp;quad quad T[i + 1][j 1] (T[i][j][0], 0)&amp;amp;quad text{if }T[i][j+1][0] (T[i][j][0] T[i][j][1] times r_{j+1})&amp;amp;quad T[i][j r_{j+1}, 1)&amp;amp;return; T[k-1][n]end{aligned}$$Each made tuple, $k’$ second last $n’$th door.By calculating table, bar specific position $O(nk)$.Since whole based should points. $O(n^2k)$.Time 100$ $1leq 7$, algorithm finish calculate. problem.Problem Fenced InProblem SummaryThere’s rectangle corner $(0,0)$ $(A, B)$. built vertical fences $x a_1, a_2, cdots a_n$ $m$ horizontal $y b_1, b_2, cdots, b_m$. By doing so, divided into $(n 1)(m 1)$ grids. Now, connect grid together by removing rectangle. What fence remove EVERY cell rectangle?Proposed SolutionWe see as node, while between bi-directional weighted edge, weight equals length cells. field graph.After graph, find simply us provide sum weights Minimum Span Tree graph. greedy problem. pseudocode shown below$$begin{aligned}&amp;amp; // text{Fringe Priority Queue output smallest it}&amp;amp;L =0&amp;amp;text{Connected} phi &amp;amp;text{Fringe} { V_0.allEdges &amp;amp;text{While Fringe not Empty}&amp;amp;quad text{newEdge text{Fringe.pop()}&amp;amp;quad text{While newEdge.destination text{Connected}&amp;amp;quad }leftarrow }=text{Fringe cup newEdge.destination.allEdges}&amp;amp;quad text{Connected }=text{Connected }cup newEdge.destination}&amp;amp;quad L L+text{newEdge.wieght}&amp;amp;returnquad Lend{aligned}$$Time AnalysisThe min-span tree $O(E)$, which, case, $O(mn)$. mleq 2000$ 2000$, expected take 10^7$. highly"
    },
    {
      "title"    : "USACO 2016 Jan Gold Analysis",
      "url"      : "/blog/2020/USACO-2016-Jan-Gold-Analysis.html",
      "tags"     : "Algorithm",
      "date"     : "2020-10-04 00:00:00 +0000",
      "content"  : "Problem 1. Angry CowsQuestion SummaryLink to QuestionThe $N$ hey are on a line, with position $x_1, x_2, cdots, x_N$. If the cow is shoot $x$ force $R$, then all cows in range $x pm R$ will explode. The exploded have of $x’ (R - 1)$, second round $x’’ (R-2)$, and so on.The question requires minimum power $R$ one-decimal accuracy that let line explode.$$2 leq N 50,000 quad forall n, 0 x_n 1,000,000$$Proposed SolutionBinary SearchThere exists an $r’$ such for $R&amp;gt;r’$ , explode, it possible use binary search this question.Storing positions $x_1$ $x_n$ list, we can construct two pointers represents “frontier” explosion.positions = [x1, x2, ..., xn]p1, p2 None, NoneFor each explosion, time complexity $O(1)$ update pointer’s position.def updatePosition(p1, p2, R): if positions[p1-1] positions[p1] &amp;lt;= R: p1 -= 1 positions[p2 + 1] positions[p2] += return p1, R 1Therefore, take $O(n)$ us simulate one case.One optimization stop simulation immediately false chain reaction stopIf try starting point, total be $O(n^2log{n})$ lead TLE Python.Noticing points, given fixed at $x_i$ explode all, note as true, otherwise, false, resulting result should look like this:Propagate_Leftward: [True, True, False, False]Propagate_Rightward: [False, True]Can_Explode_All Propagate_Left Propagate_RightWe find point well.def findStartLeft(l, r, # True current m (l r)/2 l r: explodePropagateLeft(l): else: -1 explodePropgateLeft(m): findStartLeft(m, R) m-1, R)def findStartRight(l, explodePropagateRight(l): explodePropgateRight(m): m, findStartRight(m+1, isValid(l, R)By using nested search, reduced $O(nlog{n}log{n})$Time Complexity AnalysisWith $O(n log{n}log{n})$ $n &amp;lt; 50,000$, approximate steps need $50,000 times 16times 16 1.3times 10^7$ (Consider performing determine existence actual computation step multiply factor $2$, which approx. $2.6times 10^7$), acceptable computational Python 3.Problem 2. Radio ContactLink QuestionQuestion SummaryFarmer Bessie two-dimension space size $1000times 1000$. Farmer start $f_x, f_y$, while $b_x, b_y$. ($0 f_x, f_y, b_x, b_y 1000$)Farmer walk path length $M$, has “N”, “W”, “E”, “S” $N$, it. $0 M, 1000$At tick, either or choose stay position. A radio consumes energy $text{Distance}(Farmer, Bessie)^2$ remain open until both farmer finish their path. What cost?Proposed SolutionThis solved Dynamic Programming.Build up table $M N$ called $E$. $E[m][n]$ represent consumed after takes $m$ moves $n$ moves. Since square distance always non-negative, (or both) tick. Therefore, used calculate $E[m 1][n]$, 1][n 1]$ $E[m][n 1]$, stop, no respectively.To specific position, say $E[x][y]$ table, must make sure value already energy, means $E[x-1][y]$, $E[x-1][y-1]$, $E[x][y-1]$ been calculated. whole from top down, row left right.Time Space AnalysisCalculating adjacent cell $O(1)$, inside $O(MN) approx O(N^2)$. upper bound only $1times 10^3$, Python3 solve problem.To store Programming (memorization), build two-dimensional array 1000$, not problem.Problem 3. Lights OutLink SummaryBessie vertex simple polygon vertices. coordinate vertices $(x_1, y_1), cdots (x_n, y_n)$ listed clockwise order. exit located y_1)$. When light out, she forgot but still remember polygon. By moving passing through several edges, able identify edge on. After know her move counter get nearest exit.The asks greatest difference between go dark lights worst case.Sample Case ExplanationProposed SolutionThe divide into parts: Help its (calculate position) Calculate shortest arbitrary exit.For first part, convert string, where A, B, C D four different types corners, integer edge.For example, sample represented as$$text{10C1D10A1}$$One primitive way unique substring maintain set pointers, same pattern. For instance, suppose string “10C1D10A10C10A”, when pass by edge, information “10C”. At time, pointer {0, 8}, since [0:3] [8:11] Then, another new info “1D”, {0}. [0 3: 0+3+2] “[8+3: 8+3+2]” “10”.This $O(n^2)$.For list $text{Dist}$ $text{Dist}[n]$ $n$th counterclockwise. Also, record perimeter nth calculated $text{Perimeter}-text{Dist}[n]$. This $O(1)$.Since vertexes through, $O(n^3)$.Time Analysis$4leq Nleq 200$, $O(n^3)$ most $1.6times steps, problem proposed solution."
    },
    {
      "title"    : "深度学习的梯度下降方法",
      "url"      : "/blog/2020/Gradient-Descent-Methods.html",
      "tags"     : "Neural Network, Notes",
      "date"     : "2020-10-03 00:00:00 +0000",
      "content"  : "神经网络的训练本质上是通过调节参数来最小化模型输出的损失函数。然而如何调节参数看似简单实际却有许多技巧和方法来优化。这篇文章会介绍最基本的随机梯度下降，采用一阶动量的SGD with momentum，和采用自适应学习率的AdaGrad, RMS Prop, 和集大成者 Adam。这些模型各自有各自的特点，并且在不同的场景中各有优劣。深度学习中的梯度下降方法上回（神经网络是如何工作的）中，我们提到模型的训练过程本质上就是通过调节模型参数使得模型输出的损失函数降低。由于神经网络的参数太多，我们几乎不可能求出损失函数极小值的解析解。为此，普遍使用的是数值计算的方法来减小损失函数的取值。这篇文章会介绍随机梯度下降 (Stochastic Gradient Descent, SGD)，RMS AdaGrad (Adaptive Gradient), 和 Adam(Adaptive Moment Estimation)这四种常简的梯度下降方法。符号定义$eta$ 学习速率$nabla C$ 损失函数梯度$w$待优化参数$m_t$ 损失函数梯度的一阶动量$v_t$ 损失函数梯度的二阶动量朴素的梯度下降法批量梯度下降 | Batch Descent对于一个有 $N$ 个数据的数据集 ${x_1, x_2, cdots x_N}$，批量梯度下降要求先计算出每一个数据的输出 ${y_1, y_2, y_N}$，然后计算出每个输入单独的损失函数及梯度 $nabla C_1(x_1, y_1), nabla C_2(x_2, y_2), cdots, C_N(x_N, y_N)$。计算完一整个数据集后，模型会取所有损失函数的平均，然后更新模型的参数$$w leftarrow w + frac{1}{N}sum_{i=0}^{N}{nabla C_i}cdot eta$$这样的梯度下降有好处也有坏处：好处是对于一个和实际生产环境相符的数据集，使用批量梯度下降可以得到更加稳定健壮的模型，模型不会受到特殊数据的影响。坏处也同样明显：当数据集很大的时候需要使用海量的内存，遍历整个数据集会耗费大量的时间。这使得使用批量梯度下降成为一种近乎奢侈的选择。还有一个限制是使用批量梯度下降的模型不能“在线学习”，必须在一个固定的数据集中训练。小批量梯度下降 Mini-batch Descent小批量梯度下降使用的方法与批量梯度下降相似，唯一的不同是小批量梯度下降将整个数据集分为若干个包含$b$个数据的 batch，每次模型处理完一个 batch 就对模型参数进行一次更新$$w frac{1}{b}sum_{i=0}^{b}{nabla eta$$随机梯度下降 Stocastic Descent随机梯度下降是当 大小为1时的小批量梯度下降。随机梯度下降可以做到“在线学习” - 每有一个新的数据被上传到数据集，模型就可以根据这个新的数据进行一次实时权重更新。$$w C cdot eta$$朴素梯度下降的问题朴素的梯度下降会出现模型在局部最优解和鞍点上震荡的问题。当模型在局部最优解和鞍点的时候，损失函数的梯度为0，模型不会继续更新参数。一阶动量梯度下降SGD Momentum 带动量的随机梯度下降这种梯度下降方法引入了“动量”的概念。动量由模型历史上的梯度决定，并且受到衰减参数$beta$的控制。$$m_t = m_{t-1} beta (1 beta)$$$$w m_t eta$$一般我们会设定$beta$为0.9， 也就是说每计算一个新的样本只会轻微的改动自己的权重更新方向。通过这种方法，我们可以有效的越过一些局部最优解的“陷阱”。一个较大的$beta$值也可以避免模型被一些极端样本影响。二阶动量梯度下降（自适应学习率）二阶动量梯度下降通过引入“二阶动量”的概念来做到 经常更新的参数学习速率较低，不常更新的参数学习速率较高 的自动调节。这在处理一些样本分布稀疏的数据集时尤为重要。AdaGrad Adaptive 自适应梯度下降法自适应梯度下降中将二阶动量定义为历史上参数所有梯度的平方和$$v_t sum_{i 0}^{t}{nabla C_i^2}$$一个参数更新的越频繁， 其二阶动量就越大，更新速度就越小，在Adagrad中，模型参数的更新公式如下：$$w frac{eta}{sqrt{v_t}}$$但是 的缺点也非常明显：有的时候学习速率收敛的过快会导致模型在训练到局部最优解前就停止参数更新。为了解决这个问题，人们提出了RMS Prop梯度下降法RMS PropRMS Prop 本质上是对AdaGrad激进的学习速率调节机制做出的调整。为了避免学习速率过快的下降，RMS 仿照一阶动量计算方法，给二阶动量也设计了衰减参数 $beta_2$。在RMS Prop中，二阶动量的计算公式如下：$$v_t beta_2 v_{t 1} beta_2) C_t^2$$使用衰减因子 $beta_2$可以有效防止参数学习速率收敛到0，导致模型提前停止训练。Adam Estimation)Adam是上述所有梯度下降方法的“集大成者”，它在使用了一阶动量来调节模型参数的调整方向的同时也使用二阶动量自动调节参数单独的学习速率。$$m_t beta_1 beta_1)$$$$v_t 1}cdot C_t^2cdot beta_2)$$$$w frac{eta}{v_t}$$对于绝大多数的英语场景，我们都可以直接运用Adam优化器作为梯度下降的调参模型，并且由于自适应学习率的存在，学习速率作为超参数对于Adam的影响其实相对有限。所以使用Adam可以极大的降低调参工作量。"
    },
    {
      "title"    : "神经网络如何工作",
      "url"      : "/blog/2020/How-do-Neural-Network-Work.html",
      "tags"     : "Neural Network",
      "date"     : "2020-07-31 00:00:00 +0000",
      "content"  : "神经网络作为一种新兴的计算机技术被许多人称为一种全新的“编程范式”，与往常的算法编写不同，神经网络是一种“数据驱动”的编程方法。在往常的算法编写中，人们需要手动编写算法的逻辑，而在神经网络中，人们只需要为网络提供海量数据和参考答案，网络就会自动生成算法。那么神经网络到底是怎么工作的呢？ By Mark Chen, 29299731这篇文章会对机器学习中的神经网络为什么可以被训练&amp;amp;输出正确预测做出不严谨但直观的解释。0. 模型是一个函数我们可以将一个深度学习中的模型看做一个映射关系：$$text{Perception} rightarrow text{Output}$$对于一个深度学习模型是“感知”（模型可以获得的所有信息的总和）与一个“数字”或者 “决策”之间的映射关系。所以我们可以将模型看作一个函数$F(x)$.那么模型就可以被表示为：$F(text{Perception}) =text{Output}$ Example: Alpha Go 可以被表示为 $F(text{棋盘状态}) = 当前落子最优位置$ 这样一个函数现在我们假设有这样的一个函数：对于任何定义域内的输入都一定会给出此时的最优输出。这样的一个理想函数我们记作$G(x)$(Ground Truth)。 当我们“训练”模型$F(x)$的时候，我们的目标就是让模型尽可能拟合$G(x)$。也就是说，我们想要通过训练使得我们的模型$F(x)$ 的输出与事实（最优函数）$G(x)$的差距最小化。1. 什么是神经网络要知道为什么”神经网络“可以被用来拟合函数呢？首先我们先了解一下什么是“神经网络”。神经网络由许多神经元相互连接而组成，每个神经元都有自己的参数$theta$ 。我们可以将神经元描绘为一个函数 $f(theta_i, x) y$。那么对于下面一个模型（$F(Theta, x), quad Theta=lbrace theta_1, theta_2, dots, theta_nrbrace$），我们可以写出它的数学表达式：$$F(Theta, f(theta_5, (f(theta_3, f(theta_2, x_2) + f(theta_1, x_1)), f(theta_4, x_2))))$$从上面的式子我们可以看到参数$theta$的取值和模型本身的结构（上图中函数互相嵌套的关系）共同决定了模型的最终输出。2. 神经网络可以拟合函数神经网络的本质建立在这样一个事实上：简单非线性函数的重复的迭代与叠加可以在拥有适当参数的情况下有限精度的拟合任何连续函数。下面的例子会给出一个直观但不严谨的，对神经网络拟合二元函数的证明：首先，我们可以用5个使用sigmoid函数的神经元来构建一个“高台”函数。(代码是具体的实现)import matplotlib.pyplot as pltimport numpy npimport pylabfrom matplotlib import cmfrom mpl_toolkits.mplot3d Axes3Ddef sigmoid(x): s 1 / (1 np.exp(-x)) return sdef tower(x, y, x_min, x_max, y_min, y_max): x1 sigmoid(1000 * (x - x_min)) x2 x_max)) y1 (y y_min)) y2 y_max)) z x1-x2+y1-y2 sigmoid(30*(z-1.1)) zX np.arange(-5, 5, 0.1)Y 0.1)X, Y np.meshgrid(X, Y)Z tower(X, Y, -0.3, 0.7, -0.2, 0.8)fig plt.figure()ax Axes3D(fig)ax.plot_surface(X, Z, rstride=1, cstride=1, cmap=cm.viridis)plt.show()如果我们把这样的一个高台记作$Tower(x_1, x_2，Theta)$，那么通过组合足够多这些高台，我们可以得到任何一个连续二元函数的任意小精度拟合（缩小每个高台的面积），例如下图（左：原函数，右：四个$Tower(x_1, x_2,Theta)$的组合def sigmoid(4*(z-1.1)) zZ -0.5, 0.5, 0.5) -1, 1, 1) -2, 2, 2) -4, 4, 4)fig cmap=cm.viridis)plt.show()3. 如何让电脑自动调参？在上面的例子中，所有的参数都是人工设定的，因为只有20个不到的参数，人工设定是一种可行的做法。可是目前绝大多数的模型都有超过一万个参数，参数最多的自然语言模型GPT-3甚至有1730亿个参数（存储整个模型需要800T空间）！在这么多参数的情况下，人工调节每一个参数变成了一项不可能的任务，所以我们需要让电脑来自动调整参数来让模型$F(x)$拟合到目标$G(x)$上。要让电脑自动完成这项工作，我们需要先回想一下当我们调整参数时我们所作的工作： 评估现在的模型$F(x)$与$G(x)$相差大不大（现在的模型是不是一个好模型） 预测调节参数$theta$（调大/调小）以后模型会变好还是变坏 如果参数$theta$调小可以让模型$F(x)$更加接近$G(x)$，那么就调小$theta$， 反之亦然 损失函数为了让机器拥有完成任务1的能力，人们设计出了“损失函数”用来量化表示模型$F(x)$与事实$G(x)$之间的差距，用$L(hat{y}, y)$表示，$hat{y}$表示模型的输出（对Ground Truth $y$的预测值），一般来说，一个良好的损失函数应该有这些性质： 损失函数大小与模型质量单调递增 模型越差，损失函数越大 损失函数应该是一个连续，尽量平滑的函数一种常见的损失函数是$L(hat{y}, y) hat{y})^2$参数调节方向的计算为了让机器完成任务2 和 3，我们需要将”预测调节参数$theta$（调大/调小）以后模型会变好还是变坏“这样一个主观的过程用数学方法表达出来。因为我们已经引入了损失函数，所以实际上这个过程可以被表述为“预测如何调节参数$theta$（调大/调小）可以减小损失函数的值”在此之前，我们先看一看我们如何最小化一个一元函数$h(x)$. 对于一个一元函数，我们可以计算出当前位置的一阶导数$dh/dx$。如果一阶导数是正数，说明增大$x$可以增大$h(x)$，反之亦然。所以要最小化$h(x)$，我们只需要不停的执行下面这一个操作：$$xstackrel{text{update}}{longrightarrow}x eta cdot frac{dh(x)}{dx},quadquad text{where $eta$ is a positive number}$$这里的$eta$是一个参数“学习速率”，学习速率越高，每次更新$x$的时候$x$的值就会改变越多 。有了上面的铺垫，解决“预测如何调节参数$theta$（调大/调小）可以减小损失函数的值”的方法就很明显了：计算$partial L(hat{y}, y)/partial theta$ 并且将$theta$按照一下方式更新：$$thetastackrel{text{update}}{longrightarrow}theta frac{partial y)}{partialtheta},quadquad number}$$ 有些人可能会疑惑，在$L(hat{y}, y)$中明明都没有自变量$theta$ 啊，怎么计算$frac{partial y)}{partial theta}$ 呢？ 实际上注意到损失函数的第一个输入时$hat{y}$，也就是模型的输出，而模型可以表示为$F(theta, x)$，所以我们可以通过链式法则计算$frac{partial y)}{partialtheta}$$$frac{partial theta} hat{y}}cdot hat{y}}{partial theta}$$ 这也是神经网络的基石 反向传播算法 (Back Propagation) 的数学原理当机器拥有了自动更新权重的能力的时候，我们就可以开始对神经网络进行训练了！训练的过程其实就是将样本从训练数据集中输入到模型中，再通过算法自动调节模型函数来最小化损失函数。"
    },
    {
      "title"    : "什么是贝叶斯网络 | What is Bayes Network",
      "url"      : "/blog/2020/What-is-Bayes-Network.html",
      "tags"     : "Machine Learning",
      "date"     : "2020-04-30 00:00:00 +0000",
      "content"  : "贝叶斯网络是人们在探索机器学习时的一个重要里程碑，通过贝叶斯网络，机器学习摆脱了以往基于形式逻辑推理和庞大知识库的限制，开始了“统计学习”的新纪元。那么什么是贝叶斯网络呢？贝叶斯网络和贝叶斯统计学派又有什么关系呢?目录 统计贝叶斯学派与贝叶斯公式 什么是贝叶斯网络 为什么我们需要贝叶斯网络 贝叶斯网络“加速”的原理 用朴素的贝叶斯网络识别手写数字 参考资料 1 统计贝叶斯学派与贝叶斯公式根据对统计的理解，数理统计存在概率学派与贝叶斯学派两种学派，他们之间的主要区别在于对于概率的理解方法不同概率学派认为世界存在一个固定的先验概率，例如一枚公平的硬币抛出正反面的概率一定分别是1/2。换句话说，古典学派认为任何事件都存在一个固定的概率模型，虽然我们可能不知道这个概率分布中的一些参数，但是只要我们进行了足够多次的取样，我们可以通过取样的结果来推断事件的概率分布。贝叶斯学派则认为世界没有一个确定的先验概率，假设我们只得到了事件A的样本X，那么我们就只能依靠样本X对事件A的概率分布做出推断，而不必考虑“可能出现但未出现（在样本X中）”的情况。在这种理解的背景下，我们每次对事件A进行采样就会更新我们对事件A各个情况概率分布的认知（Belief）。1两个学派都各有优势，在一些简单并可以做出大量模拟的情况（例如预测抛硬币正反的概率分布）下，概率学派可以较为精确的获得某一事件的发生概率；在一些难以分析，很难模拟/大量采样的情况（例如地震概率的预测）下，贝叶斯学派则有极大的优势，可以使用有限的信息帮助我们做出合理的推断贝叶斯公式是贝叶斯学派的重要理论之一，这个公式告诉了我们如何通过我们对事件A已有的认知和新的采样（evidence）B来更新事件A的后验概率（在事件B发生后我们对事件A概率分布的新认知）$$P(A mid B) = frac{P(Bmid A)P(A)}{P(B)}$$概率学派也有关于这个公式的另一套解释方法：概率学派将概率看为“结果的比例（结果A在所有结果中的概率记为P(A) ）。这个公式在这种解释下成为了描述“具有B的所有结果中有A性质的结果所占的比例 具有A性质的所有结果中具有B性质的结果所占的比例 $times$ 所有结果中A的比例 / 所有结果中B的比例” 22 什么是贝叶斯网络贝叶斯网络是一种描述随机变量之间互相条件独立关系的有向无环图。在这个有向无环图中，每个节点代表一个随机变量对其父节点的条件概率分布 $P(X_i parents(X_i))$，每一条边可以理解成变量之间的联系。 注意：虽然一般来讲这种“联系”可以被解释为“因果关系”，但是实际上 这种关系并不一定是因果关系，只要两个变量之间互相不条件独立就应该被连在一起在贝叶斯网络中，已知$X$的父节点$parents(X)$时$X$的条件概率分布$P(Xmid parents(X))$ 与已知$X$的父节点时网络中$X$的“祖先节点”的概率分布$P(ancestor(X)mid parents(X))$互相条件独立。3 例子： 在这样一给贝叶斯网络图中，E的父节点$parent(E) {D}$，E不包括父节点的祖先节点$ancestor(E) {B, C, A}$ 通过贝叶斯网络的定义，我们可以知道随机变量C, D, E之间存在这样的关系：$$P(Emid D) perp P(Cmid D)$$ 也就是说$$P(Emid B, A) P(Emid D)$$贝叶斯网络本质上只是一种维持子节点与其祖先节点（不包括父节点）在给定父节点的条件下互相条件独立的存储随机变量之间互相关系的数据结构。3. 为什么我们需要贝叶斯网络在生产生活中，我们经常需要对具有随机性的状态的出现概率进行推断。假设我们想用随机变量$X_0$到$X_n$来表示一个事件的“状态”，其中每一个随机变量都只有2个可能的取值：1（发生）或0（不发生） 我们这时候想要得知$P(x_1, x_2, cdots, x_n)$这的概率分布。如果使用直接列出一张全联合分布的概率分布表（如下）的话，整张概率分布表会有$2^n$行，每次计算一行都要计算随机变量的所有情况，这使得求解概率分布的时间复杂度极高（时间复杂度$O(n2^n)$）。如果我把这n个随机变量用贝叶斯网络表示出来，因为贝叶斯网络可以很好的表达随机变量之间的相互条件独立关系，我们的计算量可以大大减小$$P(x_1, x_n) prod^n_{i 1}{P(x_i | x_{i+1}, x_{i + 2}, cdots x_n)}$$上面的式子中连乘号中的概率分布也可以表示为：$$P(x_i parents(x_i), ancestor(x_i))$$因为我们知道 $P(ancestor(x_i)mid parents(x_i))perp P(x_i parents(x_i))$，我们可以消去上式中给定条件里的$ancestor(x_i)$这一项这时候，我们可以得知：$$P(x_1, 1}P(x_i parents(x_i))$$看到这里，你可能会觉得这个式子有些似曾相识……是的，这里被连乘的每一项就是贝叶斯网络中每一个节点所存储的条件概率表所存储的概率分布！这时候，在一个最多有$k$个父节点的贝叶斯网络中，求解状态的概率分布所需要的时间复杂度就被缩小到了$O(n2^k)$。虽然求解问题依然是一个非多项式时间问题（NP）， 但是在大多数情况中贝叶斯网络的使用可以有效的降低时间复杂度的幂。34. 贝叶斯网络“加速”的原理为什么贝叶斯网络处理同样的问题比直接计算所有随机变量的全联合分布要快呢？这个问题其实可以在贝叶斯网络的时间复杂度表达式中看出端倪：对于一个每个节点最多有$k$个父节点的贝叶斯网络，求解概率分布的时间复杂度是$O(n2^k)$。这意味着如果有一个贝叶斯网络是一个完全图（每个节点之间都有连线）的话，它的求解时间复杂度会达到$O(n2^n)$，和全联合分布一样。实际上，贝叶斯网络可以计算的比全联合分布快是因为贝叶斯网络可以有效的表示变量之间的条件独立关系，基于这种条件独立的假设来简化计算，从而降低算法时间复杂度。5. 朴素的贝叶斯网络识别手写数字上面简单的介绍了什么是贝叶斯网络和贝叶斯网络的存在意义，接下来我们要看一个朴素的贝叶斯网络用来识别MNIST数据集中的手写数字的一个实践案例5.0 什么是MNIST数据集MNIST数据集是美国国家标准与技术研究所收集整理标注的一个手写数字数据集，其中包括了60000张28*28的8bit灰度手写数字图片作为训练集，还有10000张28*28的8bit灰度图片作为测试集。每张图片由$28^2 784$个像素构成，每个像素取值（从白到黑）在$[0, 255]$的范围内。每一张图像都有一个“标签”，这个标签代表着这个图片上写的数字。5.1 为什么说是“朴素的”贝叶斯网络因为在这个例子里面，我们假定每一个像素是一个单独的feature（特性），并且我们认为所有的像素之间都是互相独立的（显然不是，一个高亮的像素周边的像素大概率也比较亮）。这样一个略微脱离实际的假设使得我们可以大大简化模型的贝叶斯网络并且可以极快的求解概率分布（因为每个像素都只有一个父节点——图像的标签）。5.2 如何运用模型预测对于一张给定的图片，我们把里面的784个像素看成784个随机变量，同时，我们记这个模型的标签为$label$，在这种设定下，一张图片的标签可以这样表示：$$label {underset {labelin [0, 9]}{operatorname {arg,max} }},(P(label, f_1, f_2, f_{784}))$$ 对于一幅图片（给定$f_1, f_{784}$），我们希望找到一个0 - 9之间的label，使得$P(label, f_{784})$的值最大使用贝叶斯网络，我们可以发现这个概率$P(label, f_{784})$可以这么计算：$$P(label, f_{784}) P(label) cdot P(f_1 label) P(f_2mid label)cdots P(f_{784}mid label)$$我们只用完成这样的一个简单运算就可以得到一张照片是label A的概率了：def predict(data): global LabelDistribution, PixelDistribution, THRESHOLD labelProbTable [1] * 10 for i in range(10): labelProbTable[i] *= LabelDistribution[i] pixel range(len(data)): if data[pixel] &amp;gt;= THRESHOLD: PixelDistribution[i][pixel] else: (1 PixelDistribution[i][pixel]) MAX_PROB, MAX_LABEL -1, -1 &amp;gt; MAX_PROB: MAX_PROB return MAX_LABEL5.3 如何训练模型通过上面的公式，我们知道可以很方便的使用$P(label)$和$P(f_imid label)$来预测一张图片的标签，那么我们怎么获得这两种数据呢?答案是：数数是的，这个”天真烂漫的朴素贝叶斯网络“的整个训练过程只在做一件事情：数数我们通过统计训练数据里60000个标签的概率分布来得到$P(label)$，同时我们对每一张图片的每一个像素进行统计，如果像素亮度超过阈值就记+1上去，最后得到每一个标签下所有像素超过阈值的概率，也就是$P(f_i 1mid label)$。Data [list(map(int, line.strip().split(&quot;,&quot;))) line open(&quot;mnist_train.csv&quot;).read().strip().split(&quot;n&quot;)]LabelDistribution {i: 0 range(10)}PixelDistribution [{i: range(784)} _ range(10)]THRESHOLD 100# Calculate the P(F_i y)def train(): Data, Data: label line[0] pixels line[1:] LabelDistribution[label] += range(len(pixels)): pixels[pixel] PixelDistribution[label][pixel] normalize(PixelDistribution[i], label=i) normalize(LabelDistribution)5.4 模型准确率虽然这个模型看上去非常的不靠谱（假设所有feature相互独立），但是竟然可以达到高达84.4%的分类准确率！（当然，比起其他像神经网络一样的fancy方法，这个结果也很朴素）NO.9999predict: 6actual: 6accumulative precision: 0.8446. 参考资料[4]:"
    },
    {
      "title"    : "长短期记忆递归网络 LSTM",
      "url"      : "/blog/2020/What-is-LSTM.html",
      "tags"     : "Neural Network, NLP",
      "date"     : "2020-04-03 00:00:00 +0000",
      "content"  : "一般的神经网络只能处理单个信息，可是有的时候神经网络的输入是一个时间序列，在这种情况下普通的前馈神经网络就不能利用“上下文”中隐含的信息来更好的处理当前输入。为了解决这个问题，人们提出了递归神经网络(Recurrent Neural Network, RNN)。可是递归神经网络也有问题：由于同样的权重在网络中一直被累乘，在反向传播的时候极容易出现梯度消失与梯度爆炸的问题。同时，由于RNN在状态间传递的信息过少，RNN在上下文距离较远的时候会很快的遗忘前文信息。为了解决这些问题，人们提出了LSTM这个新的网络模型，它可以很好的处理以上这些问题。0. 什么是LSTMLSTM，全称 Long Short Term Memory (长短期记忆) 是一种特殊的递归神经网络 。这种网络与一般的前馈神经网络不同，LSTM可以利用时间序列对输入进行分析；简而言之，当使用前馈神经网络时，神经网络会认为我们$t$时刻输入的内容与$t + 1$时刻输入的内容完全无关，对于许多情况，例如图片分类识别，这是毫无问题的，可是对于一些情景，例如自然语言处理 (NLP, Natural Language Processing) 或者我们需要分析类似于连拍照片这样的数据时，合理运用 $t$ 或之前的输入来处理 $t+n$ 时刻显然可以更加合理的运用输入的信息。为了运用到时间维度上信息，人们设计了递归神经网络 (RNN, Recurssion Network)，一个简单的递归神经网络可以用这种方式表示在图中，$x_t$是在$t$时刻的输入信息，$h_t$是在$t$时刻的输入信息，我们可以看到神经元$A$会递归的调用自身并且将$t -1$时刻的信息传递给$t$时刻。递归神经网络在许多情况下运行良好，特别是在对短时间序列数据的分析时十分方便。但是，注意到前面着重强调了“短”，这是为什么呢？上图所示的简单递归神经网络存在一个“硬伤“，长期依赖问题：递归神经网络只能处理我们需要较接近的上下文的情况： Example 1. 想象现在设计了一个基于简单RNN的句子自动补全器，当我输入”Sea is …” 的时候会自动补全为”Sea blue“。在这种情况下，我们需要的上下文极短，而RNN可以很好的收集到 $t = 0$时的信息”Sea”并且补上”blue” 2. 现在，假设我们用刚刚的RNN试图补全一篇文章”我一直呆在中国，……，我会说一口流利的 (?)”。在这里，为了补全最后的空缺，需要的信息在非常远的上文（e.g. 200+字前）提到的”中国“。在实验中简单的理想状态下，经过精心调节的RNN超参数可以良好的将这些信息向后传递。可是在现实的情况中，基本没有RNN可以做到这一点。一些学者后来研究发现RNN的长期依赖问题是这种网络结构本身的问题。不但如此，这种简单的RNN还很容易受到两种在神经网络中臭名昭著的影响梯度消失问题（神经网络的权重/偏置梯度极小，导致神经网络参数调整速率急剧下降）和梯度爆炸问题（神经网络的权重/偏置极大，导致神经网络参数调整幅度过大，矫枉过正）。相信大家都看过一个著名的鸡汤，$(0.99)^{365}$和$(1.01)^{365}$的对比。实际上，这个鸡汤非常好的描述了梯度问题的本质：对于任意信息递归使用足够多次同样的计算，都会导致极大或极小的结果，也就是说…根据微分链式法则，在RNN中，神经元的权重的梯度可以被表示为一系列函数的微分的连乘。因为神经元的参数（权重与偏置）都是基于学习速率（一般为常数）和参数梯度相反数（使得神经网络输出最快逼近目标输出）得到的，一个过大或过小的梯度会导致我们要么需要极长的训练时间（本来从-2.24 调节到 -1.99 只用500个样本，由于梯度过小，每次只调小0.0001，最后用了几千个样本），要么会导致参数调节过度（例如本来应该从-10.02调节到-9.97，由于梯度过大，直接调成了+20.3）1. 为什么需要LSTMLSTM从被设计之初就被明确的用于解决一般递归神经网络中普遍存在的长期依赖问题，使用LSTM可以有效的传递和表达长时间序列中的信息并且不会导致长时间前的有用信息被忽略（遗忘）。与此同时，LSTM还可以解决RNN中的梯度消失/爆炸问题2. LSTM 的直觉解释LSTM的设计或多或少的借鉴了人类对于自然语言处理的直觉性经验。要想了解LSTM的工作机制，可以先阅读一下一个（虚构的）淘宝评论： “这个笔记本非常棒，纸很厚，料很足，用笔写起来手感非常舒服，而且没有一股刺鼻的油墨味；更加好的是这个笔记本不但便宜还做工优良，我上次在别家买的笔记本裁纸都裁不好，还会割伤手……”如果让你看完这段话以后马上转述，相信大多数人都会提取出来这段话中几个重要的关键词“纸好”，“没味道”，“做工好”，然后再重新组织成句子进行转述。这说明了以下两点： 在一个时间序列中，不是所有信息都是同等有效的，大多数情况存在“关键词”或者“关键帧” 我们会在从头到尾阅读的时候“自动”概括已阅部分的内容并且用之前的内容帮助理解后文基于以上这两点，LSTM的设计者提出了“长短期记忆”的概念——只有一部分的信息需要长期的记忆，而有的信息可以不记下来3. LSTM的具体解释一个普通的，使用tanh函数的RNN可以这么表示：在这里，我们可以看到A在$t-1$时刻的输出值$h_t$被复制到了$t$时刻，与$t$时刻的输入$x_t$整合后经过一个带权重和偏置的tanh函数后形成输出，并继续将数据复制到$t+1$时刻……与上图朴素的RNN相比，单个LSTM单元拥有更加复杂的内部结构和输入输出：在上图中，每一个红色圆形代表对向量做出的操作（pointwise operation， 对位操作），而黄色的矩形代表一个神经网络层，上面的字符代表神经网络所使用的激活函数 point-wise operation 点对点操作 ​ 如果我要对向量&amp;lt;1, 2, 3&amp;gt; 和 &amp;lt;1, 3, 5&amp;gt;进行逐分量的想成操作，会获得结果 6, 15&amp;gt; layer 函数层 一个函数层拥有两个属性：权重向量(Weight) 偏置向量(bias)，对于输入向量$A$的每一个分量 $i$ ， 函数 层会对其进行以下操作(假设激活函数为$F(x)$)：$$Output_i F(W_i cdot A_i b_i)$$​ 常见的激活函数（也就是套在最外面的$F(x)$）有ReLU(线性修正单元)，sigmoid（写作$sigma$），和 $tanh$###　LSTM的关键：单元状态LSTM能够从RNN中脱颖而出的关键就在于上图中从单元中贯穿而过的线 ——神经元的隐藏态，我们可以将神经元的隐藏态简单的理解成递归神经网络对于输入数据的“记忆”，用$C_t$表示神经元在$t$时刻过后的“记忆”，这个向量涵盖了在$t+1$时刻前神经网络对于所有输入信息的“概括总结”接下来我们会看一下LSTM四个函数层分别在做些什么LSTM_1 遗忘门对于上一时刻LSTM中的单元状态来说，一些“信息”可能会随着时间的流逝而“过时”。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了“遗忘门”每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘掉之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到$(0, 1)$的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态对应的分量也会变成0，换句话说，“遗忘”了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以长期记忆重要信息，并且记忆可以随着时间进行动态调整下面的公式可以用来描述遗忘门的计算，其中$f_t$就是sigmoid神经层的输出向量：$$f_t sigma(W_fcdot [h_{t-1}, x_t] b_f)$$LSTM_2 &amp;amp; 3 记忆门记忆门是用来控制是否将在$t$时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用（图上tanh函数层左侧）的sigmoid函数来控制这些记忆要放“多少”进入单元状态。这两者结合起来就可以做到： 从当前输入中提取有效信息 对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态下面的公式可以分别表示这两个步骤在LSTM中的计算： $$C’t tanh(W_ccdot [h{t - 1},x_t] b_c)$$ $$i_t sigma(W_icdot b_i)$$ LSTM_4 输出门输出门，顾名思义，就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量（也就是公式中的$[h_{t 1},x_t]$）用sigmoid函数提取其中的信息，接着，会将当前的单元状态通过tanh函数压缩映射到区间$(-1, 1)$中* 为什么我们要在LSTM的输出门上使用tanh函数？ 以下引用自Stack Overflow上问题 What the intuition of using tanh in 中的最佳答案： https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm 在LSTM的输入和输出门中使用tanh函数有以下几个原因： 为了防止梯度消失问题，我们需要一个二次导数在大范围内不为0的函数，而tanh函数可以满足这一点 为了便于凸优化，我们需要一个单调函数 tanh函数一般收敛的更快 tanh函数的求导占用系统的资源更少 将经过tanh函数处理后的单元状态与sigmoid函数处理后的，整合后的向量点对点的乘起来就可以得到LSTM在$t$时刻的输出了！4. 的变体自从LSTM在自然语言处理等方面大获成功后，许多种LSTM的变体被提出，其中只有几种值得特别关注：这种LSTM让各个门都可以在获得了上一时刻的单元状态的前提下进行运算。在上面的图中，单元状态被额外赋予到了所有三个层中（输出门除外），然而在实际的应用中，大部分研究者只会选择性的打开三个通道中的一或两个除此之外，还有很多其他LSTM变体以及通过其他方式构建RNN达到类似LSTM的效果的架构，然而这些架构的效率都大同小异，所以不过多说明了5. 参考资料[1] “Understanding Networks.” Understanding Networks – Colah’s Blog, colah.github.io/posts/2015-08-Understanding-LSTMs/.[2] “Long Short-Term Memory.” Wikipedia, Wikimedia Foundation, 1 Apr. 2020, en.wikipedia.org/wiki/Long_short-term_memory.[3] “LSTM以及三重门，遗忘门，输入门，输出门.” LSTM以及三重门，遗忘门，输入门，输出门_网络_Lison_Zhu’s Blog-CSDN博客, blog.csdn.net/Lison_Zhu/article/details/97236501.[4] “递归神经网络问题整理.” 递归神经网络问题整理_网络_leo鱼的博客-CSDN博客, blog.csdn.net/webzjuyujun/article/details/71124695.[5] “详解机器学习中的梯度消失、爆炸原因及其解决方法.” 详解机器学习中的梯度消失、爆炸原因及其解决方法_网络_Double_V的博客-CSDN博客, blog.csdn.net/qq_25737169/article/details/78847691.[6] Dnkdnk. “What Is Intuition Using Tanh LSTM.” Stack Overflow, Sept. 1966, stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm."
    },
    {
      "title"    : "医学图像分割模型 U-net",
      "url"      : "/blog/2020/U-net.html",
      "tags"     : "Computer Vision, Neural Network",
      "date"     : "2020-01-04 00:00:00 +0000",
      "content"  : "U-net是一种前馈神经网络模型，与传统卷积神经网络不同的是，U-net通过直接拼接相同分辨率的图像在网络中创造“短路”，从而使得梯度可以更好的在网络中传播。与此同时，通过将下卷积前的图像分割结果拼接到上卷积过程中的分割结果上，下卷积结果中的高分辨率细节也可以被传递到上卷积过程中，从而提高模型分割准确率。1. IntroductionU-net与其他机器视觉神经网络的根本区别： 一般的神经网络执行分类操作，输入一张图片，输出一个向量，其中每一项对应该图片属于对应标签的概率 U-net 对图片进行“语义分割”，输出的信息不但包括对图片中属性特征的识别，还包括对于指定物体位置的识别过去进行对图像进行语义分割的一种尝试是：通过提供一个像素周边的环境，训练网络识别这个像素属于的物体的类型。这种方法确实可行，因为可以对图片中的每一个像素进行同样的操作来逐个识别每个像素属于什么物体。但是这个方法有两个不足之处: 处理速度太慢 因为神经网络每次要单独训练，而且划分的Patch之间有很大的冗余重复 网络的设计需要在确定位置和更大的感受野之间权衡 当使用尺寸更大的Patch时，需要使用更多的池化层，会降低网络确定像素位置的能力；当网络使用尺寸较小的Patch时，神经网络的感受野（对周边特征的“视野”）会变小。 与之前方法相比，U-net有以下几点特征： 我们的网络在上采样部分依然有大量的特征通道，这使得网络可以将空间上下文信息向更高的分辨率层传播。结果是，上采样路径基本对称于下采样路径，并呈现出一个U型。 网络不存在任何全连接层，并且，只使用每个卷积的valid部分，例如，分割图只包含这样一些像素点，这些像素点的完整上下文都出现在输入图像中。这种策略允许使用Overlap-tile策略无缝地分割任意大小的图像(参见下图)。 为了预测图像边界区域的像素点，我们采用镜像图像的方式补全缺失的环境像素。这个tiling方法在使用网络分割大图像时是非常有用的，因为如果不这么做，GPU显存会限制图像分辨率。 此外，为了使得U-net可以在小批量数据的情况下顺利训练，我们使用了弹性形变处理训练图像（因为生物材料经常发生形变），通过这种方法，我们可以极大地增加训练图像的数量。 为了应对细胞分割任务中的一个挑战是如何将同类别的相互接触的目标分开，为了解决这个问题，我们改进了网络的损失函数，提出了使用一种带权重的损失(weighted loss)；在新的损失函数中，分割相互接触的细胞会获得更大的权重。2 Network Architecture因此，本文作者基于“完全卷积网络”设计了 神经网络架构（如下图），用以处理图像的语义分割问题在这个网络中，图片首先通过最大池化层进行“下采样”，减小图片分辨率的同时使用33卷积核提取图片的特征，每一层中，提取的特征通道数量是输入特征通道数量的两倍。通过这种方法，最后将输入图片转化为大小2828，具有1024个特征通道状态。接着，网络通过22的卷积核对图片进行上采样（如下图所示，但下图中使用的是33卷积核）需要注意的是在上采样的过程中，图片依然保存了大量的特征通道，这有助于网络将图片周边的环境向上传播与此同时，为了提高图片的分辨率，网络还会将池化前的特征通道经过裁剪后（裁剪是由于无填充像素下卷积操作带来的无法避免的尺寸减小导致的，如下图所示）复制到上采样时的状态中，再使用一个3*3卷积核将这些特征通道进一步整合起来。如此重复此步骤直到图片的尺寸重新被放大至392*392 pixel （作为对比，输入是572*572像素，大小的减少是由于重复卷积操作导致的），此时图片依然有多达64个特征通道。此时，我们可以看到上采样的通道与下采样的通道基本对称，整个神经网络呈现为“U形”这时候再用3*3卷积核与1*1卷积核将这些特征通道重新整合起来即可。 需要注意的一点是，再U-net中，作者使用的所有激活函数都是线性修正单元（ReLU, rectified linear unit）。由于使用这种函数的一阶导数是常数，与带权输入无关，可以有效避免深度网络训练时的梯度消失问题与梯度爆炸问题（与之相对应，Sigmoid函数有严重的梯度消失问题，这会极大的降低神经元的学习速度，同时使得神经网络靠近输出的层级更加容易达到饱和状态）。3 TrainingU-net使用随机梯度下降的方法进行训练，每批次中只有一幅图片。为了减少使用单个图片计算损失函数梯度带来的，每次梯度下降方向由于图片之间差异带来的过大变化，作者使用了很大的动量值(momentum = 0.99) ，这意味着每一次梯度下降的方向更多的根据过去的图片的损失函数梯度来决定。同时，为了使得神经网络可以区分开相邻的两个细胞，作者改进了交叉熵函数。作者通过在交叉熵函数中增加了单个像素的权重值使得网络更加注重细胞之间的分割（这里看不懂具体实现方法）U-net使用了输入图片每一个像素的经过改进的交叉熵函数的柔性最大值作为整幅图片的损失函数。"
    },
    {
      "title"    : "算法的时间复杂度 | Time Complexity and Asymptotic Notation",
      "url"      : "/blog/2019/Time-Complexity.html",
      "tags"     : "Algorithm",
      "date"     : "2019-09-01 00:00:00 +0000",
      "content"  : "Why we need Asymptotic NotationIn most of the time, don’t to calculate exact computational time for a given algorithm.For an input that is large enough, coefficient on lowest term will have little effect overall whole algorithm. Therefore, main trend determined by highest polynomial.When are focusing how increases as scale increase, calculating Efficiency algorithm.What do concern running algorithm increase increase. In this case, employ asymptotic notation help us analyze complexity algorithm.$Theta (g(n))$ | Big-Theta NotationThis represents set functions has tight upper bound and lower bound. If function $f(x)$ in $Theta (g(n))$, then know there exists $n_0$, $c_1$, $c_2$ such that$$c_1 cdot g(n) leq f(n) c_2 quad forall n geq n_0$$$O(g(n))$ Big-O specific $O(g(n))$, $n_0$ $c$ that$$0leq f(n)leq ccdot n_0$$Since big O only specify function, it much bigger than theta notation. Which means $Theta(n) subseteq O(n)$.$Omega(g(n))$ Big-Omega For all $Omega(g(n))$, must satisfy exist that$$ccdot n_0$$Amortized Analysis Time ComplexityThe Amortized Complexity calculation average operation.Example: Java, arrayList item fact array. When full, copy elements from original array into new with length 1.5 times one.Though seems be inefficient may $O(n)$ some situation, Average adding still $O(1)$.Suppose reading &amp;amp; writing one element take $c$. Constructing $n = 1.5^m k$ take:$$begin{aligned}T(n) &amp;amp;= underbrace{2sum_{i 0}^{m}{(1.5)^ikcdot c}}{text{Copy across arrays}} + underbrace{(1.5)^m kc}{text{Add last array}} 2ckcdot frac{1 - 1.5^m}{1 1.5} kc&amp;amp;= -4ck 4ck(1.5)^m (1.5)^m O(1) O(n) O(n)&amp;amp;= end{aligned}$$Therefore, average, takes add $O(1)$."
    }
]
