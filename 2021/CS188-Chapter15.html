<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!--<meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c"></meta>--><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CS188 Chapter 15 Probabilistic Reasoning over Time | Yutian’s Blog</title>
<meta name="generator" content="Jekyll v4.2.2">
<meta property="og:title" content="CS188 Chapter 15 Probabilistic Reasoning over Time">
<meta name="author" content="Yutian (Mark) Chen">
<meta property="og:locale" content="en_US">
<meta name="description" content="In which we try to interpret the present, understand the past, and perhaps predict the future, even when very little is crystal clear.">
<meta property="og:description" content="In which we try to interpret the present, understand the past, and perhaps predict the future, even when very little is crystal clear.">
<link rel="canonical" href="https://markchenyutian.github.io//blog/2021/CS188-Chapter15.html">
<meta property="og:url" content="https://markchenyutian.github.io//blog/2021/CS188-Chapter15.html">
<meta property="og:site_name" content="Yutian’s Blog">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-08-15T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="CS188 Chapter 15 Probabilistic Reasoning over Time">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yutian (Mark) Chen"},"dateModified":"2021-08-15T00:00:00+00:00","datePublished":"2021-08-15T00:00:00+00:00","description":"In which we try to interpret the present, understand the past, and perhaps predict the future, even when very little is crystal clear.","headline":"CS188 Chapter 15 Probabilistic Reasoning over Time","mainEntityOfPage":{"@type":"WebPage","@id":"https://markchenyutian.github.io//blog/2021/CS188-Chapter15.html"},"url":"https://markchenyutian.github.io//blog/2021/CS188-Chapter15.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="shortcut icon" href="">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/blog/assets/css/main.css">
  <script src="/blog/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="https://markchenyutian.github.io//blog/feed.xml" title="Yutian's Blog">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      skipTags:['script', 'noscript', 'style', 'textarea', 'pre'],
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>



















<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<!-- | default: default_paths - --><span class="site-brand"><a class="site-brand-inner" rel="author" href="/blog/">
  <img class="site-favicon" title="Yutian's Blog" src="" onerror="this.style.display='none'">
  Yutian's Blog
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
<a class="page-link" href="/blog/about.html">ABOUT</a><a class="page-link" href="/blog/posts.html">POSTS</a><a class="page-link" href="/blog/files.html">FILES</a>




<span class="page-link">

<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="Franch">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: '',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  (function() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  })();
</script>











































  <section class="page-banner">
    <div class="page-banner-img">
      <div style="background-image: url(/blog/assets/images/banners/CS188Background.jpg)"></div>
    </div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">CS188 Chapter 15 Probabilistic Reasoning over Time</h1>
  <h3 class="post-subtitle"></h3>

  <p class="post-meta">
    <time class="dt-published" datetime="2021-08-15T00:00:00+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Aug 15, 2021
    </time>

    
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 33 mins</span>

    <!-- Read Count Insert Here -->
  </p>
<div class="post-tags"><a class="post-tag" href="/blog/tags.html#Machine%20Learning">#Machine Learning</a></div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('auto' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <div class="info">
<em>In which we try to interpret the present, understand the past, and perhaps predict the future, even when very little is crystal clear.</em>
</div>

<p><strong>belief state</strong> that represents which states of the world are currently possible. From belief state and a <strong>transition model</strong>, the agent can predict how the world might evolve in the next step.</p>

<p><img src="https://markdown-img-1304853431.file.myqcloud.com/20210731142523.jpg" alt="How Belief State Evolves"></p>

<p>From information from the <strong>sensor model</strong>, agents can update the belief state.</p>

<p><img src="https://markdown-img-1304853431.file.myqcloud.com/20210731142629.jpg" alt="Use Sensor update Belief State"></p>

<p>In <em>previous</em> section, belief state can only tell which state is <em>possible</em>, but can’t say which state is <em>likely</em> or <em>unlikely</em>. In this section, we can <strong>quantify the degree of belief in the belief state</strong>.</p>

<h2 id="151-time-and-uncertainty">15.1 Time and Uncertainty</h2>

<p>In previous section, we have talked about the Bayesian Network. Bayesian network can perform probabilistic reasoning in static world. The value of random variable at each moment is independent with its previous value.</p>

<p>However, in many scenarios, the previous state <strong>DO</strong> influence the current state. To utilize such information, we use a model called <strong>Markov chain</strong>.</p>

<h3 id="1511-states-and-observations">15.1.1 States and observations</h3>

<p>We view the world as a series of snapshots (a.k.a. <strong>time slices</strong> and time is not continuous)</p>

<p>$\mathbf{X}_t$ denote the set of state variables at time $t$</p>

<p>$\mathbf{E}_t$ denote the set of observable evidence variables at time $t$</p>

<p>$\mathbf{E}_t = e_t$ where $e_t$​ is the observed value for evidence variable.</p>

<p>We will assume that the state sequence starts at $t=0$ and evidence starts arriving at $t=1$.</p>

<h3 id="1512-transition-and-sensor-models">15.1.2 Transition and Sensor Models</h3>

<p>Transition model specifies the probability distribution over the latest state variables given previous values, that is,</p>

<p>$$
\mathbf{P}\left(\mathbf{X}<em>t \mid \mathbf{X}</em>{0:t-1}\right)
$$</p>

<p>However, this leads to a problem: as $x\rightarrow \infty$, the size of set $\mathbf{X}_{0:t-1}$ has an unbounded size. To solve this problem, we introduce the <strong>Markov Assumption</strong>.</p>

<div class="info">
  <p><strong>Markov Assumption</strong>
Markov process is <em>memoryless</em>, which means that Current State only depends on a <em>finite fixed number</em> of previous states.</p>
</div>

<p><u>Process satisfying Markov assumption is called <b>Markov Process</b> or <b>Markov Chains</b>.</u></p>

<div class="info">
<b>First Order Markov Process</b> - $\mathbf{X}_{t}$ is only related with $\mathbf{X}_{t-1}$​

\$\$
\mathbf{P}(\mathbf{X}\mid \mathbf{X}_{0:t-1}) = \mathbf{P}(\mathbf{X}\mid \mathbf{X}_{t-1})
\$\$

</div>

<p>Beyond first-order Markov process, there are second, third, …, n-th order Markov Process.</p>

<p><strong>N-order Markov Process</strong></p>

<p>$$
\mathbf{P}(\mathbf{X}\mid \mathbf{X}<em>{0:t-1}) = \mathbf{P}(\mathbf{X}\mid \lbrace\mathbf{X}</em>{t-1}, \mathbf{X}<em>{t-2}, \cdots, \mathbf{X}</em>{t-n}\rbrace)
$$</p>

<p>Therefore, in a first-order Markov process, the transition model is the conditional distribution $\mathbf{P}(\mathbf{X_t}\mid \mathbf{X}_{t-1})$</p>

<p>Besides Markov Assumption, we also assume the world is <em>stationary</em>. At any given $t$, the transition model $\mathbf{P}(\mathbf{X_t}\mid \mathbf{X}_{t-1})$ is the same.</p>

<div class="info">
<b>Stationary Assumption</b>

\$\$
\mathbf{P}(\mathbf{X_m}\mid \mathbf{X}_{m-1})\equiv \mathbf{P}(\mathbf{X_n}\mid \mathbf{X}_{n-1}) \forall m, n
\$\$

</div>

<p>During the process, we can learn the status of world through <strong>sensor</strong>. The sensors read from world status and give us number. Therefore, it’s safe to assume that</p>

<div class="info">
<b>Sensor Assumption</b>

\$\$
\mathbf{P}(\mathbf{E}_t\mid\mathbf{X}_{0:t}, \mathbf{E}_{0:t-1}) = \mathbf{P}(\mathbf{E}_t \mid \mathbf{X}_t)
\$\$

</div>

<p>$\mathbf{P}(\mathbf{E}_t \mid \mathbf{X}_t)$ is the <strong>Sensor Model</strong>, sometimes also called <em>Observation Model</em>.</p>

<p><img src="https://markdown-img-1304853431.file.myqcloud.com/20210802183103.jpg" alt="bfe4f431a5fb0f8bbed1896c3512dc8"></p>

<h3 id="1513-stationary-state-of-markov-model">15.1.3 Stationary State of Markov Model</h3>

<p>In most cases, there exists a stationary state in the Markov Model, that is, there exists some distribution of probability of state $\mathbf{X}_ t$ such that $\mathbf{P}(\mathbf{X}_ t) = \mathbf{P}(\mathbf{X}_ {t+1})$</p>

<p>The state of Markov Model, in most cases, will converge to a stationary case.</p>

<h3 id="1514-improve-markov-model">15.1.4* Improve Markov Model?</h3>

<p>Generally, there are two methods to increase the precision of Markov Model:</p>

<ul>
  <li>Increase the order of Markov Process Model</li>
  <li>Increase the set of state variables.</li>
</ul>

<p>By increasing the order of model, we can use information from multiple ticks to calculate the probability distribution on time $t$.</p>

<p>Increasing the order of model can <em>always</em> be reformulated as an increase in the set of state variables.</p>

<h2 id="152-inference-in-temporal-models">15.2 Inference in Temporal Models</h2>

<p>There are four basic inference tasks that must be solved in generic temporal model:</p>

<ul>
  <li>
<strong>Filtering</strong> - computing the <em>Belief State</em> - the posterior distribution over the most recent state - given all evidence to date.
    <center>\$\$\mathbf{P}(\mathbf{X_t}\mid e_{1:t})\$\$​</center>
    <p>With filtering, agent can keep track on current state and make rational decisions.</p>
  </li>
  <li>
    <p><strong>Prediction</strong> - computing the posterior distribution over the future state, given all evidence to date.</p>

    <p>$$
  \mathbf{P}(\mathbf{X_{t+k}}\mid e_{1:t})
$$</p>

    <p>Prediction is useful for evaluating possible courses of action based on their expected outcomes.</p>
  </li>
  <li>
    <p><strong>Smoothing</strong> - computing the posterior distribution over a <em>past</em> state, given all evidence up to the present.</p>

    <p>$$
  \mathbf{P}(\mathbf{X}<em>k\mid e</em>{1:t}) , \text{where }1 \leq k\leq t
$$</p>

    <p>Smoothing provides a better estimate of the state than was available at the time, because it incorporates more evidence.</p>
  </li>
  <li>
    <p><strong>Most likely explanation</strong> - Given a sequence of observations, we might wish to find the sequence of states that is most likely to have generated those observations.</p>

    <p>$$
  \text{argmax}<em>{\mathbf{x}</em>{1:t}}P(\mathbf{x_{1:t}\mid e_{1:t}})
$$</p>
  </li>
</ul>

<h3 id="1521-filtering-and-prediction">15.2.1 Filtering and Prediction</h3>

<h4 id="filtering">Filtering</h4>

<p>Filtering algorithm should compute the probability distribution <span>$\mathbf{P}(\mathbf{X}_ {t+1})$</span> from <span>$\mathbf{P}(\mathbf{X}_ t\mid e _ {1:t})$</span> given new evidence <span>$\mathbf{P}(e_ {t+1})$</span>.</p>

<p>$$
\mathbf{P}(\mathbf{X}<em>{t+1}\mid e</em>{1:t+1}) = f(e_{t+1}, \mathbf{P}(\mathbf{X}<em>{t}\mid e</em>{1:t}))
$$</p>

<p>For function $f$, this process is called <strong>recursive estimation</strong>.</p>

<p>Below, we will reformulate the filtering function and find ways to describe filtering using <em>sensor model</em>, <em>transition model</em> etc.</p>

<ol>
  <li>Split the evidence $e_ {1:t+1}$ to $e_ {1:t}, e_ {t+1}$</li>
</ol>

<p>$$
\begin{aligned}
\mathbf{P}(\mathbf{X}<em>{t+1}\mid e</em>{1:t+1}) &amp;= \mathbf{P}(\mathbf{X}<em>{t+1}\mid e</em>{1:t}, e_{t+1})
\end{aligned}
$$</p>

<ol>
  <li>Apply Bayes formula</li>
</ol>

<blockquote>
  <p><a href="/2021/05/30/CS188-Chapter13.html#h8">Reference - Bayes Formula</a>
$$
\mathbf{P}(\mathbf{X}_ {t+1}\mid e_ {1:t}, e_ {t+1}) = \frac
{\mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1}, e_ {1:t})\mathbf{P}(\mathbf{X}_ {t+1} \mid e_ {1:t})}
{\mathbf{P}(e_ {1+t}\mid e_ {1:t})}
$$</p>

  <p>Due to the <em>sensor assumption</em> in hidden Markov model, $\mathbf{e_ {1+t}}$ is independent with $\mathbf{e_ {1:t}}$.</p>

  <p>$$
\mathbf{P}(\mathbf{X}_ {t+1}\mid e_ {1:t}, e_ {t+1}) = \frac
{\mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1}, e_ {1:t})\mathbf{P}(\mathbf{X}_ {t+1} \mid e_ {1:t})}
{\mathbf{P}(e_ {1+t})}
$$</p>
</blockquote>

<p>In this case, we change $\mathbf{P}(e_ {1+t})$ to <strong>normalization constant</strong> - $\alpha$.</p>

<p>$$
= \alpha \mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1}, e_ {1:t})\mathbf{P}(\mathbf{X}_ {t+1} \mid e_ {1:t})
$$</p>

<ol>
  <li>Apply <strong>Sensor assumption</strong> in Hidden Markov Model</li>
</ol>

<p>$$
= \alpha \mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1})\mathbf{P}(\mathbf{X}_ {t+1} \mid e_ {1:t})
$$</p>

<ol>
  <li>Expand the last term</li>
</ol>

<p>$$
= \alpha \mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1})\mathbf{P}(\mathbf{X}_ {t+1} \mid x_t) \mathbf{P}(\mathbf{x}_ t \mid e_ {1:t})
$$</p>

<p>In a short, we can filter on $\mathbf{X}_ {t+1}$ using this formula</p>

<div class="info">
<b>Filtering Formula</b>

\$\$
\mathbf{P}(\mathbf{X}_{t+1}\mid e_{1:t+1}) = 
\alpha 
\overbrace{\mathbf{P}(e_ {1+t} \mid \mathbf{X}_ {t+1})}^{\text{Sensor Model}}
\underbrace{\mathbf{P}(\mathbf{X}_ {t+1} \mid \mathbf{x}_ t)}_{\text{Transition Model}}
\overbrace{\mathbf{P}(\mathbf{x}_ t \mid e_ {1:t})}^{\text{Recursive Filtering}}
\$\$

<p>*$\alpha$ is the normalization constant</p>

</div>

<blockquote>
  <p>$\mathbf{P}(\mathbf{X}_ {0}\mid e_ {1:0})$ is the probability distribution of state variable when NO CLUE is provided. Therefore, this value is prior knowledge.</p>
</blockquote>

<h4 id="prediction">Prediction</h4>

<div class="info">

<b>Prediction Formula</b>

\$\$
\mathbf{P}(\mathbf{X}_ {1+t}\mid e_{1:t}) = 
\alpha
\underbrace{\mathbf{P}(\mathbf{X}_ {t+1}\mid x_ {t})}_{\text{Transition Model}}
\overbrace{\mathbf{P}(\mathbf{x}_ t\mid e_{1:t})}^{\text{Previous Filtering}}
\$\$

<p>*$\alpha$ is the normalization constant</p>
</div>

<p>By applying transition model repeatedly, we can predict state at $t+2$, $t+3$, …, etc.</p>

<h4 id="case-study-rain--umbrella">Case Study: Rain &amp; Umbrella</h4>

<p>You are in a basement, and you want to know whether it is raining outside. The only information you can get is whether people get in basement with umbrella on their hands.</p>

<p><strong>Prior Knowledge</strong></p>

<ul>
  <li>
    <p>State transition model</p>

    <p>$$
\mathbf{P}(R_t \mid R_ {t - 1}) = \left[\begin{matrix}
P(\neg r_ t \mid r_ {t - 1}) = 0.3 &amp; P(r_ t \mid r_ {t - 1}) = 0.7 <br>
P(\neg r_ t \mid \neg r_ {t - 1}) = 0.7 &amp; P(r_ t \mid \neg r_ {t - 1}) = 0.3<br>
\end{matrix}\right]
$$</p>

    <p><em>If it rains at day $t$, the probability to rain on day $t+1$ is 0.7</em>, if …</p>
  </li>
  <li>
    <p>Sensor Model</p>

    <p>$$
\mathbf{P}(u \mid R) = \left[\begin{matrix}0.9 &amp; 0.2\end{matrix}\right]
$$</p>

    <p><em>The probability of having an umbrella if rainy is $0.9$</em>. However, even when it is not rainy, <em>the probability of seeing an umbrella is $0.2$</em>.</p>
  </li>
  <li>
    <p>Initial State Distribution</p>

    <p>On day 0, you believe $P(Rain) = P(\neg Rain) = 0.5$, in other words, $\mathbf{P}(R_0) = \langle0.5, 0.5\rangle$</p>
  </li>
</ul>

<p><strong>Prediction &amp; Filtering</strong></p>

<p>Without any new information, you can predict $\mathbf{P}(R_1)$ by applying transition model.</p>

<p>$$
\mathbf{P}(R_1) = \alpha\mathbf{P}(R_0)\mathbf{P}(R_1\mid R_0) = \alpha\left[\begin{matrix}
0.5 &amp; 0.5
\end{matrix}\right] \times \left[\begin{matrix}
0.3 &amp; 0.7 <br>
0.7 &amp; 0.3
\end{matrix}\right] = \left[\begin{matrix}
0.5, 0.5
\end{matrix}\right]
$$</p>

<p>Seems useless, ugh? But, things becomes interesting at the moment you receive new message: you see an umbrella so $U_1 = t$</p>

<p>Now we can run the filtering process:</p>

<p>$$
\begin{aligned}
\mathbf{P}(R_1 \mid u_1) &amp;= \alpha \mathbf{P}(u_1\mid R_1)\mathbf{P}(R_1\mid R_0)<br>
&amp;= \alpha\left[\begin{matrix}
0.9 &amp; 0.2
\end{matrix}\right]\times \left[\begin{matrix}
0.5 &amp; 0.5
\end{matrix}\right]<br>
&amp;= \alpha \left[\begin{matrix}
0.45 &amp; 0.1
\end{matrix}\right]<br>
&amp;\approx \left[\begin{matrix}
0.818 &amp; 0.182
\end{matrix}\right] 
\end{aligned}
$$</p>

<h3 id="1522-smoothing">15.2.2 Smoothing</h3>

<p>Smoothing is computing the past state possibility distribution given all evidence. In formal mathematical language, smoothing is evaluating:</p>

<p>$$
\mathbf{P}(X_k\mid e_ {1:t}), \quad \forall k \in [1, t)
$$</p>

<p>To evaluate this expression, we could take following steps:</p>

<ol>
  <li>Split the evidence variable set</li>
</ol>

<p>$$
\mathbf{P}(X_k\mid e_ {1:t}) = \mathbf{P}(X_k\mid e_ {1:k}, e_ {k+1: t})
$$</p>

<ol>
  <li>Apply Bayes Rule, take $e_ {1:k}$​ as evidence variable set (<a href="/2021/05/30/CS188-Chapter13.html#h8">Reference - Bayes Formula</a>)</li>
</ol>

<p>$$
= \alpha \mathbf{P}(X_ k \mid e_ {1:k}) \mathbf{P}(e_ {k+1:t} \mid X_k, e_ {1:k})
$$</p>

<ol>
  <li>According to sensor assumption in HMM, we know $e_ {k+1:t}$ is independent with $e_ {1:k}$</li>
</ol>

<p>$$
\begin{aligned}
&amp;=\alpha\mathbf{P}(X_k\mid e_ {1:k}) \mathbf {P}(e_ {k+1:t} \mid X_k) <br>
&amp;=\alpha\text{ Filtering}(X_k) \text{Backward}(X_k, e_ {k+1:t})<br>
&amp;=\alpha
  \mathbf{P}(e_ {k} \mid \mathbf{X}_ {k})
  \mathbf{P}(\mathbf{X}_ {k} \mid \mathbf{x}_ {k - 1})
  \mathbf{P}(\mathbf{x}_ {k - 1} \mid e_ {1: k-1})
  \text{Backward}(X_k, e_ {k+1:t}) <br>
\end{aligned}
$$</p>

<p>For the “Filtering” part, we can call filtering function described above. Below will discuss the “Backward” part. Backward function will broadcast information from “future” to the state we want to apply smoothing on.</p>

<ol>
  <li>Conditioning on $\mathbf{X}_ {k + 1}$</li>
</ol>

<p>$$
\mathbf {P}(e_ {k+1:t} \mid X_k) = \sum_ {x_ {k + 1}}{
  \mathbf{P}(\mathbf{e}_ {k + 1 : t} \mid \mathbf{X}_ {k}, \mathbf{x}_ {k + 1})
  \mathbf{P}(\mathbf{x}_ {k + 1} \mid \mathbf{X}_ {k})
}
$$</p>

<ol>
  <li>Conditional Independence</li>
</ol>

<p>$$
= \sum_ {x_ {k + 1}}{
  \mathbf{P}(\mathbf{e}_ {k + 1 : t} \mid \mathbf{x}_ {k + 1})
  \mathbf{P}(\mathbf{x}_ {k + 1} \mid \mathbf{X}_ {k})
}
$$</p>

<ol>
  <li>Split Evidence variables set</li>
</ol>

<p>$$
= \sum_ {x_ {k + 1}}{
  \mathbf{P}(\mathbf{e}_ {k + 1}, \mathbf{e}_ {k + 2 : t} \mid \mathbf{x}_ {k + 1})
  \mathbf{P}(\mathbf{x}_ {k + 1} \mid \mathbf{X}_ {k})
}
$$</p>

<p>4.</p>

<p>$$
= \sum_ {x_ {k + 1}}{
  P (\mathbf{e}_ {k + 1} \mid \mathbf{x}_ {k + 1})
  P (\mathbf{e}_ {k + 2 : t} \mid \mathbf{x}_ {k + 1})
  \mathbf{P}(\mathbf{x}_ {k + 1} \mid \mathbf{X}_ {k})
}
$$</p>

<p>We can find that $\mathbf {P}(e_ {k+1:t} \mid X_k)$’s expression contains $\mathbf {P}(e_ {k+2:t} \mid X_ {k + 1})$. So the evaluation process is a <strong>recursive</strong> process.</p>

<p>$$
\begin{aligned}
\mathbf {P}(e_ {k+1:t} \mid X_k) &amp;= \mathbf{b}_ {k + 1: t}<br>
&amp;= \text{Backward}(\mathbf{b}_ {k + 2: t}, \mathbf{e}_ {k + 1})
\end{aligned}
$$</p>

<p>But there is one problem - as the size of evidence set increase, it will take increasing time to perform a smoothing operation (as it requires recursively called from $k$ to $t$).</p>

<p>To solve this problem, a strategy called “<strong>fixed-lag smoothing</strong>” is proposed. For any $k$ that is called to smoothing on $X_k$, the <em>Backward</em> function will only call recursively to $k+n$ where $n$ is a constant.</p>

<h3 id="1523-finding-the-most-likely-sequence">15.2.3 Finding the most likely sequence</h3>

<p>Sometimes, when we get a series of evidence value from sensor, we want to know the <em>most-likely</em> sequence of hidden state that can lead to such series of evidence value. Using mathematical language, we can describe finding most-likely sequence as such expression:</p>

<p>$$
\max_ {x_ 1\cdots, x_ t}\mathbf{P}(x_ 1, \cdots, x_ t, \mathbf{X}_ {t+1} \mid \mathbf{e}_ {1:t+1})
$$</p>

<p>There is a recursive relationship between each state in the most-likely sequence.</p>

<p>$$
=\alpha \mathbf{P}(\mathbf{e}_ {t+1} \mid \mathbf{X}_ {t+1}) \max_ {\mathbf{x}_ t}{(
  \mathbf{P}(\mathbf{X}_ {t+1} \mid \mathbf{x}_ {t})
  \max_ {\mathbf{x}_ 1\cdots \mathbf{x}_ {t - 1}}{
      P(x_ 1, \cdots, x_ {t - 1}, x_ t \mid \mathbf{e}_ {1:t})
    }
)}
$$</p>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/blog/2021/uniswap3-1.html" title="Uniswap 3 - Liquidity, Liquidity Provider and AMM">Uniswap 3 - Liquidity, Liquidity Provider...</a><a class="next" href="/blog/2021/uniswap3-2.html" title="Uniswap 3 - Starting from Uniswap v1">Uniswap 3 - Starting from Uniswap...</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <!-- <ul>
        
        <li><a class="post-link" href="/blog/2022/the-fences.html" title="Uniswap 3 - Starting from Uniswap v1">The Fences | AR Web Application</a></li><li><a class="post-link" href="/blog/2022/Multi-heuristic-Astar.html" title="Uniswap 3 - Starting from Uniswap v1">A* Search and its Variants</a></li><li><a class="post-link" href="/blog/2021/Seq2Seq.html" title="Uniswap 3 - Starting from Uniswap v1">NLP 101: Seq2Seq 模型</a></li><li><a class="post-link" href="/blog/2022/clac-embeddable.html" title="Uniswap 3 - Starting from Uniswap v1">Embeddable Clac Execution Environment</a></li></ul> -->
      
      
      
      <ul>
        
          
          
          
            <li><a class="post-link" href="/blog/2022/Multi-heuristic-Astar.html" title="Uniswap 3 - Starting from Uniswap v1">A* Search and its Variants</a></li>
            
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
            <li><a class="post-link" href="/blog/2021/Word-Embedding.html" title="Uniswap 3 - Starting from Uniswap v1">NLP 101: Word Embedding 词嵌入</a></li>
            
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
            <li><a class="post-link" href="/blog/2021/2048-Project-1.html" title="Uniswap 3 - Starting from Uniswap v1">2048 Project (1)</a></li>
            
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
          
        
          
          
          
            <li><a class="post-link" href="/blog/2021/CS188-Chapter14.html" title="Uniswap 3 - Starting from Uniswap v1">CS188 Chapter 14 Probabilistic Reasoning</a></li>
            
          
          
      </ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">目录</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      if (! h.getAttribute('hide-toc')){
        menuHTML += (
          '<li class="h-' + h.tagName.toLowerCase() + '">'
          + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
        }
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
      <div>Copyright © 2019-2022 @Yutian (Mark) Chen</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="http://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/blog/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
</html>
